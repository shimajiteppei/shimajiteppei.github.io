<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Ubuntu blog</title><link>https://ubuntu.com//blog/feed</link><description>Ubuntu blog feed</description><atom:link href="https://ubuntu.com//blog/feed" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>Python Feedgen</generator><lastBuildDate>Sat, 14 Feb 2026 12:01:00 +0000</lastBuildDate><item><title>The foundations of software: open source libraries and their maintainers</title><link>https://ubuntu.com//blog/the-foundations-of-software-open-source-libraries-and-their-maintainers</link><description>&lt;p&gt;Open source libraries are repositories of code that developers can use and, depending on the license, contribute to, modify, and redistribute. Open source libraries are usually developed on a platform like GitHub, and distributed using package registries like PyPI for Python and npm for JavaScript. These repositories contain pre-written, re-usable code that developers use to [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Open source libraries are repositories of code that developers can use and, depending on the license, contribute to, modify, and redistribute. Open source libraries are usually developed on a platform like GitHub, and distributed using package registries like PyPI for Python and npm for JavaScript. These repositories contain pre-written, re-usable code that developers use to add elements or features within their software projects. Open source libraries are maintained ‚Äì updated, patched, improved, and so on ‚Äì by people who are known, unsurprisingly, as ‚Äòmaintainers.‚Äô&lt;/p&gt;
&lt;p&gt;That‚Äôs the simple definition, at least ‚Äì but it fails to do justice to what goes on behind the scenes. The truth is that open source library maintainers are communities whose efforts support the overwhelming majority of modern software applications that we all rely on. For example, React is used widely to build user interfaces for web and mobile apps. React Native &lt;a href="https://www.ropstam.com/react-native-apps/"&gt;was used to build many popular apps&lt;/a&gt; which you may have used, including Facebook, Discord, and Airbnb. Libraries like React are sometimes supported by specific foundations, but there are hundreds, if not thousands, of libraries that rely on individual maintainers as well.¬†&lt;/p&gt;
&lt;p&gt;You may have noticed that our YouTube channel recently began a new series, ‚Äú&lt;a href="https://www.youtube.com/playlist?list=PLwFSk464RMxns9ylPfbaivj-fmIiE-Kld"&gt;Push to Talk | Meet the Maintainers.&lt;/a&gt;‚Äù The series highlights the work of prominent open source developers, like Andrew Gallant (the maintainer behind ripgrep), as well as giving a behind-the-scenes look into their journeys in the open source community. In this blog, we‚Äôre going to provide some context by peeling back the layers of open source libraries: how they work, why they‚Äôre important, and the maintainers that keep them going behind the scenes.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;How open source libraries work, and why they‚Äôre different from closed source libraries&lt;/h2&gt;
&lt;p&gt;Software doesn‚Äôt spring from the void. Someone ‚Äì or teams of someones ‚Äì have to build it in the first place, write the code, and make it run. But software is never &lt;em&gt;really&lt;/em&gt; done. Bugs appear that need patching, new functionalities are imagined or requested, performance can always be improved. Moreover, code faces an unrelenting tide of new security threats, changes to external libraries and frameworks, updates to operating systems, browsers and hardware ‚Äì all of which someone needs to stay on top of to avoid code becoming obsolete or unusable.¬†&lt;/p&gt;
&lt;p&gt;In proprietary software frameworks, broadly speaking, teams of developers are employed to do this work (building and/or maintaining software libraries). However, the library‚Äôs source code ‚Äì human-readable text written in a programming language which computers translate to binary, process, and execute ‚Äì can only be accessed by authorized individuals, like company employees and specific partners. The company, as the software owner, retains exclusive rights, which usually stops unauthorized viewing, modification, and redistribution of code from the closed source library. That means that only the software owners can include code from the libraries in their projects, and therefore, if software built using the closed source libraries goes wrong, users can only get support through the proprietary vendor who owns the code.¬†&lt;/p&gt;
&lt;p&gt;Open source development frameworks work differently. Open source libraries are usually built through community effort. Depending on the license and contributor agreement, anyone can propose a contribution to the code. More often than not, anyone can request a new feature or modification, or offer bug fixes. Maintainers lead the library, managing and moderating the community of contributors and users. Depending on the library, maintainers may look both at fine details ‚Äì reviewing contributed code, deciding which bits of code end up in the library, ensuring documentation is clear and accurate ‚Äì as well as the big-picture decisions, like steering the direction of the open source library as a whole.¬†&lt;/p&gt;
&lt;p&gt;The maintainers of open source libraries are usually not employed to look after the framework. Instead, the work is voluntary. In some cases, individual maintainers may support their work with sponsorships or donations. In other cases, foundations ‚Äì such as the Eclipse Foundation or Linux Foundation ‚Äì take a stewardship approach to open source maintenance. In these cases, the foundation acts as a guardian of the project or library, rather than an owner in the traditional sense. The foundation ensures that the project remains available and supported, which may include establishing Technical Steering Committees (TSCs) to provide strategic direction and guide the codebase, acting as a mediator for conflicts within the community regarding project development, and ensuring the code is properly licensed. Most importantly, foundations can collect and organize sponsorship, helping to buy servers, increase bandwidth, and provide grants for the contributors of the project.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Open source libraries: the backbone of modern software&lt;/h2&gt;
&lt;p&gt;Open source software can be found everywhere. &lt;a href="https://canonical.com/blog/state-of-global-open-source-2025"&gt;Our recent report, in collaboration with the Linux Foundation&lt;/a&gt;, revealed that globally, 55% of enterprises have adopted open source operating systems, whilst 49% have adopted open source cloud and container technologies, and 46% open source web and application development. Even if a project isn‚Äôt fully open source, it more likely than not contains some open source code, drawn from open source libraries: &lt;a href="https://www.blackduck.com/resources/analyst-reports/open-source-security-risk-analysis.html?utm_source=the+new+stack&amp;amp;utm_medium=referral&amp;amp;utm_content=inline-mention&amp;amp;utm_campaign=tns+platform"&gt;audits of codebases&lt;/a&gt; have found that up to 96% of projects contain open source code. This isn‚Äôt surprising: open access to the code means code can potentially be worked on by any number of contributors, as well as offering greater opportunities for thorough testing of the code for bugs.&lt;/p&gt;
&lt;p&gt;Without maintainers to manage the libraries, many open source libraries would stagnate. Some open source libraries have huge numbers of contributors, whilst for others, the maintainer may be the only contributor. In the latter case, the library simply stops if the maintainer does: no more patches, no security updates, no bug fixes.¬†&lt;/p&gt;
&lt;p&gt;If code needs to be continually updated and maintained to ensure that it doesn‚Äôt become obsolete, and the majority of software projects contain code from open source libraries, the effort that maintainers make to keep libraries up to date can‚Äôt be overstated.&lt;/p&gt;
&lt;p&gt;Why, then, do maintainers do the work?¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;What motivates maintainers?&lt;/h2&gt;
&lt;p&gt;As the 2023 &lt;a href="https://www.sonarsource.com/open-source-maintainer-survey-2023.pdf"&gt;&lt;em&gt;Tidelift state of the open source maintainer report&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;revealed, most are driven by making a positive impact on the world (70%) and the fact that the work is creative, challenging, and/or enjoyable (62%). Maintainers are motivated by belief in the software, in the community, and in the open source philosophy ‚Äì broadly speaking. But what does that mean in practice?&lt;/p&gt;
&lt;p&gt;The first episode of Canonical‚Äôs ‚ÄúMeet the Maintainers‚Äù series begins to reveal what these general motivations mean for the individual maintainers. The maintainer behind ripgrep, Andrew Gallant (or BurntSushi, as he‚Äôs also known) explains his earliest contributions to open source were inspired by his desire to host a discussion forum on his fan website for &lt;em&gt;The Simpsons&lt;/em&gt;. Starting with self-described ‚Äúhacking‚Äù on the proprietary forum software VBulletin, Gallant developed an interest in forum software in general. Like the motivations other maintainers report, Gallant enjoyed the challenge and creativity involved with hacking the PHP code to modify it so it will ‚Äúdo little things.‚Äù Two decades later, Gallant‚Äôs motivations are more community-centered: the satisfaction of creating something that is ‚Äúfree for everyone to use,‚Äù and ‚Äúwatching people use the stuff [he] build[s].‚Äù To find out more about the many libraries and projects Gallant has contributed to and worked on over the years, &lt;a href="https://www.youtube.com/watch?v=InsUD69qmUw"&gt;watch the video on our YouTube channel&lt;/a&gt;.¬†&lt;/p&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="304" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/InsUD69qmUw?feature=oembed" title="Meet the Maintainers: the mind behind ripgrep - Andrew Gallant‚Äôs blazing-fast search tool" width="540"&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Supporting maintainers: why it helps, and how you can do it&lt;/h2&gt;
&lt;p&gt;Financial incentives may not be the primary motivator for all maintainers; however, providing financial support helps to facilitate the work, ultimately producing stronger software, and faster code development.¬†&lt;/p&gt;
&lt;p&gt;Fortunately, giving back to open source projects and libraries is simple and straightforward. Platforms like thanks.dev help you to donate to the repositories your software draws on, automatically distributing funds proportionally to how often the dependency is used. As &lt;a href="https://thanks.dev/static/why"&gt;thanks.dev suggest on their site&lt;/a&gt;, this makes it easier for larger organizations to ‚Äúmanage the logistics of supporting the thousands of projects they depend on‚Äù, including deeply nested packages and crucial indirect dependencies that may otherwise be overlooked.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/blog/canonical-thanks-dev-giving-back-to-open-source-developers"&gt;Canonical began donating via thanks.dev in April of 2025&lt;/a&gt;. We committed to donating US$120,000 across 12 months at US$10,000 a month through the platform. You can find the full list of recipients so far at &lt;a href="https://thanks.dev/r/canonical"&gt;thanks.dev/r/canonical&lt;/a&gt;.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Recognizing maintainers&lt;/h2&gt;
&lt;p&gt;Open source libraries are labors of love that depend on the hard work of communities and talented developers. That work often goes unseen, unpaid, and unrecognized, but ‚Äì directly, or indirectly ‚Äì we rely on it more than we may be aware of.¬†&lt;/p&gt;
&lt;p&gt;As an open source company, Canonical is committed to spreading the open source philosophy to as many people and communities as we can. We drive our own projects, but also contribute staff, code, and funding to many more, which you can find out about on our &lt;a href="https://canonical.com/projects"&gt;webpage&lt;/a&gt;. ‚ÄúMeet the Maintainers‚Äù sheds light on the maintainers behind the libraries, recognizing them for their work, and, hopefully, inspiring more people to support open source, join communities, and contribute to open source libraries.¬†&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLwFSk464RMxns9ylPfbaivj-fmIiE-Kld" rel="noreferrer noopener" target="_blank"&gt;Watch the series&lt;/a&gt;&lt;a href="https://www.youtube.com/playlist?list=PLwFSk464RMxns9ylPfbaivj-fmIiE-Kld"&gt; &amp;gt;&lt;/a&gt;&lt;/p&gt;
</content:encoded><author>Isobel Kate Maxwell (Isobel Kate Maxwell)</author><category>Community</category><pubDate>Fri, 13 Feb 2026 17:30:52 +0000</pubDate></item><item><title>From inspiration to impact: design students from Regent‚Äôs University London explore open design for their dissertation projects</title><link>https://ubuntu.com//blog/from-inspiration-to-impact-design-students-from-regents-university-london-explore-open-design-for-their-dissertation-projects</link><description>&lt;p&gt;Last year, we had the opportunity to speak at Regent‚Äôs UX Conference (Regent‚Äôs University London‚Äôs conference to showcase UX work by staff, students, and alumni), where we engaged with students to make them aware of open design and their ability to contribute design skills to open source projects. The talk sparked great discussion, and we [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="550" loading="lazy" sizes="(min-width: 974px) 974px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_974/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_974/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F62bb%2Fimage.png 974w" width="974"/&gt;&lt;/figure&gt;
&lt;p&gt;Last year, we had the opportunity to speak at &lt;a href="https://studentunion.regents.ac.uk/event-details/regents-ux-design-conference" rel="noreferrer noopener" target="_blank"&gt;Regent‚Äôs UX Conference&lt;/a&gt; (Regent‚Äôs University London‚Äôs conference to showcase UX work by staff, students, and alumni), where we engaged with students to make them aware of &lt;a href="https://canonical.design/blog/open-design-the-opportunity-design-students-didnt-know-they-were-missing" rel="noreferrer noopener" target="_blank"&gt;open design&lt;/a&gt; and their ability to contribute design skills to open source projects. The talk sparked great discussion, and we were thrilled when two students, &lt;a href="https://www.linkedin.com/in/khaula-akhtar/" rel="noreferrer noopener" target="_blank"&gt;Khaula Akhtar&lt;/a&gt;, and &lt;a href="https://tanrikuluyaprak6.wixsite.com/portfolio-01" rel="noreferrer noopener" target="_blank"&gt;Yaprak Tanrikulu&lt;/a&gt;, chose to take on our open design briefs as part of their final-year dissertation projects.&lt;/p&gt;
&lt;p&gt;Both students worked independently on their projects, gaining hands-on experience in a real-world work. They explored the growing role of design in open source and brought fresh thinking to areas where design is often overlooked.&lt;/p&gt;
&lt;p&gt;This post celebrates their thoughtful work, shares reflections from their design journey, and invites others to consider contributing to open source projects!&lt;/p&gt;
&lt;p&gt;If you want to explore the project briefs yourself, they are open for anyone to explore, think about, and attempt to solve. Whether you‚Äôre thinking of ideas, writing them on a napkin, or developing your solution, there are no limitations to your creativity here! &lt;a href="https://assets.ubuntu.com/v1/7bd9c15e-project_briefs_for_universities.pdf" rel="noreferrer noopener" target="_blank"&gt;Get the briefs here&lt;/a&gt; (PDF).&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;a href="https://www.linkedin.com/in/khaula-akhtar/" rel="noreferrer noopener" target="_blank"&gt;Khaula Akhtar&lt;/a&gt;: Improving UX designer participation in open source software&lt;/h1&gt;
&lt;p&gt;Project brief: A master‚Äôs final project for Canonical that explores how to make non-code contribution pathways in open source more welcoming, engaging, and rewarding for UX designers.&lt;br/&gt;&lt;br/&gt;Objective: To identify the key barriers and motivations influencing UX designers‚Äô participation in open source and translate those insights into practical and evidence-based recommendations for improving contribution pathways.&lt;/p&gt;
&lt;p&gt;Check out their &lt;a href="https://assets.ubuntu.com/v1/ffff3c7e-masters_final_project_presentation_2.pdf" rel="noreferrer noopener" target="_blank"&gt;project presentation&lt;/a&gt;!&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Reflection from Khaula&lt;/h2&gt;
&lt;h4 class="wp-block-heading"&gt;What motivated you to take on an open source design brief for your final year project?&lt;/h4&gt;
&lt;p&gt;I chose this brief because open source plays a huge role in digital infrastructure, yet UX work within these communities is still underrepresented and often undervalued. I wanted to understand why designers struggle to participate and what could be changed to make these spaces more inclusive and collaborative. Canonical‚Äôs question about improving non-code contribution pathways felt meaningful and aligned with my interest in design as a social and organizational practice, not just as an interface problem. The project was a chance to dig into the culture, incentives, and workflows that shape real-world contribution, which made it a challenging but rewarding topic. I was motivated by the idea that my work could help create clearer paths for designers and potentially make open source more human-centered.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;What surprised you most about open source?&lt;/h4&gt;
&lt;p&gt;I was most surprised by how strongly developer culture influences every part of the contribution experience. I expected some technical bias, but I did not anticipate how deeply it shaped language, decision rights, and even what counts as a meaningful contribution. It was eye-opening to see how much design work gets reduced to visual tasks and how little visibility research, content, and information architecture receive. At the same time, I was surprised by the amount of genuine goodwill among contributors. Many designers are interested in giving back, learning and collaborating, even when recognition is limited. This mix of strong community spirit and structural misalignment helped me understand why participation can feel both inspiring and challenging at the same time.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;What was the biggest challenge you encountered during the project, and how did you tackle it?&lt;/h4&gt;
&lt;p&gt;The biggest challenge was the analysis phase and bringing enough participants together for interviews within a short time frame. Recruiting designers with actual open source experience required a lot of outreach and scheduling flexibility, and I had to rely on professional networks and snowball sampling to reach people. Once interviews were collected, the next challenge was learning how to apply reflexive thematic analysis properly. It was my first time working with this method, and I initially struggled with coding consistently and avoiding over-interpretation. I tackled this by keeping a reflexive journal, revisiting transcripts multiple times and creating an audit trail to track how my ideas developed. Regular check-ins and re-reading the literature also helped me stay grounded and confident in the themes I was building.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;What advice would you give other students considering contributing to open source through design?&lt;/h4&gt;
&lt;p&gt;My advice would be to approach open source with patience and a learning mindset. The environments can feel technical at first, but designers bring valuable skills that many projects genuinely need. Start with projects that clearly welcome UX work, because good documentation, UX labels and approachable maintainers make a big difference. When contributing, keep your proposals clear, connect them to existing components or patterns and explain your rationale so developers can understand your thinking. Open source runs on transparency, so the more you show your process, the smoother collaboration becomes. Most importantly, choose a project that aligns with your interests so you stay motivated while navigating the learning curve.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;a href="https://tanrikuluyaprak6.wixsite.com/portfolio-01" rel="noreferrer noopener" target="_blank"&gt;Yaprak Tanrikulu&lt;/a&gt;: Unifying the Juju ecosystem&lt;/h1&gt;
&lt;p&gt;Project brief: A project to unify the Juju ecosystem by creating a centralized, user-focused documentation and learning platform that simplifies onboarding, enhances discoverability, and improves the overall usability of Juju‚Äôs tools and resources.&lt;br/&gt;&lt;br/&gt;Objective: The objectives of this project focus on understanding the challenges newcomers face within the Juju ecosystem, evaluating and improving the accessibility and discoverability of its documentation, designing a structured learning path for new users, and exploring how different documentation formats and platforms influence the overall user experience.&lt;br/&gt;&lt;br/&gt;Check out their &lt;a href="https://assets.ubuntu.com/v1/c583686b-unifying_the_juju_ecosystem_proposal.pdf" rel="noreferrer noopener" target="_blank"&gt;project presentation&lt;/a&gt;!&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Reflection from Yaprak&lt;/h2&gt;
&lt;h4 class="wp-block-heading"&gt;What motivated you to take on an open source design brief for your final year project?&lt;/h4&gt;
&lt;p&gt;I was drawn to the open source design brief because it offered an opportunity to work on a project that has real-world impact and is deeply collaborative by nature. Open source communities thrive on transparency, inclusivity, and shared ownership, values that align closely with how I see design as a discipline. I wanted to explore how design could play a role in improving accessibility and usability in open systems, and how it could help bridge the gap between contributors with different skill sets. The idea of designing for a global audience, while contributing to something that anyone can build upon, was incredibly motivating.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;What was your approach to designing a more unified documentation experience?&lt;/h4&gt;
&lt;p&gt;My approach began with understanding the ecosystem of users involved; maintainers, contributors, and newcomers. I conducted user research and mapped out their pain points when navigating and contributing to documentation. From there, I developed a modular design system that emphasized clarity, consistency, and discoverability. I focused on creating a structure that could adapt across different open source projects while maintaining a cohesive visual and information hierarchy.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;What was the biggest challenge you encountered during the project, and how did you tackle it?&lt;/h4&gt;
&lt;p&gt;The biggest challenge was realizing that open source communities have very different needs, and that a one-size-fits-all documentation solution wouldn‚Äôt work. Users of the Juju ecosystem have varying levels of experience, which makes it difficult to design a structure that supports everyone equally. To address this, I created a Learning Hub concept that categorizes lessons and resources based on user experience levels. This way, new users can easily identify where to start and see if a lesson has any prerequisites, while existing contributors can quickly find advanced materials relevant to them. By organizing the content in a progressive, user-centred way, the documentation becomes more inclusive and adaptable to different learning journeys within open source communities.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;What advice would you give other students considering contributing to open source through design?&lt;/h4&gt;
&lt;p&gt;My biggest advice would be to approach open source work with curiosity and not get sidetracked by technical details or unfamiliar terminology. For those new to open source, there are often many unknown concepts and terms, so instead of getting caught up in definitions, focus on understanding the general idea and the broader purpose behind the project. Open source design is as much about listening as it is about creating, it‚Äôs a dialogue between diverse contributors with shared goals. Start by understanding the community‚Äôs context, participate in discussions, and learn how decisions are made. Don‚Äôt be afraid to share your early ideas and invite feedback; openness is part of the process. Contributing to open source through design is a powerful way to grow as a designer because it pushes you to think inclusively, work collaboratively, and design for impact beyond a single user group.&lt;br/&gt; &lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;üéâCongratulations to Khaula &amp;amp; Yaprak!&lt;/h1&gt;
&lt;p&gt;We‚Äôre incredibly proud of both students for their initiative, insight, and thoughtful work. Taking on open design briefs independently, and part of a dissertation, shows a deep commitment to using design for real-world impact.&lt;/p&gt;
&lt;p&gt;Their projects offered us valuable insights into how emerging designers interpret open source challenges, reminding us of the importance of clear pathways, supportive communities, and space for creative exploration. Seeing how they approached ambiguity with curiosity has reinforced our commitment to making open design more accessible, and we hope to continue building partnerships that empower the next generation of designers to shape the future of open source.&lt;/p&gt;
&lt;p&gt;We hope this experience has opened the door to future engagement with open source communities, and we encourage them to continue advocating for design in tech, sharing their work, and building on the foundations of open design!&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Interested in running a project like this?&lt;/h1&gt;
&lt;p&gt;Are you part of a university looking to bring open source design into your curriculum? &lt;a href="https://canonical.design/blog/open-design-the-opportunity-design-students-didnt-know-they-were-missing" rel="noreferrer noopener" target="_blank"&gt;We‚Äôre looking for academic partners&lt;/a&gt; who want to give students meaningful, real-world experiences while contributing to the global open source ecosystem.&lt;/p&gt;
&lt;p&gt;Reach out at &lt;a href="mailto:opendesign@canonical.com" rel="noreferrer noopener" target="_blank"&gt;opendesign@canonical.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Learn more at &lt;a href="https://canonical.design/blog/open-design-the-opportunity-design-students-didnt-know-they-were-missing" rel="noreferrer noopener" target="_blank"&gt;Canonical.design&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity"/&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Join the Canonical design team&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We‚Äôre looking for designers who care about craft and how systems work under the hood. At Canonical, design sits at the intersection of UX, engineering, and open source where we shape cohesive, accessible experiences across cloud, desktop, and IoT products.&lt;/p&gt;
&lt;p&gt;If you enjoy solving complex problems and turning technical depth into clarity, explore our open roles: &lt;strong&gt;&lt;a href="https://canonical.com/careers/web-and-design" rel="noreferrer noopener" target="_blank"&gt;canonical.com/careers&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</content:encoded><author>Miguel Divo (Miguel Divo)</author><category>Design</category><category>open design</category><category>University</category><pubDate>Fri, 13 Feb 2026 09:22:29 +0000</pubDate></item><item><title>When an upstream change broke smartcard FIPS authentication ‚Äì and how we fixed it</title><link>https://ubuntu.com//blog/when-an-upstream-change-broke-smartcard-fips-authentication-and-how-we-fixed-it</link><description>&lt;p&gt;This is the story of how Canonical&amp;#8217;s Support team provided bug-fix support: we tracked down an upstream change in OpenSC that inadvertently broke FIPS compatibility, coordinated with upstream developers across distributions, and delivered both a hotfix and a proper universal solution.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;A government agency mandated smartcard authentication across their Ubuntu fleet. When they enabled FIPS mode to meet compliance requirements, smartcard authentication stopped working. Nearly 1,000 systems sat waiting for FIPS rollout.&lt;/p&gt;
&lt;p&gt;This is the story of how Canonical‚Äôs Support team provided bug-fix support: we tracked down an upstream change in OpenSC that inadvertently broke FIPS compatibility, coordinated with upstream developers across distributions, and delivered both a hotfix and a proper universal solution.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;The setup: finding what broke&lt;/h3&gt;
&lt;p&gt;When the case first opened, the error messages looked like standard authentication failures. Nothing pointed to the root cause.&lt;/p&gt;
&lt;p&gt;Our support engineer started by replicating the issue on a Noble (24.04 LTS) test system. The pkcs11 tooling was segfaulting on Noble FIPS installations, but the same tools worked fine on Jammy (22.04 LTS). Something had changed in the OpenSC package ‚Äì the open source software toolkit for using cryptographic smartcards across various operating systems, which the government agency used for authentication ‚Äì between Ubuntu 22.04 LTS and 24.04 LTS. But what?&lt;/p&gt;
&lt;p&gt;Within days, we‚Äôd narrowed the problem to changes in the upstream OpenSC codebase, ruling out conflicts with our FIPS implementation. An upstream change in how OpenSC handled provider initialization was causing crashes when it tried to interact with OpenSSL in FIPS mode.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;The investigation: confirming the root cause&lt;/h3&gt;
&lt;p&gt;We filed upstream bug reports with both OpenSSL and OpenSC to see if they had insights. Then we kept debugging.&lt;/p&gt;
&lt;p&gt;The breakthrough came quickly: the FIPS OpenSSL provider was being initialized incorrectly. OpenSC was setting the wrong OpenSSL provider in its backend, using the default provider instead of the FIPS provider, which blocked the hashing mechanisms needed for smartcard authentication.&lt;/p&gt;
&lt;p&gt;We built a test to confirm this was the actual root cause. The customer tested it in their environment. It worked.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This is the challenge of managing upstream dependencies in enterprise Linux: OpenSC had evolved its provider handling between releases, introducing behavior that broke FIPS compatibility. An upstream development decision had unintended consequences in specific compliance contexts.¬†&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Enterprise bug-fix support bridges this gap: identifying which upstream change caused the regression, understanding why, and coordinating a universal fix.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;The fix: unblock now, solve fully later&lt;/h3&gt;
&lt;p&gt;Working with OpenSC maintainers, we reached the final diagnosis: upstream changes to OpenSC meant it now attempts to load an algorithm disallowed under FIPS policy. OpenSSL correctly returns a NULL pointer, but OpenSC still tries to use it as a valid object. Instead of gracefully handling the situation ‚Äì trying different crypto options or querying what‚Äôs available ‚Äì it errors out.&lt;/p&gt;
&lt;p&gt;We shared a hotfix ‚Äì a common practice to restore functionality in our enterprise bug-fix support service ‚Äì¬†to unblock the customer so they could move forward with their FIPS rollout.&lt;/p&gt;
&lt;p&gt;But a hotfix isn‚Äôt the same as a comprehensive fix. This needed a solution that worked upstream ‚Äì fixing the issue in OpenSC itself so it would work across Ubuntu and any other distribution using OpenSC in FIPS environments, not just a distro-specific patch.&lt;/p&gt;
&lt;p&gt;This week, we agreed on the shape of the final fix. The upstream PR is waiting to merge. Once that‚Äôs done, we‚Äôll backport it to Ubuntu. This will resolve all three customer cases we‚Äôve seen with the same root cause.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;The key ingredient: collaboration across the ecosystem&lt;/h3&gt;
&lt;p&gt;Dariusz Gadomski, a member of our Support team who worked on this case, reflected on what made it work:&lt;/p&gt;
&lt;figure class="wp-block-pullquote"&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;I really like how this case brought different groups together. Even though we come from different backgrounds, we all had the same goal: fixing the problem for our users. This is the real power of open source: people working together as one team to build better software for everyone.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/figure&gt;
&lt;p&gt;Fixing this bug involved coordination across support engineering, Canonical‚Äôs security team, and the OpenSC upstream community. What appeared as an authentication failure was an upstream change to provider initialization that broke FIPS compatibility. The diagnosis demanded understanding how OpenSC, OpenSSL, and FIPS mode interact across versions, then collaborating with upstream maintainers to develop a universal solution.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Learn more about bug-fix support through Ubuntu Pro + Support&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/what-is-linux-support"&gt;Read more about what Linux support actually means&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/support"&gt;Explore Ubuntu Pro + Support options&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/support/contact-us?product=support-overview"&gt;Get in touch to discuss your specific needs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Lidia Luna Puerta (Lidia Luna Puerta)</author><category>Bug-fix support</category><category>Enterprise Support</category><category>FIPS</category><pubDate>Thu, 12 Feb 2026 13:36:21 +0000</pubDate></item><item><title>Open platforms, edge AI, and sovereign telco clouds: Ecrio &amp;#038; Canonical at MWC Barcelona</title><link>https://ubuntu.com//blog/open-platforms-edge-ai-and-sovereign-telco-clouds-ecrio-canonical-at-mwc-barcelona</link><description>&lt;p&gt;Building telco clouds with open source At MWC Barcelona 2026, Canonical is demonstrating how telecommunications operators and enterprises can design and operate a cloud on their own terms: sovereign, cost-effective, and built on open platforms that span from core data centers to the intelligent edge. One of the demos is the result of Canonical‚Äôs collaboration [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;h1 class="wp-block-heading"&gt;Building telco clouds with open source&lt;/h1&gt;
&lt;p&gt;At MWC Barcelona 2026, Canonical is demonstrating how telecommunications operators and enterprises can design and operate a cloud on their own terms: sovereign, cost-effective, and built on open platforms that span from core data centers to the intelligent edge.&lt;/p&gt;
&lt;p&gt;One of the demos is the result of Canonical‚Äôs collaboration with Ecrio, a leader in AI-powered critical communication software optimized for private mobile and edge deployments. Ecrio Edge AI Communication Platform is an end-to-end platform that combines edge AI and communications to enable rapid human oversight where automation alone falls short. The platform delivers actionable and distributed inferencing, intelligent human-to-machine communications, and full support for generative and agentic AI, with a companion app for rugged phones, tablets, and smart glasses for human escalation.&lt;/p&gt;
&lt;p&gt;Our demo with Ecrio showcases a compact and ruggedized edge cloud deployment which combines networking and AI resources to serve real-world use cases such as worker safety and crowd management. Together, Canonical and Ecrio are showcasing how cloud-native, open-source infrastructure enables modern telco services while preserving operator control, flexibility, and long-term sustainability.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/engage/canonical-at-mwc-barcelona-2026"&gt;Visit Canonical‚Äôs booth (Hall 2, stand 2D20)&lt;/a&gt; to see a real-world telco cloud stack in action, integrating open infrastructure, edge AI, and mission-critical communications.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;A cloud on your own terms&lt;/h2&gt;
&lt;p&gt;Telecommunications operators face increasing pressure to modernize infrastructure while avoiding vendor lock-in, controlling costs, and meeting sovereignty requirements. This demo demonstrates how Canonical addresses these challenges with a hardened, long-term supported open source foundation consisting of Ubuntu, the securely designed, enterprise-grade operating system for telco workloads, and Canonical Kubernetes, the production-grade platform for cloud-native network functions and AI applications.&lt;/p&gt;
&lt;p&gt;Together, Ubuntu and Canonical Kubernetes form the backbone of an open telco cloud architecture that gives operators the freedom to deploy, scale, and evolve their networks on their own terms, across public cloud, private cloud, and edge environments.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Cloud-native edge AI communications with Ecrio&lt;/h2&gt;
&lt;p&gt;Running on Ubuntu and Canonical Kubernetes, Ecrio‚Äôs Edge AI Communication platform demonstrates how critical communication services can be delivered using modern, cloud-native architectures. Ecrio‚Äôs solution provides 3GPP standards-compliant voice and video calling, messaging, mission-critical push-to-talk capabilities, and AI-driven orchestration and analytics designed for edge and private mobile networks.&lt;/p&gt;
&lt;p&gt;Built on a modular architecture, the platform includes an MCP-based AI Workload Orchestrator to enable sophisticated automation workflows which use connected cameras, industrial IoT sensors, and Enterprise data. The platform serves a wide range of industries ‚Äì including oil and gas, mining, chemicals, manufacturing, retail, utilities, healthcare, and more ‚Äì driving efficiency, safety, and innovation at scale.&lt;/p&gt;
&lt;p&gt;Enabled by Canonical‚Äôs open infrastructure software, Ecrio shows how communication platforms can be deployed consistently from the core to the edge, fully integrated with modern cloud-native workflows.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Edge AI and ecosystem demos at MWC&lt;/h2&gt;
&lt;p&gt;The joint demo emphasizes practical, production-ready edge AI use cases, highlighting how open-source infrastructure accelerates innovation across the telco ecosystem. Live demonstrations at Canonical‚Äôs booth include real-time video analytics at the edge, workplace safety monitoring and situational awareness, and AI-driven operational intelligence across distributed environments.&lt;/p&gt;
&lt;p&gt;Ecrio‚Äôs communication and orchestration layers complement these scenarios, illustrating how AI-powered human-machine communication fits naturally into a broader telco cloud and edge AI architecture.&lt;/p&gt;
&lt;p&gt;This integrated approach enables operators to deploy intelligent services closer to users while maintaining a consistent, open platform across the entire network.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Build your cloud with Canonical&lt;/h1&gt;
&lt;p&gt;As demonstrated at MWC Barcelona this year, the combination of Canonical‚Äôs open source cloud infrastructure with Ecrio‚Äôs edge-optimized communication services represents a new generation of telco cloud stacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sovereign by design&lt;/li&gt;
&lt;li&gt;Extensible through open ecosystems&lt;/li&gt;
&lt;li&gt;Cost-efficient without sacrificing performance or security&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With Canonical‚Äôs trusted open source, operators and enterprises can modernize network operations, enable private 5G and edge cloud deployments, and unlock new AI-driven services without surrendering control of their technology stack.&lt;/p&gt;
&lt;p&gt;To learn more about this project or how you could benefit, visit Canonical‚Äôs booth at MWC Barcelona 2026 in Hall 2, 2D20 or &lt;a href="https://canonical.com/solutions/telco#get-in-touch"&gt;contact us&lt;/a&gt; for more information.&lt;/p&gt;
</content:encoded><author>Benjamin Ryzman (Benjamin Ryzman)</author><pubDate>Thu, 12 Feb 2026 13:12:34 +0000</pubDate></item><item><title>What is RDMA?</title><link>https://ubuntu.com//blog/what-is-rdma</link><description>&lt;p&gt;Modern data centres are hitting a wall that faster CPUs alone cannot fix. As workloads scale out and latency budgets shrink, the impact of moving data between servers is starting to become the most significant factor in overall performance. Remote Direct Memory Access, or RDMA, is one of the technologies reshaping how that data moves, [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Modern data centres are hitting a wall that faster CPUs alone cannot fix. As workloads scale out and latency budgets shrink, the impact of moving data between servers is starting to become the most significant factor in overall performance. Remote Direct Memory Access, or RDMA, is one of the technologies reshaping how that data moves, and it forces a rethink of some long-held assumptions in data centre networking.&lt;/p&gt;
&lt;p&gt;This article is the first in a short series. The follow-ups will look specifically at the two primary network interconnects that enable RDMA, InfiniBand and RoCE. Here, the goal is simpler: explain what RDMA is, why it matters now, and why it can be both powerful and uncomfortable for operators.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Remote Direct Memory Access explained&lt;/h2&gt;
&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Remote Direct Memory Access (RDMA) is a data center networking technology that allows servers to exchange data directly between application memory spaces over the network, bypassing the operating system and CPU on the remote side. This enables lower latency, higher throughput, and more predictable performance compared to traditional TCP/IP networking.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;At its core, RDMA lets one machine read from or write directly into the memory of another machine over the network, without involving the remote CPU or operating system in the data path.&lt;/p&gt;
&lt;p&gt;In a conventional TCP/IP exchange, even a fast one, data is copied multiple times. It moves from the NIC into kernel buffers, through the network stack, into user space, and back again on the other side. Each step adds latency, burns CPU cycles, and introduces jitter.&lt;/p&gt;
&lt;p&gt;RDMA removes most of that path. Once a connection is set up and memory is registered, the NIC performs the transfer directly between application memory regions. The remote CPU is not interrupted. The kernel is not traversed. The result is very low latency, very high throughput, and far more predictable performance.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;‚û§ RDMA implements kernel bypass and zero-copy networking, avoiding the overheads inherent in TCP/IP-based data center networks.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is not magic, and it is not free. RDMA shifts responsibility away from the operating system and towards the application and the network. That shift is where both the value and the challenge lie.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Why RDMA matters for modern data center networking&lt;/h2&gt;
&lt;p&gt;RDMA is not new. High-performance computing (HPC) has used it for decades. What has changed is where the bottlenecks now sit for communication service providers (CSPs) and large enterprises.&lt;/p&gt;
&lt;p&gt;Telco clouds, core network functions, analytics pipelines, and AI workloads all rely on intensive server-to-server communication. This east-west traffic dominates over slower, less latency-sensitive north-south flows between the data centers and the Internet. When every microsecond matters, shaving tens of microseconds from each exchange compounds quickly.&lt;/p&gt;
&lt;p&gt;Second, CPUs are expensive and increasingly scarce. Offloading data movement from general-purpose cores frees capacity for actual packet processing, encoding, inference, or control-plane logic. Operators deploying UPFs, databases, or message buses at scale see this immediately in reduced core counts per workload.&lt;/p&gt;
&lt;p&gt;Third, determinism matters more than peak throughput. Many telco and real-time enterprise applications care less about average latency and more about tail latency. RDMA‚Äôs bypass of the kernel scheduler and TCP congestion machinery produces tighter latency distributions, which directly translates into more predictable service behaviour.&lt;/p&gt;
&lt;p&gt;This is why RDMA is showing up in modern storage backends, distributed databases, AI training clusters, and increasingly in network-intensive telco workloads. In practice, adopting RDMA is less about enabling a feature in a workload and more about designing the data centre fabric, host configuration, and lifecycle operations to support predictable low-latency behaviour.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;RDMA vs TCP/IP: how data center networking is changing&lt;/h2&gt;
&lt;p&gt;The most important difference is philosophical.&lt;/p&gt;
&lt;p&gt;Traditional Ethernet networking assumes the network is unreliable and the hosts are responsible for recovery. TCP embodies this model. It is flexible, forgiving, and remarkably robust, but it hides performance costs behind abstraction.&lt;/p&gt;
&lt;p&gt;RDMA assumes a far more cooperative environment. Memory must be explicitly registered. Access permissions are managed at connection setup. Packet loss is expected to be rare, not normal. Reliability is often handled below or beside TCP, or avoided entirely.&lt;/p&gt;
&lt;p&gt;From an operator perspective, this means that the network stops being ‚Äújust IP‚Äù. Latency, loss, buffering, and congestion behaviour suddenly matter in very concrete ways. A misconfigured switch buffer or an oversubscribed link that TCP would eventually recover from can stall or break an RDMA workload.&lt;/p&gt;
&lt;p&gt;It also means that debugging shifts. Problems that used to be visible in system call traces or kernel metrics may now live in NIC counters, fabric telemetry, or application-level error paths.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;How CSPs and enterprises use RDMA in real data centers&lt;/h2&gt;
&lt;p&gt;In large telco clouds, RDMA is increasingly used underneath control-plane databases and state stores. Distributed shared memory databases, and message buses backed by RDMA-enabled transports have the potential for lower commit latencies under load. The practical effect is faster convergence during scaling events and fewer cascading timeouts during failures.&lt;/p&gt;
&lt;p&gt;In enterprise data centres, storage is often the first visible win. NVMe over Fabrics using RDMA allows storage traffic to achieve local-disk-like latency over the network. Operators see higher IOPS with fewer CPU cores consumed on both the compute and storage sides.&lt;/p&gt;
&lt;p&gt;AI infrastructure provides another clear example. GPU-to-GPU communication during training is extremely sensitive to latency and jitter. RDMA allows collective operations to scale across nodes without saturating host CPUs, which is why it has become foundational in large training clusters.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/blog/canonical-kubernetes-enhances-ai-ml-development-capabilities-with-nvidia-integrations"&gt;Explore GPU‚ÄëDirect RDMA in Kubernetes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Across all of these environments, the pattern is the same. RDMA does not merely make things faster. It changes which resources are stressed and where failures surface.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;RDMA challenges in data center networks&lt;/h2&gt;
&lt;p&gt;RDMA is unforgiving of sloppy networks. Packet loss, excessive buffering, and uncontrolled congestion can have disproportionate impact, so fabric design and validation matter more than ever.&lt;/p&gt;
&lt;p&gt;Operational tooling is often immature compared to decades of TCP observability. Teams need to be comfortable with NIC-level metrics, switch telemetry, and application-specific diagnostics.&lt;/p&gt;
&lt;p&gt;In real operator environments, many RDMA issues surface before the workload is even deployed. Inconsistent NIC firmware versions, mismatched PCIe settings, incorrect NUMA alignment, or missing kernel modules can silently degrade performance. This is why RDMA adoption tends to push operators towards tighter control of bare-metal provisioning and hardware lifecycle management, rather than treating servers as interchangeable units. Platforms that standardise bare-metal commissioning, firmware baselines, and kernel configuration, such as MAAS, become critical enablers for running RDMA reliably at scale.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/blog/data-centre-ai-evolution-combining-maas-and-nvidia-smartnics"&gt;Read more about RDMA and AI networking challenges and solutions.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Finally, RDMA tightens coupling between applications and infrastructure. Memory registration, queue depths, and transport choices leak into application design. This is acceptable when performance is critical, but it reduces portability and increases the cost of mistakes.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Closing thoughts&lt;/h2&gt;
&lt;p&gt;RDMA challenges the comfortable abstraction layers that have served data centres well for years. It trades generality for performance, and flexibility for determinism. For CSPs and enterprises building modern, scale-out infrastructure, that trade-off is increasingly justified.&lt;/p&gt;
&lt;p&gt;Understanding RDMA is no longer optional for architects working on high-performance telco clouds or data-intensive platforms. The question is not whether it will appear in your environment, but whether you will be ready for the architectural and operational consequences when it does.&lt;/p&gt;
&lt;p&gt;Are you interested in Canonical products supporting RDMA? &lt;a href="https://canonical.com/solutions/telco#get-in-touch"&gt;Contact our experts&lt;/a&gt; today.&lt;/p&gt;
</content:encoded><author>Benjamin Ryzman (Benjamin Ryzman)</author><category>AI</category><category>HPC</category><category>networking</category><pubDate>Wed, 11 Feb 2026 11:07:57 +0000</pubDate></item><item><title>Building new revenue streams: 3 strategic cloud opportunities for telcos in 2026</title><link>https://ubuntu.com//blog/new-telco-cloud-opportunity</link><description>&lt;p&gt;PWC claimed the &amp;#8216;fundamental challenge&amp;#8217; behind slowing growth is that telecom‚Äôs &amp;#8216;core products and services&amp;#8217; are &amp;#8216;becoming commodities.&amp;#8217; The way forward lies in modernizing and diversifying: evolving from traditional telecommunications to &amp;#8216;techco&amp;#8217; (technology company) services. In 2026, many of these opportunities will come from cloud computing.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;The telecommunications industry is at a turning point: telcos are seeking ways to turn innovation into new opportunities. Looking at the data, the desire is easy to understand. &lt;a href="https://www.pwc.com/gx/en/industries/tmt/assets/pwc-perspectives-from-the-global-telecom-outlook-2024-2028.pdf"&gt;In 2023, PWC projected&lt;/a&gt; that the sector‚Äôs annual growth rate would slow significantly between 2024 and 2028. PWC claimed that the ‚Äúfundamental challenge‚Äù behind this trend was that telecom‚Äôs ‚Äúcore products and services‚Äù, like fixed broadband service and mobile service, ‚Äúare becoming commodities.‚Äù This means that prices remain stagnant, while the industry ‚Äúfaces a continual need to invest in infrastructure.‚Äù Slower projected growth in revenue was particularly noticeable in mature markets. PWC is not alone with its growth projections: Analysys Mason predicted &lt;a href="https://www.analysysmason.com/research/content/regional-forecasts-/global-telecoms-forecast-rddg0/"&gt;CAGR growth of only 1% between 2024 and 2029&lt;/a&gt;.¬†&lt;/p&gt;
&lt;p&gt;For many, the way forward lies in modernizing and diversifying from their core offerings: evolving from traditional telecommunications to ‚Äútechco‚Äù (technology company) services. These offerings focus on value added digital services that are client-centric, capitalizing on the established strengths of telecoms. In 2026, many of these opportunities will come from cloud computing.&lt;/p&gt;
&lt;p&gt;In advance of &lt;a href="https://ubuntu.com/engage/canonical-at-mwc-barcelona-2026"&gt;MWC 2026&lt;/a&gt;, this article will consider the issue in more depth, outline some of the strategies that telecoms are taking, and explain how ‚Äì and why ‚Äì open source solutions are more important than ever in the conversation.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Strategy one: regional sovereign clouds&lt;/h2&gt;
&lt;p&gt;Geopolitical turbulence and changing legislation have both resulted in organizations increasingly seeking data sovereignty strategies, which we cover in greater depth in ‚Äú&lt;a href="https://ubuntu.com/engage/sovereign-cloud-guide?_gl=1*1kq1shq*_gcl_au*MTQ1MTcwMTUxLjE3NjI3NzE5Mzc."&gt;Sovereign clouds: the essential guide for enterprises&lt;/a&gt;.‚Äù While public cloud vendors are starting to offer sovereign cloud solutions, many organizations would prefer to rely on local or regional clouds to gain more autonomy.¬†&lt;/p&gt;
&lt;p&gt;Some organizations will be motivated to build their own on-premises sovereign clouds to host workloads and achieve digital sovereignty, but not every organization can ‚Äì or should ‚Äì do so. This leaves an interesting opportunity for telecommunications vendors, who can build fully open source, cost-effective private clouds using platforms such as &lt;a href="https://canonical.com/openstack"&gt;Canonical OpenStack&lt;/a&gt; to set up regional sovereign clouds.¬†&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What makes telecoms a natural fit for the sovereign cloud opportunity?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Geography&lt;/strong&gt;: since telecommunications providers typically operate as domestic entities, they are subject to regional legal frameworks. This alignment minimizes the likelihood of conflicting regulations and reduces overall compliance risk. Likewise, this makes local telecoms the natural choice for public sector data and workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trust&lt;/strong&gt;: telecoms can benefit from their strong local presence. These organizations have often built familiarity and trust over time with both customers and local governments in their region, providing a comparatively strong commercial position from which to offer regional sovereign cloud services.¬†&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Existing infrastructure&lt;/strong&gt;: telecoms have the unique advantage of a vast footprint of existing infrastructure. This established presence offers a distinct competitive advantage: it is often significantly faster and more cost-effective to retro-fit these facilities for sovereign cloud operations, than it is for competitors to construct new facilities from the ground up.¬†&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While orchestrating workloads within a regional sovereign cloud is essential, it can often be a complex and demanding task. Kubernetes streamlines this, by providing a layer that makes applications portable across clouds, requiring minimal adaptations or configuration changes. Kubernetes is more nimble than monolithic architectures, and forms the starting point for digital transformation. Canonical offers security maintenance and updates for &lt;a href="https://ubuntu.com/kubernetes"&gt;Canonical Kubernetes &lt;/a&gt;for up to 15 years as part of our Long Term Support (LTS) commitment. This means that organizations can plan their IT lifecycle in advance, and avoid the sudden costs of unexpected migrations.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Strategy two: generative AI (GenAI) factories&lt;/h2&gt;
&lt;p&gt;GenAI has become firmly established in the workflows of an increasing number of organizations. With this comes the need for ‚ÄúAI factories‚Äù: specialized data centers that can turn raw data into AI models at scale. The capital expenditure of the high-performance hardware and software needed to run AI factories effectively ‚Äì to ingest huge amounts of data, network at high speeds, and support AI training workloads ‚Äì is an obstacle to building private AI factories on premises for most organizations. Instead, enterprises are looking to outsource the compute required to build models. This edge cloud opportunity also provides telecoms a new potential stream of revenue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How can telcos lead the GenAI factory wave?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Inference at the edge: the pre-existing infrastructure that presents telecoms with a strong position from which to offer regional sovereign clouds also provides a competitive edge for moving into AI factories. As GenAI models shift from training to inference, telecoms‚Äô pre-existing distributed infrastructure means that they can process sensitive data at the edge of the network, providing ultra-low latency required for highly efficient processing. This is particularly critical for AI that relies on instantaneous ‚Äì or near instantaneous ‚Äì speed, like agentic AI.¬†&lt;/li&gt;
&lt;li&gt;Sovereign AI: much like sovereign clouds, there is a growing demand globally for LLMs that reflect local culture, values, legislation, and languages. Regionally based telecoms can provide trusted national infrastructure to host sovereign LLMs.&lt;/li&gt;
&lt;li&gt;Private AI Enclaves: telecoms can offer ‚ÄúGenAI-as-a-Service‚Äù over a private network slice. This ensures that an organization‚Äôs proprietary data used to fine-tune a model never traverses the public internet, providing a level of security that major public cloud vendors cannot match without a complex VPN setup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Building a GenAI factory demands a cutting-edge software stack ‚Äì however, with such cutting-edge software comes brand-new security challenges. As &lt;a href="https://ubuntu.com/engage/2025-state-of-software-supply-chain"&gt;our recent report with IDC&lt;/a&gt; indicated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;43% of organizations are ‚Äúvery‚Äù or ‚Äúextremely‚Äù concerned about their ability to secure their AI stack&lt;/li&gt;
&lt;li&gt;60% have only basic, or no, security controls to safeguard their AI/ML systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This creates serious risks around data and security. Safely mitigating these is critical for telecoms to grasp the GenAI factory opportunity effectively.¬†&lt;/p&gt;
&lt;p&gt;Through our data and AI portfolio, Canonical helps organizations mitigate security risks as well as simplify the deployment and maintenance of AI models through automated workflows, security patching, and tooling integrations. This ensures that organizations can access trusted, supported ML and AI applications. Find out more on our &lt;a href="https://canonical.com/solutions/ai/infrastructure"&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Strategy three: smart factories&lt;/h2&gt;
&lt;p&gt;Telecoms have become the primary enablers of a growing phenomenon: smart factories. Smart factories are highly digitized and connected production facilities. Unlike traditional factories, which rely on fixed assembly lines and manual troubleshooting, smart factories optimize manufacturing through constant feedback loops of data, using these to run themselves with minimal human intervention.¬†&lt;/p&gt;
&lt;p&gt;Smart factories require thousands of sensors, tracking each element of the manufacturing process. This is then translated into a digital twin ‚Äì a real-time virtual 3-D replica of the factory. Changes to the physical world ‚Äì communicated through the sensors ‚Äì are reflected in the digital model. AI models analyze the data provided by sensors to identify patterns and alert factory managers to issues that require their attention. For example, predicting that a motor will fail before it does. In a traditional factory set up, this would require manual labour and time-intensive troubleshooting to fix; in a smart factory, issues are solved much faster.¬†&lt;/p&gt;
&lt;p&gt;For these elements to come together effectively and successfully, smart factories require industrial connectivity ‚Äì the ultra low-latency speeds of private 5G networks. It is this aspect which provides telcos an advantage in harnessing the smart factory cloud opportunity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What gives telcos the edge in powering smart factories?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Private 5G: public Wi-Fi is too interference prone for smart factories to run on. Telecoms can carve a slice of their already-licensed 5G spectrum exclusively for factories, ensuring the greater reliability of connection necessary for smart factories to run efficiently. This carries a significant premium, which can be a lucrative stream of revenue for telecoms.¬†&lt;/li&gt;
&lt;li&gt;Quality on demand: while a system integrator can, for example, build the applications that the smart factory runs on, telecoms own the Network APIs. Because of this, only telecoms have the power to reconfigure the network in real-time, and thus offer quality on demand APIs, ensuring that the factory‚Äôs connectivity is never lost.¬†&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The missing piece of the puzzle for telecoms in this opportunity is getting support for edge systems, which smart factories depend on. Canonical‚Äôs edge portfolio is designed to support your systems‚Äô security, whilst easily managing and governing your edge infrastructure. &lt;a href="https://ubuntu.com/core"&gt;Ubuntu Core&lt;/a&gt;, our operating system for internet of things (IoT), devices, and embedded systems, features a minimized attack surface and a variety of measures which help to reduce the risk of security breaches. Likewise, &lt;a href="https://ubuntu.com/landscape?_gl=1*117tt2d*_gcl_au*MTQ1MTcwMTUxLjE3NjI3NzE5Mzc."&gt;Canonical Landscape&lt;/a&gt; simplifies managing the thousands of IoT devices needed to run a smart factory by enabling over the air (OTA) updates and automating compliance tasks across your Ubuntu estate. Find out more about our edge portfolio on our &lt;a href="https://canonical.com/solutions/infrastructure/edge-computing"&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Smart factories rely on huge amounts of data. That makes supporting and securing databases critical ‚Äì downtime could cause a physical bottleneck, and equipment damage. Such support can be expensive, however, Canonical offers both security and support for databases under the same Ubuntu Pro subscription, reducing costs and enabling telcos to offer value-added services with open source data solutions. Find out more about our database offering on the &lt;a href="https://canonical.com/data"&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Supporting your investment&lt;/h2&gt;
&lt;p&gt;To engage with any of these new streams of revenue, telecoms‚Äô underlying software stack will become of critical importance.¬†&lt;/p&gt;
&lt;p&gt;Proprietary ‚Äúblack-box‚Äù systems don‚Äôt offer the levels of cost-effectiveness, transparency, and agility telecoms need to remain competitive and future-proof their investments. Open source gives telcos the modular agility and transparency needed to turn emerging technologies into profitable services.¬†&lt;/p&gt;
&lt;p&gt;Canonical‚Äôs trusted &lt;a href="https://canonical.com/solutions/infrastructure"&gt;open source infrastructure solutions&lt;/a&gt; are modular, offering supported software elements that telcos can use to build frameworks that are customized to their individual needs. On top of that, we optimize our solutions for silicon and offer them on a large variety of hardware, thanks to our collaboration with the world‚Äôs leading silicon and hardware vendors.&lt;/p&gt;
&lt;p&gt;Many open source projects are complex to manage, particularly at a large scale. Canonical offers long-term support (LTS) for up to 15 years for our open source software, ensuring that your investment is sustainable in the long term. Likewise, through our &lt;a href="https://ubuntu.com/managed/firefighting-support"&gt;professional support offering&lt;/a&gt;, our global team of experts is on call 24/7 to ensure that if you run into a problem, we‚Äôre there to help.¬†&lt;/p&gt;
&lt;p&gt;The opportunity for growth is clear. By combining their inherent physical advantages with a securely-designed, supported, and open software foundation, telecoms can move beyond the limits of commoditized connectivity and break into new streams of revenue, new industries, and new technologies.¬†&lt;/p&gt;
&lt;p&gt;Find out more about Canonical‚Äôs telco solutions on our &lt;a href="https://canonical.com/solutions/telco"&gt;webpage&lt;/a&gt;, or meet us in person &lt;a href="https://ubuntu.com/engage/canonical-at-mwc-barcelona-2026"&gt;at MWC in 2026&lt;/a&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Further resources:&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical.com/blog/bt-group-and-canonical-deliver-5g-to-uk-stadiums"&gt;BT Group and Canonical deliver 5G to UK stadiums&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canonical.com/blog/how-telco-companies-can-reduce-5g-infrastructure-costs-with-modern-open-source-cloud-native-technologies"&gt;How telco companies can reduce 5G infrastructure costs with modern open source cloud-native technologies&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canonical.com/blog/bringing-canonical-kubernetes-to-sylva-a-new-chapter-for-european-telco-clouds"&gt;Bringing Canonical Kubernetes to Sylva: a new chapter for European telco clouds&lt;/a&gt;&lt;/p&gt;
</content:encoded><author>Isobel Kate Maxwell (Isobel Kate Maxwell)</author><category>cloud</category><category>genai</category><category>Sovereign cloud</category><category>Telco</category><pubDate>Tue, 10 Feb 2026 15:52:38 +0000</pubDate></item><item><title>SQL Server 2025 is generally available on Ubuntu 24.04 LTS</title><link>https://ubuntu.com//blog/sql-server-2025-ubuntu-24-04-lts</link><description>&lt;p&gt;Microsoft has announced the General Availability of SQL Server 2025 on Ubuntu 24.04 LTS. Learn about the new CU1 features, including OS-level observability, Contained Availability Groups, and native vector support for enterprise workloads.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Microsoft has announced the General Availability (GA) of SQL Server 2025 on Ubuntu 24.04 LTS, starting with the CU1 release. This milestone allows enterprises to deploy mission-critical workloads on our latest Long Term Support release, benefiting from predictable stability and up-to-date kernels.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Update your repository&lt;/h3&gt;
&lt;p&gt;If you have been testing the preview version, you must switch your repository configuration to ensure you are on the production track. To switch your repository configuration, update your source from mssql-server-preview.repo to mssql-server-2025.repo. Continuing to use the preview repository may result in installing pre-release builds that are not intended for production workloads.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Enhancements for Linux&lt;/h3&gt;
&lt;p&gt;SQL Server 2025 CU1 introduces specific improvements for managing databases on Linux infrastructure.&lt;/p&gt;
&lt;p&gt;New Dynamic Management Views (DMVs) now expose OS-level metrics directly to database administrators. Views such as sys.dm_os_linux_cpu_stats and sys.dm_os_linux_disk_stats help distinguish between database-specific bottlenecks and infrastructure issues. The release also includes sys.dm_os_linux_net_stats, which provides real-time network interface statistics to troubleshoot connectivity and throughput.&lt;/p&gt;
&lt;p&gt;We also see improvements in Contained Availability Groups (CAG). Administrators can now enable database creation and restoration directly within a CAG session using sp_set_session_context. This simplifies lifecycle operations while maintaining strict access controls: only users with the dbcreator role can create databases, while the db_owner or sysadmin roles are required for restoration.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;AI capabilities&lt;/h3&gt;
&lt;p&gt;This release also brings native vector support for machine learning applications. To learn how to build a secure AI playground with these new capabilities, read our technical guide, &lt;a href="https://ubuntu.com/blog/sql-server-2025-on-ubuntu"&gt;AI meets SQL Server 2025 on Ubuntu.&lt;/a&gt;&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Enterprise security&lt;/h3&gt;
&lt;p&gt;For organizations with strict compliance requirements, Ubuntu Pro is the preferred choice. It extends the standard LTS security coverage to the full software stack covered in Universe and offers FIPS compliance, which is critical for many regulated SQL Server workloads.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/azure/pro"&gt;Learn more about Ubuntu Pro for Azure ‚Ä∫&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can install the production-ready version of SQL Server 2025 on Ubuntu 24.04 today by following the &lt;a href="https://learn.microsoft.com/en-us/sql/linux/quickstart-install-connect-ubuntu"&gt;official installation guide&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Jehudi (Jehudi)</author><category>Database</category><category>Microsoft</category><category>Microsoft Azure</category><category>SQL Server</category><pubDate>Fri, 06 Feb 2026 15:41:36 +0000</pubDate></item><item><title>Hiring the Canonical way: trust, humanity, and remote-first thinking</title><link>https://ubuntu.com//blog/hiring-the-canonical-way</link><description>&lt;p&gt;Discover the human-centric hiring philosophy at Canonical. Learn how the makers of Ubuntu prioritize remote-first talent, human-led CV reviews, and finding the right role for your unique impact. Explore the career with us!&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Daniele Procida (Director of Engineering) recently shared a practical guide on &lt;a href="https://canonical.com/blog/how-to-get-a-job-at-canonical"&gt;how to get a job at Canonical&lt;/a&gt;. It is an excellent resource for anyone navigating our hiring process. I wanted to build on that and share the philosophy behind those steps. As the Chief of Staff for software engineering, I see how our values shape every hiring decision we make.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Humanity as a hiring principle&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Canonical is the publisher of Ubuntu, one of the world‚Äôs most popular open-source Linux distributions. The name ‚ÄúUbuntu‚Äù comes from an African philosophy that translates to ‚ÄúI am what I am because of who we all are.‚Äù For our operating system, this means technology should be accessible to everyone and empower people rather than exclude them.&lt;/p&gt;
&lt;p&gt;We apply this same principle to our hiring. We are a truly remote company because we believe talent isn‚Äôt bound by a certain geography. If we want software to be accessible to everyone, our career opportunities must be too. Great team members are those who don‚Äôt need an office to feel driven, they are motivated by the mission itself. We are willing to find the right place for the right people, regardless of where they are in the world.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Work that matters, at a scale that counts&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;When an organization is growing, it‚Äôs important to ensure that each new hire can have an impact. A growing organization shouldn‚Äôt make it harder for an individual to make their mark. At Canonical, we‚Äôre looking for people who won‚Äôt just fit into the organization, but who will challenge the way things are done.¬†&lt;/p&gt;
&lt;p&gt;At Canonical, we believe that impact and potential are the true drivers of career progression. My own journey illustrates how the company looks beyond conventional industry templates to find the right person for the right challenge. I joined the company at 28, with five years of experience (and rapid career growth!), as the Chief of Staff for the entire engineering organization. In most companies, a role of this scope is reserved for those meeting predefined experience thresholds.&lt;/p&gt;
&lt;p&gt;When I applied, it was for a Director of DevOps role. However, during the process, my Hiring Lead identified a more strategic need. Canonical was transitioning from a scale-up to an enterprise, and we needed to ensure that our 50 engineering teams were all on the same page, with the same goals, speaking the same language. This is a challenge for any growing organization, but because I had experience aligning large teams in my previous role, Canonical chose to trust that vision and capability.&lt;/p&gt;
&lt;p&gt;Since then, we have scaled from 600 to 950 engineers. We replaced the argument of ‚Äúit has always been this way‚Äù with unified standards and a predictable cadence. This approach also ensures we hire open-minded people who aren‚Äôt set in their ways. It‚Äôs important that candidates bring experience, but are still happy to challenge the way things are done.¬†&lt;/p&gt;
&lt;p&gt;My role was not to impose a generic industry framework, but to find the best ways of working for Canonical‚Äôs specific context. We value sharp minds and high energy because, in a fast-paced environment, the ability to find a better option is more impactful than just following a traditional playbook.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Small teams, big impact&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Our CEO, Mark Shuttleworth, envisions Canonical as the ‚Äúbest little software company in the world.‚Äù What this means in practice is that you don‚Äôt have to be a huge company to have a far-reaching impact in the world. We intentionally organize our 950-strong engineering force into powerful, nimble squads that prioritize agility and deep expertise over organizational layers. In our culture, everyone is an expert in their field. By choosing depth over speed and strong signal over high volume, we create a space for those who are ready to go the extra mile for their colleagues. This ensures that you wake up eager to collaborate with and learn from exceptional peers.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;A human approach to screening&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We do not use automated systems to screen your application. We believe that hiring needs to be fair, and that algorithms can reinforce hidden biases. Instead, hiring leads and associates review every CV manually.&lt;/p&gt;
&lt;p&gt;When you apply, we look closely at your answers to our application questions. If your answers are informative and reflect clear thinking, we progress you to the next stage and give you the chance to show your skills and give some context to your CV.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Finding the right home for talent&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Recognizing individual potential is central to how we work. We don‚Äôt just see the role you applied for. We look for the best place for your talents to thrive within our community. Applying for the ‚Äúwrong‚Äù role is not a disqualification. If we see potential that matches our core principles, but not necessarily the role you applied for, we will redirect you. We do not lower the¬† bar, but we do invest time in finding the right fit for strong candidates.&lt;/p&gt;
&lt;p&gt;We have seen engineers apply for a specific product team, only to find a far more significant impact in a different domain where their passion and technical rigor were the missing piece of the puzzle. For instance, one engineer applied for a role in container orchestration, but we identified a stronger alignment with our distributed database team. By finding that perfect fit, they were able to thrive and eventually grow into a staff engineer role, owning the performance and correctness programs for the entire organization.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;A process designed for excellence&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Our hiring process is rigorous, and that is by design. We protect our culture by being deliberate, not fast. This depth of engagement is the first investment we make in your career here, ensuring you‚Äôre entering an environment where you can actually thrive.&lt;/p&gt;
&lt;p&gt;At Canonical,¬† every individual is a vital part of the whole. Our goal is to find the exact role where your expertise ‚Äúclicks‚Äù into place, ensuring that you¬† have the greatest possible impact. We are looking for that perfect alignment where your unique strengths meet our most meaningful work.&lt;/p&gt;
&lt;p&gt;The most important thing for you to know is that the people in the hiring pipeline are on your side. We lean towards giving a candidate a chance and offering them the opportunity to prove their skills, rather than being rigid in our filtering.&lt;/p&gt;
&lt;p&gt;While our process is strict, your hiring lead is often your biggest advocate. We intentionally keep the system rigorous, but we work to move promising candidates through because we want to see you succeed. We want to see how you stand out amongst your peers. If you believe you can make a real difference here, I encourage you to &lt;a href="https://canonical.com/careers"&gt;apply&lt;/a&gt;!&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Further Reading&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://canonical.com/careers"&gt;Canonical Careers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canonical.com/blog/how-to-get-a-job-at-canonical"&gt;How to get a job at Canonical&lt;/a&gt; ‚Äì A blog by Daniele Procida (Director of Engineering)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canonical.com/careers/hiring-process"&gt;Canonical hiring process&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Maksim Beliaev (Maksim Beliaev)</author><category>careers</category><pubDate>Fri, 06 Feb 2026 14:44:31 +0000</pubDate></item><item><title>SpacemiT announces the availability of¬† Ubuntu on K3/K1 series RISC-V AI computing platforms</title><link>https://ubuntu.com//blog/spacemit-announces-availability-of-ubuntu-on-k3-k1-series</link><description>&lt;p&gt;SpacemiT (Hangzhou) Technology Co., Ltd. today announced a¬† collaboration with Canonical to make¬† Ubuntu available on SpacemiT&amp;#8217;s new K3 SoC and the existing K1 series RISC-V computing platforms. This collaboration marks a deep integration between open-source operating systems and open RISC-V silicon, bringing powerful, flexible, and reliable intelligent computing solutions to developers worldwide. Hardware platforms [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;SpacemiT (Hangzhou) Technology Co., Ltd. today announced a¬† collaboration with Canonical to make¬† Ubuntu available on SpacemiT‚Äôs new K3 SoC and the existing K1 series RISC-V computing platforms. This collaboration marks a deep integration between open-source operating systems and open RISC-V silicon, bringing powerful, flexible, and reliable intelligent computing solutions to developers worldwide.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Hardware platforms designed for high-performance intelligent computing&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;SpacemiT‚Äôs new K3 series and the existing K1 series chips are built on proprietary RISC-V processor cores and integrate homogeneous AI computing capabilities. Designed for high-performance AI edge inference and AI robotics, the platforms are well suited for applications including robotics, intelligent security at the edge, industrial vision, and AI edge inference.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="1139" loading="lazy" sizes="(min-width: 1267px) 1267px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fac59%2Fimage-1.jpeg 1267w" width="1267"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Advancing intelligent computing: seamless OS integration¬†&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;With the rapid advancement of artificial intelligence, edge computing, and robotics, the market increasingly requires hardware and software platforms that deliver both strong computing performance and high development efficiency. Built on advanced RISC-V architecture and innovative system design, SpacemiT‚Äôs K3 and K1 series chips provide an ideal platform for RISC-V high-performance computing. Ubuntu, one of the world‚Äôs most widely used Linux distributions, is known for its stability, rich software ecosystem, and strong community support. The availability of¬† Ubuntu on the K3 and K1 series means developers benefit from seamless hardware-software integration as well as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Familiar environment: low barrier to entry for¬† existing Ubuntu users&lt;/li&gt;
&lt;li&gt;Ecosystem compatibility: seamless access to Ubuntu‚Äôs vast software repositories and application ecosystem&lt;/li&gt;
&lt;li&gt;Community-driven innovation: access to global Ubuntu community resources, documentation and shared expertise&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="713" loading="lazy" sizes="(min-width: 1267px) 1267px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa872%2Fimage.png 1267w" width="1267"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Introducing one of the first RVA23 compliant platforms with Ubuntu&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The RISC-V RVA23 profile, introduced in 2024, defines a mandatory set of hardware features for 64-bit processors to help facilitate a consistent software-to-hardware interface. Some of the mandatory features include vector computing for AI workloads, advanced security extensions and hypervisor support. SpacemiT‚Äôs K3 SoC is one of the first RVA23 compliant platforms available today. Canonical announced¬† &lt;a href="https://canonical.com/blog/canonical-releases-ubuntu-25-10-questing-quokka"&gt;adoption of RVA23&lt;/a&gt; as a baseline profile for RISC-V builds with the release of Ubuntu 25.10. This enables users of RVA23 compliant platforms with Ubuntu to leverage the full power of the chip out-of-the-box and gain a stable, high performing experience.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Collaborating on platform enablement¬†&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;With RVA23 compliance in mind, SpacemiT has taken the lead in enabling the Ubuntu 26.04 LTS Preview release on the K3 SoC, delivering a new RISC-V desktop experience. The enablement of Ubuntu 26.04 LTS, which will officially be released in April 2026, on the K3 chip will support RVA23-compliant computing systems and products worldwide, representing a milestone in the development of the RISC-V software ecosystem. This is expected to attract more developers and partners, accelerating ecosystem maturity with greater speed and efficiency.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="713" loading="lazy" sizes="(min-width: 1267px) 1267px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fef14%2Fimage.png 1267w" width="1267"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Ubuntu 24.04 LTS availability on SpacemiT‚Äôs existing K1 platform&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In addition to enabling Ubuntu on the new K3 chip, SpacemiT and Canonical have also collaborated to enable Ubuntu 24.04 LTS across the broader SpacemiT lineup, including the K1 MUSE Book and MUSE Pi Pro. This initiative reflects the companies‚Äô shared mission to bring a world-class Linux experience to the entire SpacemiT community.¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;A win-win collaboration to accelerate the RISC-V ecosystem&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;‚ÄúUbuntu is one of the most popular Linux distributions globally, and we are delighted to work with Canonical to bring Ubuntu to our K3/K1 intelligent computing platforms and jointly advance the open RISC-V architecture and Linux software ecosystem,‚Äù said Sun Yanbang, President of SpacemiT. ‚ÄúThis collaboration not only provides developers with a more complete technical solution, but also reflects SpacemiT‚Äôs long-term commitment to open standards and open-source ecosystems. By combining Ubuntu‚Äôs mature software ecosystem with our advanced RISC-V hardware technologies, we aim to drive innovation and growth in intelligent computing,‚Äù he added.&lt;/p&gt;
&lt;p&gt;‚ÄùSpacemiT has significantly contributed to the fast-growing RISC-V ecosystem and leading adoption of RVA23 with Ubuntu 26.04,‚Äù said Cindy Goldberg, VP of Cloud and Silicon Partnerships at Canonical. ‚ÄúWe‚Äôre delighted to work with SpacemiT to make the intelligent computing capabilities of the K3 and K1 series easily accessible to developers. Canonical is committed to amplifying the impact of open source software and making it available to users everywhere. The collaboration with SpacemiT aligns perfectly with our vision and our commitment to the RISC-Vecosystem.‚Äù&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;About Canonical&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Canonical, the publisher of Ubuntu, provides open source security, support and services. Our portfolio covers critical systems, from the smallest devices to the largest clouds, from the kernel to containers, from databases to AI. With customers that include top tech brands, emerging startups, governments and home users, Canonical delivers trusted open source for everyone. Learn more at &lt;a href="https://canonical.com/"&gt;https://canonical.com/&lt;/a&gt;¬†&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;About SpacemiT&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Founded in November 2021, SpacemiT is a computing ecosystem company built on next-generation RISC-V architecture. The company focuses on full-stack computing technologies including high-performance RISC-V CPU cores, RISC-V AI cores, NoC interconnects, RISC-V AI CPU chips, and software systems. SpacemiT delivers end-to-end computing system solutions and is committed to building the optimal native computing platform for the next AI era, enabling new applications such as AI computers and AI robots. &lt;a href="https://www.spacemit.com"&gt;https://www.spacemit.com&lt;/a&gt; &lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="535" loading="lazy" sizes="(min-width: 1267px) 1267px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1267/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F41d4%2Fimage-1.jpeg 1267w" width="1267"/&gt;&lt;/figure&gt;
</content:encoded><author>Canonical (Canonical)</author><category>RISC-V</category><category>silicon</category><category>Ubuntu</category><pubDate>Thu, 05 Feb 2026 12:00:00 +0000</pubDate></item><item><title>AI meets SQL Server 2025 on Ubuntu</title><link>https://ubuntu.com//blog/sql-server-2025-on-ubuntu</link><description>&lt;p&gt;Partnership between Microsoft and Canonical Since 2016, when Microsoft announced its intention to make Linux a first class citizen in its ecosystem, Canonical and Microsoft have been working hand in hand to make that vision a reality. Ubuntu was among the first distributions to support the preview of SQL Server on Linux. Ubuntu was the [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;Partnership between Microsoft and Canonical&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Since 2016, when Microsoft announced its intention to make Linux a first class citizen in its ecosystem, Canonical and Microsoft have been working hand in hand to make that vision a reality. Ubuntu was among the first distributions to support the &lt;a href="https://blogs.microsoft.com/blog/2016/03/07/announcing-sql-server-on-linux"&gt;preview&lt;/a&gt; of SQL Server on Linux. Ubuntu was the &lt;a href="https://learn.microsoft.com/en-us/archive/blogs/wsl/windows-subsystem-for-linux-overview"&gt;first distribution&lt;/a&gt; offered in the launch of Windows Subsystem for Linux (WSL), and it remains the &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;default&lt;/a&gt; to this day. Ubuntu was also the first Linux distribution to support Azure‚Äôs &lt;a href="https://docs.microsoft.com/en-us/azure/confidential-computing/quick-create-confidential-vm-portal-amd"&gt;Confidential VMs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;SQL server has been a cornerstone of the ongoing collaboration to deliver a seamless Linux experience for developers and enterprises alike. Together, we have been able to meet growing customer demands with a number of joint offerings including ready-made and jointly &lt;a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps?filters=linux%3Bmicrosoft&amp;amp;page=1&amp;amp;search=Ubuntu"&gt;supported configurations&lt;/a&gt; for SQL Server on top of Ubuntu. In this article, we‚Äôll take a look at our latest collaboration: SQL Server 2025 on Ubuntu.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;SQL Server 2025&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;The &lt;a href="https://learn.microsoft.com/en-us/sql/linux/quickstart-install-connect-ubuntu?view=sql-server-ver17&amp;amp;tabs=ubuntu2004%2C2025ubuntu2204%2Codbc-ubuntu-1804"&gt;General Availability of SQL Server 2025 on Ubuntu 24.04&lt;/a&gt; is a milestone in our partnership. SQL Server 2025 brings several &lt;a href="https://learn.microsoft.com/en-us/sql/sql-server/what-s-new-in-sql-server-2025?view=sql-server-ver17"&gt;new features&lt;/a&gt;, including new AI capabilities such as vector search and external AI models integrations. Here‚Äôs how you can get up and running with these new capabilities.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Your new AI playground&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Deploying a database server instance&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Let‚Äôs start by installing &lt;a href="https://ubuntu.com/lxd"&gt;LXD&lt;/a&gt;, our Canonical tool to easily manage virtual machines and containers.&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo snap install lxd 
sudo snap list | awk '/lxd/ {print $3}'
sudo lxd init --minimal # configure LXD&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs now create a virtual machine to serve as a playground:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo lxc launch ubuntu:24.04 mssql25 --vm -c limits.cpu=4 -c limits.memory=6GiB -d root,size=24GiB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will be installing all the pre-requisites to get a SQL Server 2017 running:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo lxc exec mssql25 bash
su -l ubuntu
# Like always, we start by updating our packages
sudo apt -y update &amp;amp;&amp;amp; sudo apt -y upgrade

# Download and trust the Microsoft key 
curl -fsSL https://packages.microsoft.com/keys/microsoft.asc | sudo gpg --dearmor -o /usr/share/keyrings/microsoft-prod.gpg

# Register the SQL Server repository
curl -fsSL https://packages.microsoft.com/config/ubuntu/24.04/mssql-server-2025.list | sudo tee /etc/apt/sources.list.d/mssql-server-2025.list

# Ensures new repositories are loaded
sudo apt-get update

# Install SQL server and a password generator
sudo apt-get install -y mssql-server pwgen&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs now set up the installed SQL Server to get a running instance as follows:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;PW="$(pwgen -sB 22 1)" # Generates SQL Server compliant-password
# Prepare some environment variables to setup SQL Server
install -d -m 700 ~/.secrets/sql
install -m 600 /dev/null ~/.secrets/sql/mssql.env

cat &amp;gt; ~/.secrets/sql/mssql.env &amp;lt;&amp;lt;EOF
MSSQL_PID=Developer
MSSQL_SA_PASSWORD='$PW'
SQLSERVER=127.0.0.1
SQLPORT=1433
SQLUSER=sa
SQLCMDPASSWORD='$PW'
EOF

# Export every line in mssql.env as an environment variable
set -a; . ~/.secrets/sql/mssql.env; set +a

# Set up SQL Server
sudo MSSQL_SA_PASSWORD="$MSSQL_SA_PASSWORD" MSSQL_PID="$MSSQL_PID" /opt/mssql/bin/mssql-conf -n setup

# Let's check that everything went fine
systemctl status mssql-server --no-pager&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will now install some additional tools to be able to connect to SQL Server&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;# Download the deb package
curl -sSL -O https://packages.microsoft.com/config/ubuntu/$(grep VERSION_ID /etc/os-release | cut -d '"' -f 2)/packages-microsoft-prod.deb
# Install the downloaded deb package
sudo dpkg -i packages-microsoft-prod.deb
# Delete the downloaded package
rm packages-microsoft-prod.deb
# Install Microsoft's ODBC driver and additional tools
sudo apt-get update
sudo apt-get install -y msodbcsql18  mssql-tools18 unixodbc-dev libodbc2
echo 'export PATH="$PATH:/opt/mssql-tools18/bin"' &amp;gt;&amp;gt; ~/.bashrc
source ~/.bashrc&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will run a query to check that everything is running as intended:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;/opt/mssql-tools18/bin/sqlcmd -S 127.0.0.1 -U sa -No -C -P "$SQLCMDPASSWORD"
SELECT @@VERSION AS 'SQL Server Version';
GO&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above should return the exact version of SQL Server you are running. So far, we‚Äôve made simple interactions with SQL Server. In the next section, we will test some new exciting features of the 2025 edition.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Vector type&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;A vector type is a contiguous array of fixed-length numbers designed to enable hardware-accelerated vectorized (SIMD) execution. A vector type is the perfect type to use to store embeddings (i.e. numerical representations) of objects manipulated by AI models such as text and images.¬† Let‚Äôs create a table with a column of type of vector as follows:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;CREATE DATABASE DemoDb;
GO

USE DemoDb;
GO

ALTER DATABASE SCOPED CONFIGURATION SET PREVIEW_FEATURES = ON;
CREATE TABLE dbo.VectorDemo (id INT IDENTITY(1,1) PRIMARY KEY, embedding VECTOR(3) NOT NULL);
GO

INSERT INTO dbo.VectorDemo (embedding) VALUES ('[2,3,5]'), ('[7,11,13]'), ('[17,19,23]');
GO

DECLARE @q VECTOR(3) = '[7,11,13]';
SELECT embedding, VECTOR_DISTANCE('euclidean', embedding, @q) AS distance FROM dbo.VectorDemo ORDER BY distance;
GO

DECLARE @q2 VECTOR(3) = '[7,11,13]';
SELECT embedding, VECTOR_DISTANCE('cosine', embedding, @q2) AS distance FROM dbo.VectorDemo ORDER BY distance;
GO
exit&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have checked how to create a vector type and how to use the vector_distance operator. We will next provide an example of a more advanced use case involving calling an AI model and performing a similarity search.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;AI models integration&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;One of the most exciting features of SQL Server 2025 is the ability to call AI models from within the comfort of your database in a structured way. Let‚Äôs check how:&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI models deployment&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We will start by deploying a local embedding model using Ollama.&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;curl -fsSL https://ollama.com/install.sh | sh # Installs ollama
ollama pull nomic-embed-text # Pulls an embedding model
curl -k http://localhost:11434/api/tags  # Checks the api endpoint&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Deploying a http proxy&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;SQL Server 2025 requires that model endpoints are exposed using https (not just plain http). We will therefore deploy and configure Caddy for that purpose as follows:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo apt install -y caddy 

sudo cp /etc/caddy/Caddyfile /etc/caddy/Caddyfile.bak # Keep  a backup

sudo tee /etc/caddy/Caddyfile &amp;gt;/dev/null &amp;lt;&amp;lt;'EOF'
https://localhost:11435 {
  tls internal
  reverse_proxy 127.0.0.1:11434
}
EOF

sudo systemctl reload caddy # Needed to pick the previous changes

# We need the system to trust Caddy's certificate by doing the following:
sudo cp /var/lib/caddy/.local/share/caddy/pki/authorities/local/root.crt /usr/local/share/ca-certificates/caddy-local-root.crt

# We need also SQL Server system to trust Caddy's certificate:
sudo mkdir -p /var/opt/mssql/security/ca-certificates
sudo cp /var/lib/caddy/.local/share/caddy/pki/authorities/local/root.crt /var/opt/mssql/security/ca-certificates/caddy-local-root.crt
sudo chown -R mssql:mssql /var/opt/mssql/security
sudo chmod 744 /var/opt/mssql/security/ca-certificates
sudo chmod 644 /var/opt/mssql/security/ca-certificates/caddy-local-root.crt

# Update the VM's trusted certificates
sudo update-ca-certificates

# Restart SQL Server 
sudo systemctl restart mssql-server

# Check a few https endpoints 
curl -w '\n' https://localhost:11435/api/tags 
curl -w '\n' https://localhost:11435/api/embed \
  -H "Content-Type: application/json" \
  -d '{ "model":"nomic-embed-text", "input":"hello from caddy" }'&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Python dependencies&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Let‚Äôs now proceed with the installation of the pre-requisites to connect to the SQL Server instance using a python program.&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo apt install -y python3-openai python3-pyodbc&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Calling AI models from within SQL Server 2025&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We will now enable SQL Server to use an external endpoint and then restart it to ensure it correctly picked the new trusted certificates.&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;/opt/mssql-tools18/bin/sqlcmd -S 127.0.0.1 -U sa -C -P "$SQLCMDPASSWORD" -Q "EXEC sp_configure 'external rest endpoint enabled', 1; RECONFIGURE;"
sudo systemctl restart mssql-server&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we will write a simple Python script to test the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Connecting to the server programmatically&lt;/li&gt;
&lt;li&gt;Registering Ollama model via HTTPS proxy&lt;/li&gt;
&lt;li&gt;Creating a vector column and feeding it with some examples using the registered model&lt;/li&gt;
&lt;li&gt;Creating a vector-optimized index and using it to perform similarity search&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOT &amp;gt; ~/mssqlvector.py
import pyodbc

# Define parameters based on your sqlcmd
server = '127.0.0.1'
database = 'DemoDb'
username = 'sa'
password = "$MSSQL_SA_PASSWORD"
port = '1433'

# Connection string using SQL Server Authentication
connection_string = (
    "DRIVER={ODBC Driver 18 for SQL Server};"
    f"SERVER={server},{port};"
    f"DATABASE={database};"
    f"UID={username};"
    f"PWD={{{password}}};"
    f"Encrypt=no;"
    f"Connection Timeout=7;"
    f"TrustServerCertificate=yes;"
)

try:
    conn = pyodbc.connect(connection_string)
    cur = conn.cursor()
    print("Connected to SQL Server!")

    # Example: simple query
    cur.execute("SELECT name FROM sys.databases;")
    for row in cur.fetchall():
        print(row)

    conn.autocommit = True

    # 1) Register Ollama model via HTTPS proxy
    cur.execute("""
IF NOT EXISTS (SELECT * FROM sys.external_models WHERE name='ollama')
CREATE EXTERNAL MODEL ollama
WITH (
        LOCATION   = 'https://localhost:11435/api/embed',
        API_FORMAT = 'Ollama',
        MODEL_TYPE = EMBEDDINGS,
        MODEL      = 'nomic-embed-text'   -- 768 dims
);
""")

    # 2) Create a new table including a vector column
    cur.execute("""
DROP TABLE IF EXISTS dbo.SupportMatrix;
CREATE TABLE dbo.SupportMatrix (
        id        INT IDENTITY PRIMARY KEY,
        sentence  NVARCHAR(400) NOT NULL,
        embedding VECTOR(768)   NULL
);
""")

    # 3) Insert your Ubuntu/SQL Server lines
    texts = [
        "Ubuntu 24.04 is supported by SQL Server 2025",
        "Ubuntu 22.04 is supported by SQL Server 2022",
        "Ubuntu 20.04 is supported by SQL Server 2019",
        "Ubuntu 18.04 is supported by SQL Server 2019"
    ]
    cur.executemany("INSERT INTO dbo.SupportMatrix(sentence) VALUES (?);", [(t,) for t in texts])

    # 4) Generate embeddings in-database (using the external model)
    cur.execute("""
UPDATE dbo.SupportMatrix
SET embedding = AI_GENERATE_EMBEDDINGS(sentence USE MODEL ollama)
WHERE embedding IS NULL;
""")

    # 5) Create an ANN similarity index (DiskANN) on the vector column
    cur.execute("""
IF NOT EXISTS (SELECT 1 FROM sys.indexes WHERE name = 'IX_SupportMatrix_Embedding')
CREATE VECTOR INDEX IX_SupportMatrix_Embedding
ON dbo.SupportMatrix(embedding)
WITH (METRIC = 'cosine', TYPE = 'diskann');
""")

    # 6) Run a similarity search with VECTOR_SEARCH (uses the ANN index)
    query_text = "What Ubuntu version is supported by SQL Server 2025?"
    cur.execute("""
DECLARE @q VECTOR(768) = AI_GENERATE_EMBEDDINGS(?, ollama);

SELECT TOP (3)
  t.id,
  t.sentence,
  s.distance
FROM VECTOR_SEARCH(
    table = dbo.SupportMatrix AS t,
    column = embedding,
    similar_to = @q,
    metric = 'cosine',
    top_n = 3
) AS s
ORDER BY s.distance, t.id;
""", (query_text,))

    print(f"Top matches for: '{query_text}'\n")
    for row in cur.fetchall():
        print(row)

except Exception as e:
    print("Connection failed:", e)

finally:
    conn.close()

EOT&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then can use our python scipt as follows:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;python3 ~/mssqlvector.py&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We‚Äôve checked some of the new AI-related features that you can use from within the comfort of your SQL Server database. Bringing AI closer to your data is a good recipe for getting more value out of your data without the challenges inherent to data duplication.&lt;/p&gt;
&lt;p&gt;Another challenge companies need to address is securing the AI supply chain. Let‚Äôs look at how you can handle that next.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;Your secure AI playground&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;In order to get security updates for up to 25,000 open source packages, you can subscribe to Ubuntu Pro (free for personal use for up to 5 machines). You can check whether you have already a subscription by running the following command:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;pro api u.pro.status.enabled_services.v1 | grep -c esm&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If not enabled then you can subscribe to Ubuntu Pro &lt;a href="https://ubuntu.com/pro/subscribe"&gt;here&lt;/a&gt;. Once you get your token, just type:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo pro attach &amp;lt;token&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that you have covered all of your Canonical maintained packages, you should next check the providers of your other packages that aren‚Äôt included in Ubuntu Pro. The following command helps you identify all the deb packages that are not maintained directly by Canonical:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;dpkg-query -W -f='${Package}\n' | while read pkg; do
    src=$(apt-cache policy "$pkg" | grep -m 1 http | awk '{print $2}')
    if [[ -n "$src" &amp;amp;&amp;amp; "$src" != *ubuntu.com* ]]; then
        echo "$pkg -&amp;gt; $src"
    fi
done&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In my testing virtual machine, the above yields the following Microsoft-provided packages:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;msodbcsql18 -&amp;gt; https://packages.microsoft.com/ubuntu/24.04/prod
mssql-server -&amp;gt; https://packages.microsoft.com/ubuntu/24.04/mssql-server-preview
mssql-tools18 -&amp;gt; https://packages.microsoft.com/ubuntu/24.04/prod
packages-microsoft-prod -&amp;gt; https://packages.microsoft.com/ubuntu/24.04/prod&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should only keep trusted sources such as Microsoft and Canonical.¬† You need also to perform the same checks for all the other types of packages or images you might be using (containers, snaps ‚Ä¶). Unfortunately, many companies might overlook securing the models themselves. Canonical not only provides audited AI models but also ones that are optimized for your infrastructure. Let‚Äôs look at an example.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;Your optimized AI models&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Canonical recently &lt;a href="https://canonical.com/blog/canonical-releases-inference-snaps"&gt;announced&lt;/a&gt; &lt;a href="https://documentation.ubuntu.com/inference-snaps/"&gt;inference snaps&lt;/a&gt; that take advantage of your silicon capabilities (whether CPUs or GPUs) to accelerate your AI workloads.¬† Here‚Äôs how you can install one:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo snap install qwen-vl --beta
qwen-vl status # Checks it finished successfully&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On my machine, I get:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;engine: cpu-avx512
endpoints:
    openai: http://localhost:8326/v1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can then use the newly deployed model as follows:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;curl http://localhost:8326/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{ "model": "&amp;lt;model-name&amp;gt;", "messages": [{"role": "user", "content": "Who is the publisher of Ubuntu?"}],
"temperature": 0.7
}' | jq&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should then get a response to the supplied prompt.&lt;/p&gt;
&lt;p&gt;Running optimized AI models along Ubuntu Pro and SQL Server provides you with a secure and reliable stack to support your AI workflows. Canonical and Microsoft can help you go further with jointly supported offerings.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;Your supported AI playground&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;We saw together how Canonical and Microsoft help you run an integrated AI stack from the operating system up to the database engine and the AI models. Canonical and Microsoft¬† deliver prebuilt Azure VM images with pre-configured SQL Server on top of Ubuntu Pro, with support from both companies. We can also help you run highly available and supported SQL Server deployments on top of Ubuntu Pro. Please &lt;a href="https://canonical.com/data#get-in-touch"&gt;contact us&lt;/a&gt; for more details.&lt;/p&gt;
</content:encoded><author>Mohamed Wadie Nsiri (Mohamed Wadie Nsiri)</author><category>SQL Server</category><category>Ubuntu</category><pubDate>Wed, 04 Feb 2026 14:34:41 +0000</pubDate></item><item><title>AWS IoT Greengrass comes to Ubuntu Core</title><link>https://ubuntu.com//blog/aws-iot-greengrass-comes-to-ubuntu-core</link><description>&lt;p&gt;AWS‚Äôs open source edge run time meets Canonical‚Äôs fully containerized OS for devices delivering a supported and robust end-to-end answer for enterprises looking to develop their own IoT hardware and solutions. London, February 3, 2026 &amp;#8212; Canonical and AWS are pleased to announce the release of the new snap for AWS IoT Greengrass, making the [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;h4 class="wp-block-heading"&gt;AWS‚Äôs open source edge run time meets Canonical‚Äôs fully containerized OS for devices delivering a supported and robust end-to-end answer for enterprises looking to develop their own IoT hardware and solutions.&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;London, February 3, 2026 ‚Äî Canonical and AWS are pleased to announce the release of the new snap for AWS IoT Greengrass, making the deployment of your IoT solutions easy and seamless all the way from silicon to the cloud&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;With the &lt;a href="https://snapcraft.io/aws-iot-greengrass"&gt;AWS IoT Greengrass agent&lt;/a&gt; now available as a snap package from the Canonical Snap Store, Ubuntu Core has become the ideal operating system for all your AWS IoT edge workloads and data ingress. Its broad compatibility with silicon hardware, long-term support, and proven, reliable performance unlock endless possibilities for your IoT devices utilizing the power of the AWS cloud.&lt;/p&gt;
&lt;p&gt;AWS Greengrass is one of the market-leading IoT edge platforms, bringing the comprehensive capabilities of the AWS cloud to distributed edge environments.&lt;/p&gt;
&lt;p&gt;Ubuntu Core offers extensive silicon compatibility, simplifying device deployment across various hardware platforms. Canonical further supports this by providing device enablement and certification for custom hardware, ensuring long-term support for your products.¬†&lt;/p&gt;
&lt;p&gt;The combined solutions¬†enable enterprises to focus on their products with confidence, knowing their infrastructure and devices are covered.&lt;/p&gt;
&lt;blockquote class="wp-block-quote"&gt;
&lt;p&gt;&lt;em&gt;‚ÄúAWS IoT Greengrass is the best way to bring the power of AWS to the edge, and what better option to partner it with than the industry leading OS for edge devices ‚Äì Ubuntu Core? With the release of the Greengrass snap,¬†enterprises will be hard pressed to find an easier, more secure, reliable or robust foundation for their IoT needs.‚Äù &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;‚Äì Michael Croft-White, Engineering Director, Canonical.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 class="wp-block-heading"&gt;The power of the cloud at the edge&lt;/h2&gt;
&lt;p&gt;AWS Greengrass enables organizations to deploy and manage containerized applications and AWS Lambda functions directly onto their local hardware, streamlining their edge solution development.&lt;/p&gt;
&lt;p&gt;AWS IoT Greengrass brings processing and machine learning inference closer to the point of data collection. This makes it ideal for applications needing low latency and real-time decisions. Furthermore, with its reliable offline capabilities, Greengrass ensures continued operation during periods of intermittent network connectivity. Running on top of Canonical‚Äôs Ubuntu Core, enterprises can build, develop, and deploy sophisticated, resilient, and scalable edge solutions in sectors such as industrial automation, logistics, and automotive.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Made for security, resilience, and longevity&lt;/h2&gt;
&lt;p&gt;Ubuntu Core is purpose built for IoT and embedded devices. With Canonical‚Äôs reputation for industry-leading reliability and robust security and focus on long-term support commitment, you can rely on a predictable release cycle and stability across your entire fleet.&lt;/p&gt;
&lt;p&gt;Its minimal, containerized design with automatic, transactional updates can ensure timely delivery of security patches without downtime. Extensive hardware and silicon compatibility gives the freedom to optimize your device‚Äôs design for each and every use case.&lt;/p&gt;
&lt;p&gt;Through Ubuntu Pro, both Ubuntu and Ubuntu Core can be extended with up to 15 years of maintenance and security updates with &lt;a href="https://ubuntu.com/security/esm"&gt;Canonical‚Äôs Expanded Security Maintenance (ESM)&lt;/a&gt;. This gives organizations the confidence that their IoT infrastructure remains securely maintained against¬† vulnerabilities for the long term, reducing operational risk and total cost of ownership.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Get the snap for AWS IoT Greengrass&lt;/h2&gt;
&lt;p&gt;You can download and install the snap from the &lt;a href="https://snapcraft.io/aws-iot-greengrass"&gt;Snap Store&lt;/a&gt;¬†directly onto your IoT device with the following command:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;snap install aws-iot-greengrass&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information on Ubuntu Core, visit &lt;a href="https://ubuntu.com/core"&gt;ubuntu.com/core&lt;/a&gt;, or check out our &lt;a href="http://canonical.com/blog/tutorial-getting-started-with-aws-greengrass-on-ubuntu-core"&gt;tutorial blog&lt;/a&gt; for everything you need to get started, including a hands-on demo.¬†&lt;/p&gt;
&lt;p&gt;If you are not already familiar with AWS IoT Greengrass, more information can be found &lt;a href="https://aws.amazon.com/greengrass/"&gt;here&lt;/a&gt;.¬†&lt;/p&gt;
&lt;p&gt;Are you interested in running Ubuntu Core with AWS IoT Greengrass on your devices and are working on a commercial project?&lt;/p&gt;
&lt;p&gt; &lt;a aria-label=" (opens in a new tab)" class="p-button--small p-button--positive" href="https://canonical.com/contact-us#get-in-touch" rel="noreferrer noopener" target="_blank"&gt;Get in touch&lt;/a&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://canonical.com/blog/tutorial-getting-started-with-aws-greengrass-on-ubuntu-core"&gt;Tutorial: getting started with AWS Greengrass on Ubuntu Core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/core"&gt;Ubuntu Core: The embedded Linux OS for devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/greengrass/"&gt;Intelligence at the IoT Edge ‚Äì AWS IoT Greengrass&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="wp-block-heading"&gt;About Canonical&lt;/h2&gt;
&lt;p&gt;Canonical, the publisher of Ubuntu, provides open-source security, support and services. Our portfolio covers critical systems, from the smallest devices to the largest clouds, from the kernel to containers, from databases to AI. With customers that include top tech brands, emerging startups, governments and home users, Canonical delivers trusted open source for everyone.&lt;br/&gt;Learn more at &lt;a href="https://canonical.com/"&gt;https://canonical.com/&lt;/a&gt;&lt;/p&gt;
</content:encoded><author>Canonical (Canonical)</author><pubDate>Tue, 03 Feb 2026 09:55:59 +0000</pubDate></item><item><title>Tutorial: getting started with AWS IoT Greengrass on Ubuntu Core</title><link>https://ubuntu.com//blog/tutorial-getting-started-with-aws-greengrass-on-ubuntu-core</link><description>&lt;p&gt;We recently announced that you can now benefit from the combined power of Ubuntu Core and AWS IoT Greengrass to bring the computation, storage, and AI capabilities of the cloud closer to the edge. AWS IoT Greengrass is an open source edge runtime and cloud service that extends Amazon Web Services (AWS) capabilities to physical [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;&lt;a href="http://canonical.com/blog/aws-iot-greengrass-comes-to-ubuntu-core"&gt;We recently announced &lt;/a&gt;that you can now benefit from the combined power of Ubuntu Core and AWS IoT Greengrass to bring the computation, storage, and AI capabilities of the cloud closer to the edge. AWS IoT Greengrass is an open source edge runtime and cloud service that extends Amazon Web Services (AWS) capabilities to physical devices. It means devices can act locally on data while still harnessing the cloud for management and analytics. This is essential for applications where latency can be critical, resilience is needed due to low or no network connectivity, or where privacy and data concerns are paramount.¬†&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/core"&gt;Ubuntu Core&lt;/a&gt; is a flavor of Ubuntu that has been specially optimized for IoT and embedded systems. The combination of the Ubuntu Core and AWS IoT Greengrass is ideal for those looking for reduced latency, lower bandwidth, and more efficient data processing.¬†&lt;/p&gt;
&lt;p&gt;This tutorial helps you get started using an Ubuntu Core device as a platform to deploy an AWS Greengrass based demonstration of video inference. To follow along you will need two devices:¬†&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An intel-based device, such as a NUC, for running Ubuntu Core¬†&lt;/li&gt;
&lt;li&gt;A device for configuring your AWS deployment and running the dashboard to show you the results.¬†&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will also need a webcam to capture images and an AWS account.¬†&lt;/p&gt;
&lt;p&gt;Both AWS and Ubuntu Core are available on a wide range of hardware platforms. However, this specific demo has been optimized for Intel ‚Äì hence the device requirements.&lt;/p&gt;
&lt;p&gt;This blog will begin with a brief explanation of the solution before providing an overview of the architecture, and then guide you through the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#install-ubuntu-core"&gt;Installing Ubuntu Core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-aws-iam"&gt;Creating an AWS user account for the demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set-up-aws"&gt;Installing the Greengrass Snap package and connecting to your AWS account&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prepare-deployment-environment"&gt;Preparing your deployment environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-deploy-components"&gt;Creating and deploying Greengrass Components&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set-up-web-interface"&gt;Setting up a web interface to view the demo outputs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, let‚Äôs get started.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Solution summary&lt;/h2&gt;
&lt;p&gt;The solution uses Greengrass Nucleus installed as a Snap package on Ubuntu Core.¬† It uses the strict confinement for snap packages to help maintain the highest level of security control and isolation.¬†¬†&lt;/p&gt;
&lt;p&gt;Installing and configuring the Greengrass snap package takes only a couple of minutes. The package enables easy connection of Greengrass to the AWS Greengrass Service in your AWS account, including creation of the necessary certificate and permissions needed for the device to function.&lt;/p&gt;
&lt;p&gt;After installation and configuration, three Greengrass custom components are deployed to the device from AWS. These enable connection of a USB webcam for capturing local images. Using Computer Vision (CV) capabilities provided through Intel OpenVINO, these images can then be processed for object detection to create a high-performance power combination for local device inference.¬†&lt;/p&gt;
&lt;p&gt;The results of the CV inference are sent to AWS Cloud IoT Core service using MQTT, a standard protocol for IoT devices. The annotated images with bounding boxes for object detection are uploaded to Amazon S3 from the device. Together, these enable a web-based dashboard to visualize annotated images and inference results.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;High-level architecture and overview&lt;/h3&gt;
&lt;p&gt;The diagram below shows the high-level view of the interaction of the different components that will be deployed to your device for the purposes of this demo.&lt;/p&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="" loading="lazy" sizes="(min-width: 533px) 533px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_533/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2afd%2FDiagram-v3.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2afd%2FDiagram-v3.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2afd%2FDiagram-v3.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2afd%2FDiagram-v3.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_533/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2afd%2FDiagram-v3.png 533w" width="533"/&gt;&lt;/figure&gt;
&lt;p&gt;The three components we will be deploying are:¬†&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CameraHandler
&lt;ul&gt;
&lt;li&gt;Manages the connection to the USB webcam.&lt;/li&gt;
&lt;li&gt;Captures an image from the webcam every 30 seconds.&lt;/li&gt;
&lt;li&gt;Stores the image locally (within the confinement of Greengrass snap package).&lt;/li&gt;
&lt;li&gt;Publishes a message using Greengrass IPC on the camera/images topic with the path to the locally stored image file.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;InferenceHandler
&lt;ul&gt;
&lt;li&gt;Subscribes to the camera/images topic.&lt;/li&gt;
&lt;li&gt;When it receives a message on that topic it processes the image so that it can be sent to OpenVINO for inference.&lt;/li&gt;
&lt;li&gt;Calls the OpenVINO Model Server container to carry out the inference.&lt;/li&gt;
&lt;li&gt;Upon receiving the inference results it annotates the image with bounding boxes and uploads the annotated image to Amazon S3.&lt;/li&gt;
&lt;li&gt;Sends a MQTT message to AWS IoT Core on the topic camera/inference.&lt;/li&gt;
&lt;li&gt;Deletes the local images.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OpenVINOServerHandler
&lt;ul&gt;
&lt;li&gt;Downloads the relevant Computer Vision ML model from Amazon S3.&lt;/li&gt;
&lt;li&gt;Runs the standard Docker image for OpenVINO Model Server for inference using the provided ML model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="wp-block-heading"&gt;Requirements&lt;/h2&gt;
&lt;p&gt;The minimum requirements for edge devices running Ubuntu Core is available in &lt;a href="https://documentation.ubuntu.com/core/reference/system-requirements/"&gt;our documentation&lt;/a&gt;. While Ubuntu Core is available for many architectures, this demo is targeted at Intel CPUs because it uses the Intel OpenVINO driver, and we will need: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;512MB RAM&lt;/li&gt;
&lt;li&gt;1GB storage&lt;/li&gt;
&lt;li&gt;2 x USB ports¬†&lt;/li&gt;
&lt;li&gt;Internet connection (wifi or cabled)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will also need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2 USB memory sticks (min: 8GB)&lt;/li&gt;
&lt;li&gt;USB webcam¬†&lt;/li&gt;
&lt;li&gt;Deployment device
&lt;ul&gt;
&lt;li&gt;A laptop/desktop for creating the deployment and running the dashboard&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="wp-block-heading" id="install-ubuntu-core"&gt;1. Installing Ubuntu Core&lt;/h3&gt;
&lt;p&gt;First, we need to set up our Ubuntu Core device.&lt;/p&gt;
&lt;p&gt;Ubuntu Core is a minimal, immutable flavor of Ubuntu which provides a reliable and secure platform for connected devices. To get started with it, Canonical have provided reference images that can be flashed onto certain devices and provide you a working environment.¬†&lt;/p&gt;
&lt;p&gt;Ubuntu Core‚Äôs immutability and automatic updates make it the perfect platform for an embedded IoT workloading, meaning the user won‚Äôt have to worry about the device breaking in the field.&lt;/p&gt;
&lt;p&gt;Once we have flashed the Ubuntu Core image to our device, we will need to be able to connect to it. This will require an Ubuntu SSO account and an SSH keypair. You can skip this step if you already have an account, otherwise you can sign up for one &lt;a href="https://login.ubuntu.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To authenticate yourself when trying to connect to your Ubuntu Core device, you will need to upload a public SSH key to your SSO account. This will then be automatically downloaded to the Core device during initial configuration and allow you to log into a console.¬†&lt;/p&gt;
&lt;p&gt;To generate and upload an SSH key pair, follow the steps detailed in our documentation: &lt;a href="https://ubuntu.com/core/docs/connect-with-ssh"&gt;Connect to Ubuntu Core with SSH&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, we are ready to set up the device.&lt;/p&gt;
&lt;p&gt;We will be booting the device into a live Ubuntu environment using the first of our two USB sticks. From this instance, we can then flash the device storage with the Ubuntu Core image that we copied onto the second USB memory stick.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Follow &lt;a href="https://documentation.ubuntu.com/desktop/en/latest/how-to/create-a-bootable-usb-stick/"&gt;this&lt;/a&gt; tutorial to create a bootable USB stick with Ubuntu Desktop&lt;/li&gt;
&lt;li&gt;Download the &lt;a href="https://cdimage.ubuntu.com/ubuntu-core/24/stable/current/ubuntu-core-24-amd64.img.xz"&gt;reference Ubuntu Core 24 image for AMD/Intel 64bit devices&lt;/a&gt;¬†&lt;/li&gt;
&lt;li&gt;Boot your device into Ubuntu Desktop using your first USB stick.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once in Ubuntu Desktop, insert your second USB stick and locate the Ubuntu Core image file. This will be something like:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;/media/ubuntu/&amp;lt;disk-label&amp;gt;/ubuntu-core-24-amd64.img.xz&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let‚Äôs decompress that file to give us a raw image:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;unxz ubuntu-core-24-amd-64.img.xz&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, flash it to the device:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;dd if=ubuntu-core-24-amd-64.img of=/dev/&amp;lt;target disk&amp;gt; bs=32M status=progress&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are not sure what your local target disk is, run &lt;strong&gt;sudo fdisk -l&lt;/strong&gt;. This will list all your storage devices. You are looking for something like &lt;strong&gt;/dev/nvme01n1&lt;/strong&gt;. Note, this will completely erase anything on your target device, and replace it with Ubuntu Core.¬†&lt;/p&gt;
&lt;p&gt;Once complete, you can remove all your USB sticks and reboot the device, which should start the Ubuntu Core initial configuration.&lt;/p&gt;
&lt;p&gt;Follow this wizard process and configure your network connection. You will be prompted to enter your Ubuntu SSO credentials, which will automatically download your SSH Keys to the device.¬†&lt;/p&gt;
&lt;p&gt;Once configured, your device will be up and running. On screen, there will be a message explaining how to connect to this device from any other device on the network with a command such as:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;ssh &amp;lt;ubuntu SSO user name&amp;gt;@&amp;lt;device IP address&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations. You now have a secure, robust Ubuntu Core device. Now, let‚Äôs give it some cloud-connected superpowers.&lt;/p&gt;
&lt;h3 class="wp-block-heading" id="create-aws-iam"&gt;2. Creating AWS IAM Users&lt;/h3&gt;
&lt;p&gt;To create and deploy the AWS components for this demo, we need to create two IAM users with programmatic access (Access Key and Secret Access Key) for Greengrass installation.¬†&lt;/p&gt;
&lt;p&gt;To set up an IAM User:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to your AWS account access portal.&lt;/li&gt;
&lt;li&gt;Search for the IAM service.&lt;/li&gt;
&lt;li&gt;From the Access Management sidebar, select Users and then create a user.&lt;/li&gt;
&lt;li&gt;Pick a name for this user. When prompted for permissions, select ‚ÄúAttach Policies Directly‚Äù.&lt;/li&gt;
&lt;li&gt;Select the policies detailed for each user below.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Greengrass device user:¬†&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The first user is for installing the Greengrass device ‚Äì we‚Äôll refer to them as the ‚ÄúGreengrass Device User‚Äù from now on. It is recommended to give this user &lt;em&gt;AWSGreengrassFullAccess&lt;/em&gt; and &lt;em&gt;AWSIoTFullAccess&lt;/em&gt; permissions ‚Äì this is slightly more than is required, but will ensure the user has everything necessary to get started. A finer grained breakdown of AWS permissions used can be found in the &lt;a href="https://github.com/aws-samples/sample-greengrass-ubuntucore-computervision"&gt;component repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When creating this user, make sure you create and download the Access Keys as you will be prompted to enter them during the Greengrass installation.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Deployment user:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The second user is needed to configure the deployment and resources ‚Äì we‚Äôll call them the ‚ÄúDeployment User‚Äù from now on. This user will require a few more permissions. This user should be granted the &lt;em&gt;PowerUserAccess and IAMFullAccess&lt;/em&gt; policies in addition to the &lt;em&gt;AWSIoTFullAccess&lt;/em&gt; and &lt;em&gt;AWSGreengrassFullAccess&lt;/em&gt; policies.&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Obtain Access Keys for users:¬†&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Having created both the Greengrass Device User and the Deployment User we need to obtain their access key.¬†&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select a user from your list and look for the Access Keys section.&lt;/li&gt;
&lt;li&gt;Click ‚ÄúCreate Access Key.‚Äô&lt;/li&gt;
&lt;li&gt;Select AWS CLI. Create the Keys and make sure to save a copy of them.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will use the access keys during the following steps to configure the device and deployment.&lt;/p&gt;
&lt;h3 class="wp-block-heading" id="set-up-aws"&gt;3. Setting Up AWS on your Ubuntu Core device&lt;/h3&gt;
&lt;p&gt;The installation of Greengrass is simple and quick, following the steps below on your Ubuntu Core device.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the aws-iot-greengrass snap from the store (for more information, visit our &lt;a href="https://snapcraft.io/aws-iot-greengrass"&gt;webpage&lt;/a&gt;) and run the configuration command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo snap install aws-iot-greengrass

sudo aws-iot-greengrass.configure
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;When prompted, enter the IAM user Access Key and Secret Access Key for your Greengrass device user. Make sure to specify the AWS region that you are using and the name you want for the device in the AWS IoT Core portal.&lt;/li&gt;
&lt;li&gt;Monitor the log messages on the screen to ensure successful configuration.&lt;/li&gt;
&lt;li&gt;Check your AWS account to ensure that you can see the device listed as an ‚ÄúIoT Thing‚Äù and as a ‚ÄúGreengrass Core Device‚Äù. &lt;/li&gt;
&lt;li&gt;Make sure the necessary interfaces are connected to allow the Greengrass snap to interact with the device and webcam by running the following commands:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo snap connect aws-iot-greengrass:docker docker:docker-daemon
sudo snap connect aws-iot-greengrass:docker-executables docker:docker-executables
sudo snap connect aws-iot-greengrass:camera&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="wp-block-heading" id="prepare-deployment-environment"&gt;4. Preparing your deployment environment&lt;/h3&gt;
&lt;p&gt;Having created our device, we now will create some components and deploy them to the device. Let‚Äôs start by setting up the environment for this on your second Ubuntu device.¬†&lt;/p&gt;
&lt;p&gt;The components themselves and scripts to help make the installation process simple are available on &lt;a href="https://github.com/aws-samples/sample-greengrass-ubuntucore-computervision"&gt;GitHub&lt;/a&gt;. Start by cloning this repo to your local device:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo apt install git
git clone 
https://github.com/aws-samples/sample-greengrass-ubuntucore-computervision&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will need to install and configure the AWS CLI. This will allow us to log in to AWS and perform all the necessary actions. The login command will prompt you for the Access Key and Secret Access Key created in the previous steps ‚Äì in this case, use the ones for the Deployment User.&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;snap install aws-cli --classic

aws configure&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are logged in, we can create our components. As mentioned, the component uses the Intel OpenVINO models for image analysis. These need downloading separately using the provided script in the repository:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo apt install curl zip 
download_model.sh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we‚Äôll make sure we have all other dependencies installed and create a python virtual environment to keep everything together. From the local repository directory, run:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;sudo apt install python3-venv
python3 -m venv greengrass-deploy
source greengrass-deploy/bin/activate
pip install -r requirements-deploy.txt&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="wp-block-heading" id="create-deploy-components"&gt;5. Creating and deploying components&lt;/h3&gt;
&lt;p&gt;Before we can deploy the components to the device, we will create an S3 bucket to store our images and a user account so we can access the web dashboard we will create.&lt;/p&gt;
&lt;p&gt;This is all handled by the following script.&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;python3 setup_aws_resources.py --s3-bucket your-bucket-name --region us-east-1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The script will create:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Greengrass Token Exchange Role and Role Alias (required for Greengrass components to access AWS services)&lt;/li&gt;
&lt;li&gt;S3 bucket (for component artifacts and the latest processed image)&lt;/li&gt;
&lt;li&gt;Cognito resources and a demo user (for React dashboard authentication)&lt;/li&gt;
&lt;li&gt;IoT policies and IAM roles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As the web dashboard will be accessing our AWS resources, we will need to create a user for that purpose that allows for username/password authentication. The user will be &lt;a href="mailto:demo@example.com"&gt;demo@example.com&lt;/a&gt; and you will be prompted for the password you would like to use.&lt;/p&gt;
&lt;p&gt;Note: The InferenceHandlerCore component uploads each processed image to the same S3 location (camera/latest-inference.jpg), overwriting the previous image. This keeps storage minimal and simplifies the dashboard.&lt;/p&gt;
&lt;p&gt;And now, it is time to deploy components by simply running the script and follow the prompts:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;python3 deploy_greengrass_components.py&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will guide you through the process including:¬†&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create: Uploads component artifacts to S3 and creates Greengrass components in AWS&lt;/li&gt;
&lt;li&gt;deploy: Creates a deployment targeting your IoT Thing/Greengrass Core Device&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once the script has run, you should be able to see the status of your deployments and the components being delivered to your device.¬†&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;If you need more information on the scripts, or debugging any issues, the repository contains a &lt;a href="https://github.com/aws-samples/sample-greengrass-ubuntucore-computervision/react-web/README.md"&gt;readme.md&lt;/a&gt; file with more details.&lt;/p&gt;
&lt;h3 class="wp-block-heading" id="set-up-web-interface"&gt;6. Setting up a web interface to view the results&lt;/h3&gt;
&lt;p&gt;So, the deployment has completed and our device is happily running away doing its own thing on the edge. We want to see what it is up to, so let‚Äôs deploy a dashboard. The dashboard runs locally, connecting to AWS to display the most recent captured image alongside the inference model output.&lt;/p&gt;
&lt;p&gt;The dashboard is provided with the component repository and more information on it can be found in the /react-web folder.¬†&lt;/p&gt;
&lt;p&gt;Scripts have been provided below to perform all the necessary setup steps.¬†&lt;/p&gt;
&lt;p&gt;The configuration for the dashboard, to ensure it connects to the correct locations, is stored in the .env file that is automatically populated when you run the deploy_greengrass_components script. If you need to recreate it, you can run the script again with the following settings:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;python3 deploy_greengrass_components.py --stage setup --s3-bucket 
your-bucket-name --region us-east-1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Having configured everything, install the dependencies necessary for the dashboard. From the react-web/ folder in the repository, run:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;apt install npm
npm install&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, start the dashboard server with:&lt;/p&gt;
&lt;pre class="wp-block-code"&gt;&lt;code&gt;npm start&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Open &lt;strong&gt;http://localhost:3000&lt;/strong&gt; to view the dashboard. Log in with the demo user credentials created in the previous stage and click ‚ÄúConnect‚Äù to see the S3 images. Click ‚ÄúSubscribe‚Äù to view the model output.&lt;/p&gt;
&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="" loading="lazy" sizes="(min-width: 840px) 840px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_840/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F282f%2FImage-recognition-v2.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F282f%2FImage-recognition-v2.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F282f%2FImage-recognition-v2.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F282f%2FImage-recognition-v2.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_840/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F282f%2FImage-recognition-v2.png 840w" width="840"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Next steps&lt;/h2&gt;
&lt;p&gt;We hope that, having set up this demo, you get an insight into what you can do with AWS IoT Greengrass and Ubuntu Core. From here, you can further explore the options to build components, deploy, manage, and monitor remotely, as well as scaling up. In addition, Ubuntu Core will keep you secure and up to date automatically.¬†&lt;/p&gt;
&lt;p&gt;In future blogs, we will explore more specific Ubuntu Core management options directly from AWS Greengrass.¬† Keep your eyes peeled!&lt;/p&gt;
&lt;p&gt;What will you build next? A smart factory monitor? An automated sales kiosk? A robotic production line? Whatever it is, Ubuntu Core and AWS Greengrass have your back.¬†&lt;/p&gt;
&lt;p&gt;Whether you are a startup bringing your concept to market or already have large fleets of devices deployed in the field, we have the expertise and infrastructure to launch and support you.&lt;a href="https://ubuntu.com/core#get-in-touch"&gt; Contact our team here.&lt;/a&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://canonical.com/blog/aws-iot-greengrass-comes-to-ubuntu-core"&gt;AWS IoT Greengrass comes to Ubuntu Core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/core"&gt;Ubuntu Core: The embedded Linux OS for devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/greengrass/"&gt;Intelligence at the IoT Edge ‚Äì AWS IoT Greengrass&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Canonical (Canonical)</author><pubDate>Tue, 03 Feb 2026 09:55:24 +0000</pubDate></item></channel></rss>