<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Ubuntu blog</title><link>https://ubuntu.com//blog/feed</link><description>Ubuntu blog feed</description><atom:link href="https://ubuntu.com//blog/feed" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>Python Feedgen</generator><lastBuildDate>Thu, 08 Jan 2026 11:30:39 +0000</lastBuildDate><item><title>Canonical announces Ubuntu support for the NVIDIA Rubin platform</title><link>https://ubuntu.com//blog/nvidia-vera-rubin-ubuntu-support</link><description>&lt;p&gt;Official Ubuntu support for the NVIDIA Rubin platform, including the NVIDIA Vera Rubin NVL72 rack-scale systems, announced at CES 2026 CES 2026, Las Vegas. – Canonical, the publisher of Ubuntu, is pleased to announce official support for the NVIDIA Rubin platform and the latest distributions of the new NVIDIA Nemotron 3 open models.&amp;nbsp; As AI [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;h2 class="wp-block-heading"&gt;Official Ubuntu support for the NVIDIA Rubin platform, including the NVIDIA Vera Rubin NVL72 rack-scale systems, announced at CES 2026&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;CES 2026, Las Vegas.&lt;/em&gt; – Canonical, the publisher of Ubuntu, is pleased to announce official support for the NVIDIA Rubin platform and the latest distributions of the new &lt;a href="https://www.nvidia.com/en-us/ai-data-science/foundation-models/nemotron/"&gt;NVIDIA Nemotron&lt;/a&gt; 3 open models. &lt;/p&gt;
&lt;p&gt;As AI workloads transition from small-scale proof of concepts to massive-scale AI factories, the need for a stable, high-performance operating system substrate has never been greater. Ubuntu provides that foundation, unifying the NVIDIA Vera CPU, NVIDIA Rubin GPU, and &lt;a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/"&gt;NVIDIA BlueField-4 DPU&lt;/a&gt; into a cohesive execution environment.&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;AI democratization requires more than powerful silicon; it needs a secure, frictionless environment from cloud to edge&lt;/em&gt;,” said Justin Boitano, Vice President, Enterprise AI Products, NVIDIA. “&lt;em&gt;Our work with Canonical ensures enterprises can deploy the NVIDIA Rubin platform, including the rack-scale Vera Rubin NVL72, on the Ubuntu foundation they already trust, streamlining the path from development to production with enterprise-grade security, and removing friction so organizations can innovate with confidence.&lt;/em&gt;“&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;Our collaboration with NVIDIA reinforces Canonical’s mission to democratize AI&lt;/em&gt;,” said Cindy Goldberg, VP Cloud and Silicon Partnerships at Canonical. “&lt;em&gt;By unifying the CPU, GPU, and DPU into a single, cohesive Ubuntu execution environment, we are making it easier to build private or sovereign clouds and the next generation of intelligent applications. Enterprises can build for the future on a secure foundation they trust.&lt;/em&gt;“&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;First-class Arm support for Vera Rubin&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA Vera Rubin NVL72 rack presents a scalable architecture for integrated AI compute, pairing the custom Arm-based Vera CPU with the Rubin GPU. In Ubuntu 26.04, Arm is a first-class citizen with x86 performance parity. Canonical is integrating critical upstream features including Nested Virtualization and MPAM (Memory System Resource Partitioning and Monitoring). These tools enable providers to partition memory bandwidth and cache at the hardware level, ensuring predictable performance for multi-tenant AI workloads. This infrastructure will be further reinforced with native Arm support in&lt;a href="https://canonical.com/maas/blog/openstack-with-sunbeam-for-medium-scale-cloud-infrastructure"&gt; OpenStack Sunbeam&lt;/a&gt; and &lt;a href="https://canonical.com/data/spark"&gt;Apache Spark&lt;/a&gt;, allowing data engineers to run end-to-end pipelines on Arm-native silicon.&lt;/p&gt;
&lt;p&gt;In addition, Ubuntu serves as the host OS for &lt;a href="https://www.nvidia.com/en-us/data-center/mission-control/"&gt;NVIDIA Mission Control&lt;/a&gt; software, which accelerates every aspect of infrastructure operations — from configuring deployments and integrating with facilities to managing clusters and workloads.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Streamlined inference with Nemotron inference snaps&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Deploying large language models (LLMs) often involves complex dependency management and version conflicts. To solve this, Canonical has introduced &lt;a href="https://canonical.com/blog/canonical-releases-inference-snaps"&gt;inference snaps&lt;/a&gt;. In a recent &lt;a href="https://www.youtube.com/live/rR3TpJvM150?si=MNWEIdBTXz_B6Eeu"&gt;livestream with the NVIDIA Developer community&lt;/a&gt;, Canonical’s team presented inference snaps for DGX Spark, showing how a single snap install command brings silicon-optimized AI models to every Ubuntu machine. To further this effort, Canonical will be collaborating with the NVIDIA team on packaging and distribution of the NVIDIA Nemotron-3 family of open models, starting with Nano models. Packaging these models using inference snaps provides a containerized, immutable environment that includes all necessary libraries and runtimes, ensuring that it is optimized for the new NVIDIA platforms.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;BlueField-4 and scalable storage&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Performance of the Rubin platform is further amplified by its data pipeline. Canonical is recommitting to the NVIDIA BlueField-4 DPU as an important networking and security component of NVIDIA platforms. With 64 NVIDIA Grace CPU cores and 800G/s throughput, BlueField-4 makes scaling AI Factories even more efficient. Ubuntu serves as a foundational environment for &lt;a href="https://developer.nvidia.com/networking/doca"&gt;NVIDIA DOCA&lt;/a&gt;  – allowing for seamless offloading of networking, storage, and security tasks from the Vera CPU to the DPU.&lt;/p&gt;
&lt;p&gt;In collaboration with storage partners, Canonical is ensuring that Ubuntu’s storage subsystem is optimized for the GPUDirect Storage capabilities of BlueField-4. This enables high-speed data access between NVMe storage and Rubin GPU memory, eliminating bottlenecks. Whether deploying on-premises or in a sovereign cloud, the combination of Ubuntu and BlueField-4 provides the bare-metal isolation and hardware-root-of-trust necessary for secure, multi-tenant AI infrastructure.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Learn more&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Visit us at CES booth #10562 in LVCC, North Hall.&lt;/p&gt;
&lt;p&gt;Find out more about &lt;a href="https://ubuntu.com/nvidia"&gt;Canonical’s collaboration with NVIDIA.&lt;/a&gt;&lt;/p&gt;
</content:encoded><author>Canonical (Canonical)</author><category>AI</category><category>AI/ML</category><category>nvidia</category><category>NVIDIA AI Enterprise</category><category>Ubuntu</category><pubDate>Mon, 05 Jan 2026 23:15:00 +0000</pubDate></item><item><title>Meet Canonical at CES 2026: A trusted foundation for your device lifecycle</title><link>https://ubuntu.com//blog/canonical-at-ces-2026</link><description>&lt;p&gt;This year, the Canonical team will be at Booth #10562 in the North Hall, we will be demonstrating how Ubuntu Core, Ubuntu Pro for Devices, and our partner ecosystem help you accelerate development, ensure reliability, and simplify the lifecycle of your connected fleets.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;CES 2026 is here, bringing together the technologies defining the next generation of connected devices. With thousands of exhibitors showcasing everything from software-defined vehicles to industrial robotics, Canonical is focusing on a core challenge shared across these industries: how to scale deployments and maintain devices securely over the long term.&lt;/p&gt;
&lt;p&gt;This year, the Canonical team will be at Booth #10562 in the North Hall, we will be demonstrating how Ubuntu Core, Ubuntu Pro for Devices, and our partner ecosystem help you accelerate development, ensure reliability, and simplify the lifecycle of your connected fleets.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;Sneak peek: What you can expect at the Canonical booth this year&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;At our booth, we’re showcasing solutions that support the full device lifecycle, from secure production deployment and long-term maintenance to enabling AI workloads at the edge. Our experts will be on hand to walk through real-world use cases and architectures powering modern connected fleets.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Ubuntu Pro for Devices: Managing your device journey&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Security maintenance is a process, not a one-time fix. &lt;/p&gt;
&lt;p&gt;If you’ve been keeping up with the EU Cyber Resilience Act (CRA)  and its long list of requirements for potentially expensive long-term maintenance, you’re likely already on the lookout for partners or solutions who can help simplify compliance. We’ll be on-hand to introduce Ubuntu Pro for Devices, a comprehensive subscription service which comfortably delivers long-term security maintenance across device lifecycles in line with the most stringent security standards. &lt;/p&gt;
&lt;p&gt;Through automated patching and IoT OTA updates, Ubuntu Pro for Devices can help you bridge the gap between development and operations. This helps keep your embedded Linux deployments security-maintained for up to 15 years, helping you address regulations like the Cyber Resilience Act.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Ubuntu Core: Powering intelligent devices&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Reliability is the priority for embedded systems. At the Canonical booth, we’ll demonstrate this with Ubuntu Core, Canonical’s immutable, fully containerised operating system built for embedded and edge devices.&lt;/p&gt;
&lt;p&gt;Ubuntu Core uses strict application confinement and transactional updates to help ensure updates are applied safely, with a significantly reduced risk of failure. The operating system and applications are updated independently, helping devices remain stable and recoverable in production environments.&lt;/p&gt;
&lt;p&gt;Designed for long-term reliability in the field, Ubuntu Core provides a secure foundation for deploying, updating, and maintaining intelligent devices at scale.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;AI: Optimizing your workloads everywhere&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI workloads place different demands on infrastructure as they move from data centers to edge devices. Teams often need to balance performance, power use, hardware constraints, and long-term maintenance once systems are in production.&lt;/p&gt;
&lt;p&gt;At CES 2026, Canonical is showing how Inference Snaps and close work with silicon partners help address these challenges. The demo focuses on running AI inference efficiently across different hardware targets, while keeping deployments consistent and maintainable.&lt;/p&gt;
&lt;p&gt;Whether you are deploying computer vision pipelines or running large language models (LLMs) at the edge, Canonical helps you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Package AI inference workloads in a consistent, repeatable way&lt;/li&gt;
&lt;li&gt;Tune performance for specific hardware platforms&lt;/li&gt;
&lt;li&gt;Deploy and update models securely over the lifetime of a device fleet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This approach supports AI workloads that need to evolve over time, without rebuilding infrastructure for every hardware or model change.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canonical.com/solutions/ai" rel="noreferrer noopener" target="_blank"&gt;Learn more about Canonical’s approach to AI from cloud to edge&lt;/a&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Automotive: Driving the future&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The software-defined vehicle requires agility. &lt;a href="https://ubuntu.com/blog/future-of-infotainment-canonical-at-ces-2026"&gt;In our automotive showcase, we demonstrate how Anbox Cloud delivers Android infotainment with ultra-low latency using WebRTC streaming and support for 8K displays. &lt;/a&gt; Instead of relying on emulators or hardware-bound benches, you can deploy full Android IVI systems on any cloud and stream them to any screen in real time.&lt;/p&gt;
&lt;p&gt;By virtualizing Android Automotive OS in the cloud, we help OEMs and Tier 1 suppliers speed up infotainment development and testing on demand, without waiting for physical hardware. This brings the smartphone experience to the dashboard with greater efficiency.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;From high-performance robotics, to billions of AI quality control checks&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Our platform is only as strong as the ecosystem built upon it. This year, we are hosting demos with our partners who use Canonical solutions to solve real-world industry problems.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;NVIDIA: Witness the power of physical AI&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We are excited to participate in the NVIDIA Passport Program. Visit the Canonical booth to join in for a chance to win great prizes.&lt;/p&gt;
&lt;p&gt;We will showcase the CES 2026 Innovation Honoree, &lt;a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-thor/"&gt;NVIDIA Jetson Thor,&lt;/a&gt; running physical AI workloads. &lt;a href="https://canonical.com/blog/nvidia-jetson-thor-ubuntu-support?_gl=1*1xbybtf*_gcl_au*MTEyODY5NjM3NS4xNzYxMzgzNTExLjUwNzY5ODI0NS4xNzYyNzg5NTA2LjE3NjI3ODk1MDU.*_ga*ODQ5NzU4MTQ3LjE3NjQ0MTc4MjI.*_ga_5LTL1CNEJM*czE3NjQ1MTkwOTgkbzUkZzEkdDE3NjQ1MjUwMTQkajU1JGwwJGgw"&gt;This demo highlights how NVIDIA’s hardware and Ubuntu’s real-time kernel capabilities drive high-performance inference in robotics&lt;/a&gt;. Our booth will also feature &lt;a href="https://www.nvidia.com/en-us/products/workstations/dgx-spark/"&gt;NVIDIA DGX Spark &lt;/a&gt;with local inference and fine tuning, proving that enterprise-grade AI is accessible and scalable.&lt;/p&gt;
&lt;p&gt;For more information, please visit &lt;a href="https://www.nvidia.com/en-us/events/ces/"&gt;NVIDIA at CES 2026.&lt;/a&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="658" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F537c%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;br/&gt;&lt;strong&gt;Elementary: See industrial reliability in action&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical.com/case-study/elementary-ai-machine-vision"&gt;See AI-powered visual inspection in action with Elementary. &lt;/a&gt;We will feature a live AI vision system performing visual inspections on real-world parts. The demo shows how operators configure inspections, review results, and gain actionable insights through an intuitive interface, all running on Ubuntu Core.&lt;/p&gt;
&lt;p&gt;This all-in-one showcase demonstrates how Elementary uses the immutability and confinement of Ubuntu Core to deliver high-precision quality assurance on the factory floor. Visitors can also explore how inspection updates and new AI models are securely delivered over the air, enabling AI vision to move quickly from pilot to production.&lt;/p&gt;
&lt;p&gt;At scale, Ubuntu Core enables Elementary to manage thousands of edge devices across eight Fortune 500 manufacturers, performing more than 1 billion AI-powered inspections per year. &lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="1518" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6ed4%2Fimage-1.jpeg 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;The live system demonstrates how AI vision can quickly move from pilot to standard work&lt;/em&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Rightware: Experience the future of infotainment development &lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/blog/future-of-infotainment-canonical-at-ces-2026"&gt;In our automotive showcase, we are partnering with Rightware to demonstrate an integration between their Kanzi UI framework and Anbox Cloud.&lt;/a&gt; This demo illustrates how developers can visualize and test rich automotive user interfaces in the cloud, while streamlining the development cycle for next-generation cockpit experiences.&lt;/p&gt;
&lt;p&gt;Come see our high fidelity Kanzi-based UI cockpit rendered and streamed at 8K. This addresses the common pain point of infotainment developers: slow iteration caused by limited access to physical prototypes. &lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="900" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2be4%2Fimage.jpeg 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;Widescreen 8K infotainment CES demo&lt;/em&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Bosch Rexroth: Bridging IT and OT with ctrlX AUTOMATION&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Discover how Bosch Rexroth is removing the barriers between machine control, IT, and OT. We will showcase applications running on the ctrlX CORE, demonstrating the power of Ubuntu Core in an industrial setting.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canonical.com/blog/bosch-rexroth-adopts-ubuntu-core-and-snaps-for-app-based-ctrlx-automation-platform"&gt;With Ubuntu Core, ctrlX AUTOMATION apps run with strictly confined dependencies in snaps, ensuring isolation and stability.&lt;/a&gt; You will see how this architecture enables automated security updates and robust rollbacks, allowing machine builders to maintain reliability on the factory floor without needing manual engineering intervention.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Grundium: Meeting stringent medical security standards &lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical.com/case-study/grundium-ubuntu-pro-for-devices"&gt;See Grundium’s Ocus® microscope slide scanner and learn how it meets the rigorous demands of the medical industry.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Medical devices require a continuously monitored security posture, which is why Grundium uses &lt;strong&gt;Ubuntu Pro for Devices&lt;/strong&gt; to ensure their Ocus® scanners meet stringent requirements throughout their lifecycle. Built on a foundation of 150 open source components requiring rigorous risk analysis, these devices rely on Ubuntu Pro to secure a supply chain of over &lt;strong&gt;25,000 packages&lt;/strong&gt; with a single subscription. &lt;/p&gt;
&lt;p&gt;By using automated patching to enable up to &lt;strong&gt;10 years of support&lt;/strong&gt;, Grundium delivers a trustworthy platform for critical remote diagnostics, ensuring thousands of scanners remain operational worldwide without burdening their development teams&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;&lt;strong&gt;Join us at CES 2026&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Whether you are a decision-maker solving the puzzle of device lifecycle management, or you are interested in the future of embedded operating systems, our team of engineers and industry experts will be happy to discuss your specific challenges at Booth #10562, North Hall throughout the event. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date: January 6–9, 2026&lt;/li&gt;
&lt;li&gt;Venue: Las Vegas Convention Center (LVCC)&lt;/li&gt;
&lt;li&gt;Booth: #10562, North Hall&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don’t leave your CES 2026 experience to chance. Secure time with our team to discuss how we can help you build, deploy, and maintain your connected devices. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://calendar.app.google/ao4AHxoZWGkx4wsBA"&gt;&lt;strong&gt;Book a meeting with our team&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;More reading and resources&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical.com/solutions/iot-and-devices#get-in-touch"&gt;Contact Us&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canonical.com/solutions/iot-and-devices"&gt;Check out our IoT webpage&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://canonical.com/case-study/elementary-ai-machine-vision"&gt;Explore how Canonical helped Elementary deliver more than 1 billion inspections annually &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/blog/future-of-infotainment-canonical-at-ces-2026"&gt;Explore our Rightware CES 2026 showcase in the first blog of the series&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/nvidia"&gt;Check out the Enterprise-Ready AI solutions powered by Canonical and NVIDIA&lt;/a&gt;&lt;/p&gt;
</content:encoded><author>Canonical (Canonical)</author><category>CES</category><category>events</category><pubDate>Mon, 05 Jan 2026 14:27:10 +0000</pubDate></item><item><title>A better way to provision NVIDIA BlueField DPUs at scale with MAAS</title><link>https://ubuntu.com//blog/a-better-way-to-provision-nvidia-bluefield-dpus-at-scale-with-maas</link><description>&lt;p&gt;The recent release of MAAS 3.7 introduces a significant new capability: the ability to provision NVIDIA BlueField Data Processing Units (DPUs) directly through their Baseboard Management Controller (BMC),&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;MAAS 3.7 has been &lt;a href="https://canonical.com/maas/docs/release-notes-and-upgrade-instructions#p-9229-version-37-release-notes"&gt;officially released&lt;/a&gt; and it includes a bunch of cool new features. One of the capabilities that stands out most, without a doubt, is the support for NVIDIA Bluefield DPU provisioning directly through the Baseboard Management Controller (BMC).&lt;/p&gt;
&lt;p&gt;But, what are BlueField DPUs? This leads to a broader question: what are DPUs and SmartNICs, and why is the ability to provision them through the BMC a significant advancement?&lt;/p&gt;
&lt;p&gt;Let’s deep dive into all this.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;DPUs and SmartNICs&lt;/h2&gt;
&lt;p&gt;Today’s data centers face increasing demands: higher throughput, more tenants, rising security threats and the growing complexity of cloud-native environments. Traditional servers struggle when networking, storage, and security functions consume more and more CPU cycles intended for applications.&lt;/p&gt;
&lt;p&gt;This trend has driven the industry toward &lt;strong&gt;infrastructure hardware acceleration&lt;/strong&gt;, where specialised processors handle tasks traditionally executed by the host CPU. &lt;/p&gt;
&lt;p&gt;A SmartNIC was the logical solution, a Network Interface Card (NIC) enhanced with onboard compute and acceleration hardware. Unlike traditional NICs, which simply move packets, SmartNICs can process, filter, and &lt;strong&gt;accelerate data&lt;/strong&gt; directly on the card  before it ever reaches the host CPU.&lt;/p&gt;
&lt;p&gt;A Data Processing Unit (DPU) goes further. It is effectively a small, fully functional server on a PCIe card, with its own CPU cores, memory, operating system, security capabilities, and hardware offload engines. DPUs are designed to take over the entire &lt;strong&gt;infrastructure plane&lt;/strong&gt; (networking, storage, security and management) so that the host CPU can focus entirely on application workloads.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="530" loading="lazy" sizes="(min-width: 720px) 720px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_720/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp" srcset="https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 460w, https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 620w, https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 1036w, https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_720/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 720w" width="720"/&gt;&lt;/figure&gt;
&lt;p&gt;DPUs are increasingly common in cloud, telco, and high-performance environments such as AI training clouds. Typical use cases include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Network acceleration/offloading&lt;/strong&gt;: Implementing Software-Defined Networking (SDN) for OpenStack, LXD/MicroCloud, Kubernetes, and bare-metal, including distributed firewall functionality.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage acceleration/offloading&lt;/strong&gt;: running agents (like Ceph RBD) to present distributed storage as a standard device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secure root of trust&lt;/strong&gt;: providing authentication, attestation and isolation, and monitoring the host’s processes and network connections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes on the DPU&lt;/strong&gt;: using the DPU as a worker node for packaging and orchestrating network, storage, and security functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="wp-block-heading"&gt;NVIDIA Bluefield&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/"&gt;NVIDIA BlueField&lt;/a&gt; family is NVIDIA’s line of DPUs. This family showcases how NVIDIA has expanded from the original SmartNIC concept into a full platform that supports not only infrastructure offloads but also advanced telemetry, security analytics, and AI-centric workloads, all designed to free up host CPUs and accelerate core operations in modern and distributed data centers.&lt;/p&gt;
&lt;p&gt;BlueField-3 is particularly relevant here. It was the first DPU of the family that incorporated a Baseboard Management Controller (BMC), allowing remote monitoring and control of the DPU. A BMC is a dedicated, independent micro-controller embedded on a server’s motherboard (in this case embedded on the DPU) that provides out-of-band management capabilities. It enables administrators to remotely monitor hardware health (like temperature and power), control the server’s power state (turn it on/off or reboot), and access the console.&lt;/p&gt;
&lt;p&gt;This independence is what makes clean, automated provisioning possible.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;How should you provision a DPU: through the BMC or through the host?&lt;/h2&gt;
&lt;p&gt;Historically, DPUs were provisioned &lt;strong&gt;through the host&lt;/strong&gt;. The host OS booted first, ran vendor tools, and then configured or imaged the DPU. While workable for early deployments, this approach tightly couples the DPU lifecycle to the host, makes recovery harder, and becomes operationally fragile at scale.&lt;/p&gt;
&lt;p&gt;With a built-in BMC, a second option is available: provisioning the DPU directly &lt;strong&gt;through the BMC&lt;/strong&gt;. In this model, the DPU is treated like an independent server. The BMC can power it on, flash firmware, install an operating system, run configuration workflows, and make it operational, independently of the host.&lt;/p&gt;
&lt;p&gt;Benefits of BMC-based provisioning include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consistent “day-0” initialization&lt;/li&gt;
&lt;li&gt;Host-agnostic workflows (no dependency on a running OS)&lt;/li&gt;
&lt;li&gt;Easier recovery and re-provisioning&lt;/li&gt;
&lt;li&gt;Cleaner separation between host workloads and infrastructure functions, enabling a &lt;a href="https://ubuntu.com/blog/canonical-and-nvidia-bluefield-4-a-foundation-for-zero-trust-high-performance-infrastructure"&gt;zero-trust deployment model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Better suitability for large-scale or zero-touch environments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the provisioning method &lt;strong&gt;MAAS now supports&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;MAAS now supports BlueField provisioning through the BMC&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical.com/maas"&gt;MAAS (Metal as a Service)&lt;/a&gt; is Canonical’s open-source platform for managing physical servers with cloud-like automation. It provides a central place to discover, commission, deploy and repurpose machines. It offers repeatable workflows that make large-scale infrastructure easier to operate and an infrastructure-as-code approach to programmatically automate the whole data center.&lt;/p&gt;
&lt;p&gt;With the release of MAAS 3.7, BlueField DPUs can now be provisioned directly through their BMC. This allows MAAS to treat the DPU as an independent server, without relying on the host operating system to initialise or configure it. Behind the scenes, MAAS handles power control, device relationships, and the order of operations required to bring both the host and the DPU online correctly.&lt;/p&gt;
&lt;p&gt;Prior to this release, MAAS supported BlueField provisioning only through-the-host, meaning that MAAS needed the host to be provisioned and operational first, before even being able to provision the DPU. While functional, this approach made DPU lifecycle management dependent on the host and limited automation in larger environments.&lt;/p&gt;
&lt;p&gt;This new workflow gives operators a cleaner and more predictable way to manage DPUs. By integrating BlueField provisioning into standard MAAS processes, it becomes simpler to adopt DPUs across the data centre and maintain them consistently alongside the rest of the hardware fleet.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Get started with MAAS 3.7&lt;/h2&gt;
&lt;p&gt;You can start experimenting with BlueField provisioning today by installing or upgrading to MAAS 3.7. The easiest way to get started with MAAS is to follow the &lt;a href="https://canonical.com/maas/docs/maas-in-thirty-minutes"&gt;comprehensive 30-min tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For DPU provisioning details and supported workflows, check out the &lt;a href="https://canonical.com/maas/docs"&gt;MAAS documentation&lt;/a&gt; and the dedicated &lt;a href="https://discourse.maas.io/t/how-to-deploy-dpus-in-maas/15418"&gt;BlueField provisioning guide.&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;Give it a try and &lt;a href="https://canonical.com/maas#get-in-touch"&gt;let us know&lt;/a&gt; how it works in your environment.&lt;/p&gt;
&lt;p&gt;And if you are interested in getting Canonical’s support and compliance for MAAS, you can explore &lt;a href="https://ubuntu.com/pro"&gt;Ubuntu Pro&lt;/a&gt;, or &lt;a href="https://canonical.com/maas#get-in-touch"&gt;get in touch&lt;/a&gt; with our team. &lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://maas.io"&gt;Canonical MAAS (Metal as a Service)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://maas.io/tutorials/build-a-maas-and-lxd-environment-in-30-minutes-with-multipass-on-ubuntu"&gt;Build a MAAS and LXD environment in 30 minutes with Multipass on Ubuntu&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://maas.io/docs"&gt;MAAS documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>David Beamonte (David Beamonte)</author><category>bare metal</category><category>bluefield</category><category>data center</category><category>dpu</category><category>MAAS</category><pubDate>Fri, 19 Dec 2025 17:14:05 +0000</pubDate></item><item><title>MicroCeph: why it’s the superior MinIO alternative (and how to use it)</title><link>https://ubuntu.com//blog/microceph-why-its-the-superior-minio-alternative</link><description>&lt;p&gt;Recently, the team at MinIO moved the open source project into maintenance mode and will no longer accept any changes. That means that no new features or enhancements will be added to MinIO, and existing issues &amp;#8212; according to the update &amp;#8212; will not be actively considered. Whilst MinIO brought a solid developer-friendly approach to [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Recently, the team at MinIO moved the open source project into &lt;a href="https://github.com/minio/minio/commit/27742d469462e1561c776f88ca7a1f26816d69e2"&gt;maintenance mode&lt;/a&gt; and will no longer accept any changes. That means that no new features or enhancements will be added to MinIO, and existing issues — according to the update — will not be actively considered. Whilst MinIO brought a solid developer-friendly approach to object storage (S3) for many years, this update means that the project is unlikely to keep up with advancements in storage tech.  So, for developers hoping to stay at the cutting edge of object storage, and to take advantage of block and file storage, what’s the next step?&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="2250" loading="lazy" sizes="(min-width: 4000px) 4000px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_4000/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 1920w" width="4000"/&gt;&lt;/figure&gt;
&lt;p&gt;Ceph has set the standard as the trusted, production-worthy open source storage for over a decade. However, some users have found the upstream tooling complex to use; so, a couple of years ago we introduced MicroCeph as an opinionated and simple way to deploy Ceph.&lt;/p&gt;
&lt;p&gt;Despite the Micro name, there’s nothing missing. MicroCeph is fully-featured Ceph, with the same scale-out architecture, and block (RBD), file (CephFS, NFS), and object (S3, Swift) protocols. The positive difference is that MicroCeph offers simpler deployment, scaling, and day-2 operations. &lt;/p&gt;
&lt;p&gt;Since its release, adoption of MicroCeph has spread far and wide. Now, you’ll find it deployed in everything from single-node development environments and CI pipelines, to production-scale multi-PetaByte deployments, enabling organisations to manage ever increasing data storage needs. For developers looking for a MinIO alternative, MicroCeph could work for you.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Setting up your MinIO alternative: how to get started with MicroCeph&lt;/h2&gt;
&lt;p&gt;In this tutorial, we’ll walk through the steps to get a single node Ceph cluster up and running. We’ll also explain how to enable RGW (Rados Gateway), so that you can use the S3 API like you might have done with MinIO.&lt;/p&gt;
&lt;p&gt;First you’ll need a single node or VM to try things out. And with MicroCeph being delivered as a Snap, you don’t have to be using Ubuntu OS – any Linux machine with snapd will work!&lt;/p&gt;
&lt;p&gt;Begin by installing the latest stable version of MicroCeph:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo snap install microceph --channel=squid/stable&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once the snap is downloaded and installed, we need to initialize the Ceph cluster:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph cluster bootstrap&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can then check to see if the bootstrap was completed successfully: &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo ceph status&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You should see output similar to the example below. Don’t worry about HEALTH_WARN at this stage, that’s expected as we only have a single Monitor (MON) in the cluster and no Object Storage Daemons (OSDs).&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="520" loading="lazy" sizes="(min-width: 844px) 844px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_844/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_844/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 844w" width="844"/&gt;&lt;/figure&gt;
&lt;p&gt;Like any storage system, Ceph needs some disks to make it useful. In this scenario, we’ll add one file-based disk to get started. That’s perfect for testing and CI – but not ideal in production. For that you should use real disks, i.e. flash or spinning media. Find out more about which disks to use for MicroCeph in &lt;a href="http://microceph.com/"&gt;our documentation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;To add a file-based disk, input the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph disk add loop,4G,1&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once again, we can check the status of the cluster. Here we can see that the OSD has been successfully added.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="520" loading="lazy" sizes="(min-width: 868px) 868px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_868/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_868/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 868w" width="868"/&gt;&lt;/figure&gt;
&lt;p&gt;One more step that we need to carry out in this test, or demonstration configuration is to adjust the replication factor. This should &lt;strong&gt;never be done in production&lt;/strong&gt;, or with data that you care about: if the single disk fails, you will encounter data loss.&lt;/p&gt;
&lt;p&gt;To adjust the replication factor, input the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph pool set-rf "" --size=1&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="658" loading="lazy" sizes="(min-width: 1024px) 1024px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1024/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1024/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1024w" width="1024"/&gt;&lt;/figure&gt;
&lt;p&gt;While there is a warning, this can be ignored for now, as this is just a test environment.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Enabling RGW&lt;/h2&gt;
&lt;p&gt;The next step is to enable RGW so that we can use the S3 API.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph enable rgw&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MicroCeph will take care of several things in this step: it’ll deploy the RGW daemon and create the pools needed for object meta-data and the objects themselves.&lt;/p&gt;
&lt;p&gt;We can see those cluster changes by checking the cluster status again:&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="642" loading="lazy" sizes="(min-width: 974px) 974px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_974/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_974/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 974w" width="974"/&gt;&lt;/figure&gt;
&lt;p&gt;And also by listing the pools in the cluster:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo ceph osd pool ls&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="210" loading="lazy" sizes="(min-width: 792px) 792px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_792/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_792/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 792w" width="792"/&gt;&lt;/figure&gt;
&lt;p&gt;Next, create a RGW user so that we can grant access to storage in the cluster:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo radosgw-admin user create --uid=user --display-name=user&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The command will provide output like the example below. Your application will need the access_key and secret_key to interact with the cluster – for example, to create buckets, as well as uploading and downloading objects.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="506" loading="lazy" sizes="(min-width: 1338px) 1338px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1338/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1338/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1338w" width="1338"/&gt;&lt;/figure&gt;
&lt;p&gt;We can quickly find out the IP address of the RGW by checking MicroCeph’s status:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph status&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="182" loading="lazy" sizes="(min-width: 784px) 784px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_784/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_784/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 784w" width="784"/&gt;&lt;/figure&gt;
&lt;p&gt;And then we can test the API endpoint using curl:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;curl http://&amp;lt;IP Address&amp;gt;&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="118" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p&gt;Here we can see that the API endpoint is responding – ready for you to create buckets, and start uploading and downloading files.&lt;/p&gt;
&lt;p&gt;There are many ways of interacting with object storage. Tools like &lt;a href="https://github.com/s3tools/s3cmd"&gt;s3cmd&lt;/a&gt;, &lt;a href="https://github.com/boto/boto3"&gt;boto3&lt;/a&gt;, &lt;a href="https://github.com/peak/s5cmd"&gt;s5cmd&lt;/a&gt; or &lt;a href="https://cyberduck.io/s3/"&gt;cyberduck&lt;/a&gt; are all popular. Alternatively, your application may accept the access and secret keys to directly manage objects stored in an S3 compatible bucket.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;MicroCeph beyond a MinIO alternative&lt;/h2&gt;
&lt;p&gt;Of course, this tutorial only provides a taster of what Ceph is capable of. Scaling up from one node is a very simple process, and ultimately, the cluster can be scaled to multiple petabytes if needed. And unlike MinIO, no other solution is needed if you require Block or File storage too! Find out how to perform a multi-node install in &lt;a href="https://canonical-microceph.readthedocs-hosted.com/v19.2.0-squid/how-to/multi-node/"&gt;our documentation&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;The great thing about the MicroCeph snap is that, as part of Ubuntu and Canonical’s Long Term Support (LTS) commitment, it can be supported for up to 15 years from the release of the LTS. If you’re curious to find out how you can use MicroCeph in the long term, try our blog &lt;a href="https://canonical.com/blog/storage-for-kubernetes"&gt;explaining how to use MicroCeph as Kubernetes storage&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Philip Williams (Philip Williams)</author><category>ceph</category><category>Storage</category><pubDate>Fri, 19 Dec 2025 08:26:00 +0000</pubDate></item><item><title>Design and Documentation clinics at FOSDEM Fringe 2026</title><link>https://ubuntu.com//blog/design-and-documentation-clinics-at-fosdem-fringe-2026</link><description>&lt;p&gt;FOSDEM is one of the biggest and most exciting open source events of the year, held at the Solbosch campus of the Université Libre de Bruxelles (Brussels), Belgium. Thousands of open source contributors and enthusiasts attend, often with several folks from Canonical among them. The next one is coming quickly, with FOSDEM 2026 being held [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;&lt;a href="https://fosdem.org/2026/"&gt;FOSDEM&lt;/a&gt; is one of the biggest and most exciting open source events of the year, held at the Solbosch campus of the Université Libre de Bruxelles (Brussels), Belgium.&lt;/p&gt;
&lt;p class="has-medium-font-size"&gt;Thousands of open source contributors and enthusiasts attend, often with several folks from Canonical among them. The next one is coming quickly, with FOSDEM 2026 being held across the weekend of &lt;strong&gt;January 31st – February 1st&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For the first time, a few of us from the Design and Documentation teams at Canonical are going to both attend and &lt;em&gt;organize&lt;/em&gt; a&lt;strong&gt; free&lt;/strong&gt; &lt;a href="https://fosdem.org/2026/fringe/"&gt;FOSDEM Fringe&lt;/a&gt;&lt;strong&gt; &lt;/strong&gt;event&lt;strong&gt; &lt;/strong&gt;on &lt;strong&gt;Monday February 2nd&lt;/strong&gt;, between 09:00 and 17:00.  Anyone who needs help with their open source work is invited, as are unaffiliated individuals who want to learn more about either Design or Documentation.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;How we can help&lt;/h3&gt;
&lt;p&gt;Our fringe event includes both Design and Documentation clinics where attendees can ask questions and get the help they need to fix a problem, get a review, or create a solution. Items you might want to consider include:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Design clinic:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;UX/UI reviews:&lt;/strong&gt; Professional feedback on your CLI or GUI.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Workflow optimization:&lt;/strong&gt; Streamline how users interact with your tool.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualization:&lt;/strong&gt; Learn how to create and share your ideas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt; &lt;strong&gt;clinic:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Structure and strategy:&lt;/strong&gt; Organize and plan your content for better navigability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tooling setup:&lt;/strong&gt; Pick and configure the right documentation tools.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Onboarding:&lt;/strong&gt; Make it easier for new contributors to join.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But these are just a guide. We’re up for any challenge!&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Register now&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;When: &lt;/strong&gt;Monday 2nd February, between 09:00 and 17:00. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where&lt;/strong&gt;: &lt;a href="https://www.workatfirma.be/"&gt;Firma&lt;/a&gt;, Brussels.&lt;/p&gt;
&lt;p&gt;To give us some idea of numbers, we’re asking anyone who may want to attend to register their interest first. Please fill in the following form and we’ll be in touch:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSfJLEIb5zZ3gggdIWQiB6X2asTIEJ_07CPV077blzf9YJ0HCQ/viewform"&gt;&lt;strong&gt;Documentation and Design Clinic @FOSDEM Fringe Attendance Form&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;Questions? Find us on Matrix at &lt;/strong&gt;&lt;a href="https://matrix.to/#/#design:ubuntu.com"&gt;&lt;strong&gt;#design:ubuntu.com&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; and &lt;/strong&gt;&lt;a href="https://matrix.to/#/#documentation:ubuntu.com"&gt;&lt;strong&gt;#documentation:ubuntu.com&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;
</content:encoded><author>Graham Morrison (Graham Morrison)</author><category>Design</category><category>documentation</category><category>Event</category><pubDate>Thu, 18 Dec 2025 09:24:45 +0000</pubDate></item><item><title>Extending ROS Noetic Support with ESM-Enabled Content Snaps</title><link>https://ubuntu.com//blog/extending-ros-noetic-support-with-esm-enabled-content-snaps</link><description>&lt;p&gt;Canonical has now extended its ESM (Expanded Security Maintenance) for ROS coverage to ROS Noetic content-sharing snaps. With ESM for ROS now available in both deb and snap formats, Ubuntu continues to be the trusted foundation for secure, long-term robotics innovation.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Since ROS Noetic reached end of life in May 2025, the Ubuntu Robotics team has been working to ensure that developers and organizations can continue building and deploying robots securely on Ubuntu.&lt;/p&gt;
&lt;p&gt;To build on this foundation, Canonical has now &lt;strong&gt;extended its &lt;/strong&gt;&lt;a href="https://ubuntu.com/blog/ros-noetic-is-eol-take-action-to-maintain-fleet-security"&gt;&lt;strong&gt;ESM (Expanded Security Maintenance) for ROS&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; coverage to ROS Noetic content-sharing snaps.&lt;/strong&gt; This update is a significant step toward long-term support and security for ROS environments distributed through the Snap ecosystem, ensuring developers can continue to rely on maintained and compatible components.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;What are content-sharing snaps?&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/explanations/snaps/ros-architectures-with-snaps/#multi-snaps-using-content-sharing"&gt;Content-sharing snaps&lt;/a&gt; are a key feature of the Snap ecosystem that allow multiple snaps to share common dependencies, such as ROS libraries, tools, and assets, without duplication. This model simplifies packaging, improves consistency, and reduces image size across robotic systems. You can learn more about the benefits of following a modular architecture for your ROS robots &lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/explanations/snaps/ros-architectures-with-snaps/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Ubuntu Robotics team maintains several content-sharing snaps on the &lt;a href="https://snapcraft.io/publisher/ubuntu-robotics-community"&gt;Snap Store&lt;/a&gt; – such as &lt;a href="https://snapcraft.io/ros-noetic-desktop"&gt;&lt;em&gt;ros-noetic-desktop&lt;/em&gt;&lt;/a&gt; and &lt;a href="https://snapcraft.io/ros-noetic-ros-base"&gt;&lt;em&gt;ros-noetic-ros-base&lt;/em&gt;&lt;/a&gt; – which serve as the foundation for many ROS-based applications.&lt;/p&gt;
&lt;p&gt;With ESM now integrated, these content &lt;strong&gt;snaps continue to receive security updates and maintenance&lt;/strong&gt;, ensuring developers can build and deploy with confidence as ROS 1 transitions into its long-term maintenance phase. What’s more, this benefit is free – no Pro token is required.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Why this matters&lt;/h2&gt;
&lt;p&gt;Robotics projects often have long lifecycles, where stability and security are critical. While ROS Noetic is no longer maintained upstream, Canonical’s ESM for ROS service delivers ongoing CVE patches and security fixes for both ROS and Ubuntu packages.&lt;/p&gt;
&lt;p&gt;By extending ESM for ROS to content-sharing snaps, we’re &lt;strong&gt;giving developers the same long-term security guarantees in the snap ecosystem&lt;/strong&gt; that they already rely on in Ubuntu’s ESM for deb packages. This means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Continued security maintenance for ROS Noetic environments distributed through snaps.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;A unified and consistent experience across both deb-based and snap-based systems.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Easier access to maintained ROS libraries for new and existing robotic deployments.&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="wp-block-heading"&gt;Continuing long-term support for the ROS community&lt;/h2&gt;
&lt;p&gt;This update reflects Canonical’s ongoing commitment to the ROS ecosystem – helping developers and organizations extend the life of their robots securely and sustainably. With ESM for ROS now available in both deb and snap formats, Ubuntu continues to be the trusted foundation for secure, long-term robotics innovation.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Learn more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/explanations/security/what-is-ros-esm/"&gt;What is ESM for ROS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/tutorials/snaps-core/building-ros-snaps-with-content-sharing/"&gt;Tutorial: Building ROS snaps with content sharing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canonical.com/blog/ros-enterprise-support-15-things-you-need-to-know"&gt;ESM for ROS: 15 things you need to know&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Florencia Cabral Berenfus (Florencia Cabral Berenfus)</author><category>devices</category><category>ESM for ROS</category><category>robotics</category><category>ROS</category><category>Security</category><pubDate>Wed, 17 Dec 2025 20:38:28 +0000</pubDate></item><item><title>Native integration available between Canonical LXD and HPE Alletra MP B10000</title><link>https://ubuntu.com//blog/canonical_lxd_hpe_alletra</link><description>&lt;p&gt;Native integration available between Canonical LXD and HPE Alletra MP B10000. The integration combines efficient open source virtualization with high performance, enterprise-grade storage&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;The integration combines efficient open source virtualization with high performance, enterprise-grade storage&lt;/p&gt;
&lt;p&gt;We are pleased to announce a new,  native integration between Canonical LXD and HPE Alletra. This integration brings together Canonical’s securely designed, open source virtualization platform with HPE’s enterprise-grade storage to deliver a simple, scalable, high-performance experience. &lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Enterprise-grade storage meets efficient open source virtualization&lt;/h1&gt;
&lt;p&gt;HPE Alletra is designed to deliver mission-critical storage at mid range economics, with a consistent data experience across various cloud environments. With this integration, Canonical LXD and MicroCloud users can now provision and manage Alletra block storage directly through the LXD interface, without the need for any third-party plugins or additional abstraction layers. &lt;/p&gt;
&lt;p&gt;The integration enables users to seamlessly create, attach, snapshot, and manage thin-provisioned block volumes as easily as working with local storage, while retaining the full performance, resilience, and enterprise data services of HPE Alletra. &lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="949" loading="lazy" sizes="(min-width: 1571px) 1571px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1571/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1571/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1571w" width="1571"/&gt;&lt;/figure&gt;
&lt;h1 class="wp-block-heading"&gt;Simplified operations and scalable performance&lt;/h1&gt;
&lt;p&gt;HPE Alletra NVMe-based architecture ensures sub-millisecond latency for demanding workloads, with built-in services such as thin-provisioning and data deduplication minimizing storage costs while maintaining consistent performance. Paired with LXD’s lightweight control plane and streamlined UI, users can easily operate their environments, combining the best of open source with enterprise storage functionality.&lt;/p&gt;
&lt;p&gt;As demands grow, new volumes and storage capacity can be allocated on the fly. Alletra’s scale-out, modular architecture ensures the platform can expand without disrupting running workloads. &lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;A foundation for modern infrastructure deployments &lt;/h1&gt;
&lt;p&gt;LXD provides a unified open source virtualization platform to run system containers and virtual machines with a focus on efficiency, security, and ease of management. With native support for HPE Alletra, enterprises can now build, deploy, and manage their workloads with enterprise storage guarantees, whether in private clouds, on-premises data centers, or edge environments. &lt;/p&gt;
&lt;p&gt;The combined solution empowers teams to deliver predictable performance for critical and data-intensive workloads while reducing complexity and ensuring agility.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Availability&lt;/h1&gt;
&lt;p&gt;The integration between LXD and HPE Alletra is available starting with the &lt;a href="https://documentation.ubuntu.com/lxd/latest/reference/release-notes/release-notes-6.6/"&gt;LXD 6.6 feature release&lt;/a&gt;, and requires a HPE Alletra WSAPI version 1. LXD currently supports connecting to HPE Alletra storage through NVMe/TCP or iSCSI protocols. For detailed information, visit &lt;a href="https://documentation.ubuntu.com/lxd/stable-5.21/reference/storage_alletra/"&gt;Canonical’s LXD documentation&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Miona Aleksic (Miona Aleksic)</author><category>HPE</category><category>LXD</category><category>microcloud</category><pubDate>Mon, 15 Dec 2025 15:57:28 +0000</pubDate></item><item><title>Why you should retire your Microsoft Azure Consumption Commitment (MACC) with Ubuntu Pro</title><link>https://ubuntu.com//blog/retire-azure-consumption-commitment-macc-ubuntu-pro</link><description>&lt;p&gt;Fulfilling your Microsoft Azure Consumption Commitment (MACC) requires efficient planning. Discover how allocating your MACC to Ubuntu Pro allows you to meet consumption goals while securing your open source supply chain and automating compliance.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;When your organization first signed its Microsoft Azure Consumption Commitment (MACC), it was a strategic step to unlock better pricing and enable cloud growth. However, fulfilling that commitment efficiently requires planning. Organizations often look for ways to retire their MACC that drive strategic value, rather than simply increasing consumption to meet a deadline.&lt;/p&gt;
&lt;p&gt;The goal is to meet your commitment while delivering long-term benefits to the business.&lt;/p&gt;
&lt;p&gt;With Ubuntu Pro in the Azure Marketplace, you can retire your MACC at 100% of the pretax purchase amount. In practice, this allows you to meet consumption goals on your standard Azure invoice, while securing your open source supply chain and automating compliance.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Turn a spend target into an open source security strategy&lt;/h1&gt;
&lt;p&gt;Instead of simply increasing consumption to hit a target, effective IT and FinOps teams align their MACC with broader strategic goals. Open source support and security maintenance is a priority for enterprises, as a &lt;a href="https://pages.ubuntu.com/rs/066-EOV-335/images/Final%20report%20-%20WorldofOS_EUSpotlight_2025_081525.pdf?version=0&amp;amp;_gl=1*tbk0ic*_gcl_au*MjAyODc1NDE5My4xNzU0OTk1ODU4"&gt;recent Linux Foundation report&lt;/a&gt; shows: 54% of enterprises want long-term guarantees, and 53% expect rapid security patching.&lt;/p&gt;
&lt;p&gt;Ubuntu Pro offers both. By choosing software that strengthens your security and operations, you can retire your MACC while funding capabilities your organization prioritizes.&lt;/p&gt;
&lt;p&gt;Allocating MACC to Ubuntu Pro is a direct investment in your open source estate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Expanded Security Maintenance (ESM)&lt;/strong&gt;: extend security coverage to the critical open source applications running above the operating system layer. ESM provides up to 15 years of security updates for the OS, plus tens of thousands of packages. You might already see alerts for these missing updates in your Azure portal – learn how to check your exposure in our blog: [&lt;a href="https://ubuntu.com/blog/ubuntu-lts-vm-azure-security-view"&gt;A complete security view for every Ubuntu LTS VM on Azure&lt;/a&gt;].&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kernel Livepatch&lt;/strong&gt;: reduce maintenance windows by applying critical kernel patches without requiring a reboot for most workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compliance tooling&lt;/strong&gt;: access options for CIS hardening and FIPS 140-3 validated cryptographic modules to support meeting compliance and regulatory needs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optional enterprise support&lt;/strong&gt;: add enterprise SLAs, direct access to Canonical engineers for break-fix and bug-fix, and guidance on operating Ubuntu and ESM-covered packages on Azure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By choosing Ubuntu Pro, you convert your MACC spend into a maintained open source foundation across the development lifecycle.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Maximize value and streamline procurement&lt;/h1&gt;
&lt;p&gt;Retiring your commitment should be financially efficient and administratively simple. While standard Marketplace listings are MACC-eligible, many organizations use p&lt;a href="https://learn.microsoft.com/en-us/marketplace/private-offers-overview"&gt;rivate offers&lt;/a&gt; to secure tailored commercial terms, like custom pricing or volume discounts, without sacrificing eligibility.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;We support both standard private offers and multiparty private offers for rollouts involving resellers in the US/UK. In all cases, checking that your purchase counts toward your commitment is straightforward:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Confirm Eligibility&lt;/strong&gt;: verify the listing or private offer is marked as “Azure benefit-eligible.”&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Purchase Correctly&lt;/strong&gt;: execute the transaction in the Azure portal under the tenant and subscription tied to your MACC agreement.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This approach guarantees that every dollar spent satisfies your financial goals while delivering the specific security coverage your organization needs.&lt;/p&gt;
&lt;p&gt;Ready to align Ubuntu Pro with your MACC? &lt;a href="https://ubuntu.com/azure/contact-us"&gt;Talk to our team&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Jehudi (Jehudi)</author><pubDate>Sat, 13 Dec 2025 00:07:17 +0000</pubDate></item><item><title>How to launch a Deep Learning VM on Google Cloud</title><link>https://ubuntu.com//blog/how-to-launch-a-deep-learning-vm-on-google-cloud</link><description>&lt;p&gt;Setting up a local Deep Learning environment can be a headache. Between managing CUDA drivers, resolving Python library conflicts, and ensuring you have enough GPU power, you often spend more time configuring than coding. Google Cloud and Canonical work together to solve this with Deep Learning VM Images, which use Ubuntu Accelerator Optimized OS as [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Setting up a local Deep Learning environment can be a headache. Between managing CUDA drivers, resolving Python library conflicts, and ensuring you have enough GPU power, you often spend more time configuring than coding.&lt;/p&gt;
&lt;p&gt;Google Cloud and Canonical work together to solve this with &lt;a href="https://console.cloud.google.com/marketplace/details/click-to-deploy-images/deeplearning"&gt;Deep Learning VM Images&lt;/a&gt;, which use Ubuntu Accelerator Optimized OS as the base OS. These are pre-configured virtual machines optimized for data science and machine learning tasks. They come pre-installed with popular frameworks, such as PyTorch, and the necessary NVIDIA drivers.&lt;/p&gt;
&lt;p&gt;In this guide, I’ll walk you through how to launch a Deep Learning VM on GCP using the Console, and how to verify your software stack so you can start training immediately.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Why use a Deep Learning VM?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pre-installed frameworks:&lt;/strong&gt; No need to pip install generic libraries manually.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPU-ready:&lt;/strong&gt; NVIDIA drivers are pre-installed and verified.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter integration:&lt;/strong&gt; Seamless access to JupyterLab right out of the box.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 class="wp-block-heading"&gt;How to make a Deep Learning VM in GCP&lt;/h1&gt;
&lt;h2 class="wp-block-heading"&gt;Step 1: Navigate to the GCP Marketplace&lt;/h2&gt;
&lt;p&gt;First, log in to your Google Cloud Console. Instead of creating a generic Compute Engine instance, we want to use a specialized image from the Marketplace.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open the&lt;a href="https://console.cloud.google.com"&gt; Google Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In the search bar at the top, type &lt;strong&gt;“Deep Learning VM”&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Select the product named &lt;strong&gt;Deep Learning VM&lt;/strong&gt; published by Google.&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="538" loading="lazy" sizes="(min-width: 1448px) 1448px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1448/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1448/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1448w" width="1448"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Step 2: Configure your instance&lt;/h2&gt;
&lt;p&gt;Once you are on the Marketplace Deep Learning VM listing page, click &lt;strong&gt;Launch&lt;/strong&gt;. This will take you to the deployment configuration screen. This is where you define the power behind your model.&lt;/p&gt;
&lt;p&gt;Here are the key settings you need to pay attention to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Zone:&lt;/strong&gt; Make sure to select a zone that supports the specific GPU you want to use (in my case, I selected the us-central1-f zone).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Type:&lt;/strong&gt; Choose a CPU/RAM combination that meets your requirements if you don’t need a GPU.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPU Type:&lt;/strong&gt; You can add your GPU type, such as the NVIDIA T4, A100, or H100. &lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="585" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;Configuring the VM instance in the Google Cloud Console.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Once you have made your selections, click &lt;strong&gt;Deploy&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Step 3: Connect and verify&lt;/h2&gt;
&lt;p&gt;After a minute or two, your VM will be deployed. You can find it listed in your &lt;strong&gt;Compute Engine &amp;gt; VM Instances&lt;/strong&gt; page.&lt;/p&gt;
&lt;p&gt;To access the machine, click the &lt;strong&gt;SSH&lt;/strong&gt; button next to your new instance. This opens a terminal window directly in your browser.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="497" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Step 4: Check the software stack &amp;amp; drivers&lt;/h2&gt;
&lt;p&gt;Now, let’s make sure everything is working under the hood.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;1. Verify NVIDIA drivers&lt;/h3&gt;
&lt;p&gt;If you have attached a GPU, the most important check is to ensure the drivers have loaded correctly. Run the following command in your SSH terminal:&lt;/p&gt;
&lt;p&gt;nvidia-smi&lt;/p&gt;
&lt;p&gt;You should see a table listing your GPU (e.g., A100) and the CUDA version.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="691" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h3 class="wp-block-heading"&gt;2. Check pre-installed software&lt;/h3&gt;
&lt;p&gt;Google’s Deep Learning VMs usually come with PyTorch pre-configured. You can check the installed packages to ensure your favorite libraries are there:&lt;/p&gt;
&lt;p&gt;pip show torch&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="391" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;And that’s it! In just a few minutes, you have built a fully configured Deep Learning environment. You can now start running training scripts directly from the terminal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don’t forget:&lt;/strong&gt; Deep Learning VMs with GPUs can be expensive. Remember to &lt;strong&gt;stop&lt;/strong&gt; your instance when you aren’t using it to avoid unexpected charges!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://documentation.ubuntu.com/gcp/google-explanation/canonical-offerings/"&gt;Learn  more about Canonical’s offerings on GCP&lt;/a&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Read more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ubuntu.com/gcp"&gt;Ubuntu on Google Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discourse.ubuntu.com/t/optimizing-ai-workloads-with-ubuntu-ai-images/67099"&gt;Optimizing AI workloads with Ubuntu AI images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Hugo Huang (Hugo Huang)</author><category>accelerator</category><category>deep learning</category><category>Google Cloud</category><pubDate>Thu, 11 Dec 2025 14:31:00 +0000</pubDate></item><item><title>Harnessing the potential of 5G with Kubernetes: a cloud-native telco transformation perspective</title><link>https://ubuntu.com//blog/harnessing-the-potential-of-5g-with-kubernetes-a-cloud-native-telco-transformation-perspective</link><description>&lt;p&gt;Telecommunications networks are undergoing a cloud-native revolution. 5G promises ultra-fast connectivity and real-time services, but achieving those benefits requires an infrastructure that is agile, low-latency, and highly reliable. Kubernetes has emerged as a cornerstone for telecom operators to meet 5G demands. In 2025, Canonical Kubernetes delivers a single, production-grade Kubernetes platform with long-term support (LTS) [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Telecommunications networks are undergoing a cloud-native revolution. 5G promises ultra-fast connectivity and real-time services, but achieving those benefits requires an infrastructure that is agile, low-latency, and highly reliable. Kubernetes has emerged as a cornerstone for telecom operators to meet 5G demands. In 2025, Canonical Kubernetes delivers a single, production-grade Kubernetes platform with long-term support (LTS) and telco-specific optimizations, deployable across clouds, data centers, and the far edge.&lt;/p&gt;
&lt;p&gt;This blog explores how Canonical Kubernetes empowers 5G and cloud-native telco workloads with high performance, enhanced platform awareness (EPA), and robust security, while offering flexible deployment via snaps, Juju, or Cluster API. We’ll also highlight its integration into industry initiatives like Sylva, support for GPU/DPU acceleration, and synergy with MicroCloud for scalable edge infrastructure.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;The rise of the cloud-native telco&lt;/h1&gt;
&lt;p&gt;Telecom decision-makers face immense pressure to evolve their networks rapidly and cost-effectively. Traditional, hardware-centric architectures struggle to keep pace with 5G’s requirements for low latency, high throughput, and dynamic scaling. This is where Kubernetes – the de facto platform for cloud-native applications – comes in. Kubernetes brings powerful automation, scalability, and resiliency that allow telcos to manage network functions like software across data centers, public clouds, and far-edge deployments. The result is a more agile operational model: services can be rolled out faster, resources automatically optimized to demand, and updates applied continuously without disrupting critical services. In the 5G era, such agility is essential for delivering innovations like network slicing, multi-access edge computing (MEC), and AI-driven services.&lt;/p&gt;
&lt;p&gt;At the same time, Kubernetes opens the door for telcos to refactor their network functions into microservices. Instead of relying on monolithic appliances or heavy virtual machines, operators can deploy &lt;em&gt;cloud-native network functions (CNFs)&lt;/em&gt; – essentially containerized network services – that are lighter and faster to roll out than traditional virtual network functions (VNFs). By shifting to CNFs, new network features (whether a 5G core component or a firewall) can be introduced or updated in a fraction of the time, using automated CI/CD pipelines instead of lengthy manual upgrades. This approach helps telcos simplify the migration from legacy systems to a more agile, software-driven network model.&lt;/p&gt;
&lt;p&gt;However, adopting Kubernetes for telecom workloads also means meeting rigorous performance and reliability standards. Carrier-grade services like voice, video, and core network functions can’t tolerate unpredictable delays or downtime. Telco leaders need a Kubernetes platform that combines cloud-native flexibility with &lt;em&gt;telco-grade&lt;/em&gt; performance, security, and support. Canonical Kubernetes answers that call, providing a Kubernetes distribution specifically tuned for telecommunications needs.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Canonical Kubernetes: optimized for cloud-native 5G networks and edge computing&lt;/h1&gt;
&lt;p&gt;Canonical’s Kubernetes distribution has been engineered from the ground up to address the unique challenges of 5G and cloud-native telco cloud deployments. It is a single, unified Kubernetes offering that blends the ease of use of lightweight deployments with the robustness of an enterprise-grade platform. Importantly, Canonical Kubernetes can be deployed and managed in whatever way best fits a telco’s environment – whether installed as a secure snap package or integrated with full automation tooling like Juju (model-driven operations) or Kubernetes Cluster API (CAPI). This flexibility means operators can start small at the network edge or scale up to carrier-core clusters, all using the same consistent platform. Notably, Canonical Kubernetes brings cloud-native telco-friendly capabilities in the areas of performance, networking, operations, and support:&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;High performance &amp;amp; low latency&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/engage/an-introduction-to-real-time-linux-part-i"&gt;Real-time linux kernel&lt;/a&gt; support ensures that high-priority network workloads execute with predictable, ultra-low latency, a critical requirement for functions like the 5G user plane function (UPF). In parallel, built-in support for advanced networking (including SR-IOV and DPDK) enables fast packet processing by giving containerized network functions direct access to hardware, dramatically reducing network I/O latency for high bandwidth 5G applications. Together, these features allow cloud-native network functions to meet stringent performance and determinism once only achievable on specialized telecom hardware.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;GPU acceleration&lt;/h3&gt;
&lt;p&gt;Canonical Kubernetes integrates seamlessly with acceleration technologies to support emerging cloud-native telco workloads. It works with NVIDIA’s GPU and networking operators to leverage hardware accelerators (GPUs, SmartNICs, DPUs) for intensive tasks. It supports NVIDIA’s Multi-Instance GPU (MIG), which expands the performance and value of the NVIDIA’s data center GPUs, such as the latest GB200 and RTX PRO 6000 Blackwell Server Edition by partitioning the GPU into up to seven instances, each fully hardware isolated with its own high-bandwidth memory, cache, and streaming multiprocessors. The partitioned instances are transparent to workloads which greatly optimizes the use of resources and allows for serving workloads with guaranteed QoS.&lt;/p&gt;
&lt;p&gt;This means telecom operators can run AI/ML analytics, media processing, or virtual RAN computations that take advantage of GPUs and DPU offloading within their Kubernetes clusters – all managed under the same platform. By tapping into hardware acceleration, telcos can deliver advanced services (like AI-driven network optimization or AR/VR streaming) with high performance, without needing separate siloed infrastructure.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Operational efficiency and automation&lt;/h3&gt;
&lt;p&gt;Day-0 to Day-2 operations are streamlined through automation in Canonical’s stack. The distribution supports full lifecycle management – clusters can be deployed, scaled, and updated via one-step commands or integrated CI/CD pipelines, reducing manual effort and errors. Using Juju charms, Canonical’s model-driven operations further simplify complex orchestration, enabling teams to configure and update Kubernetes and related services in a repeatable, declarative way. Built-in self-healing and high availability features ensure that the platform can recover from failures automatically, keeping services running without intervention.&lt;/p&gt;
&lt;p&gt;This high degree of automation translates into faster rollout of new network functions and updates (with minimal downtime), allowing telco teams to focus on innovation rather than routine ops tasks.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Edge flexibility&lt;/h3&gt;
&lt;p&gt;Canonical Kubernetes is designed to run from the core to the far edge with equal ease. Its lightweight, efficient design (delivered as a single snap package) results in a low resource footprint, making it viable even on a one- or two-node edge cluster in a remote site. At the same time, it scales up to multi-node deployments for central networks. The platform supports a variety of configurations – from a single node for an ultra-compact edge appliance, to a dual-node high-availability cluster, to large multi-node clusters for data centers – all with the same tooling and consistent experience.&lt;/p&gt;
&lt;p&gt;This flexibility allows operators to extend cloud capabilities to edge locations (for ultra-low latency processing) while managing everything in a unified way. In practice, Canonical’s solution can power cloud-native telco IT workloads, 5G core functions, and edge applications under one umbrella, meeting the specific performance and latency needs of each environment.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Long-Term support and stability&lt;/h3&gt;
&lt;p&gt;Canonical backs its Kubernetes with long-term support options far exceeding the typical open-source release cycle. &lt;a href="https://canonical.com/blog/12-year-lts-for-kubernetes"&gt;Each Canonical Kubernetes LTS version can receive security patches and maintenance for up to 15 years&lt;/a&gt;, ensuring a stable foundation for cloud-native telco services over the entire 5G rollout and beyond. (For comparison, upstream Kubernetes offers roughly 1 year of support per release).&lt;/p&gt;
&lt;p&gt;This extended support window means carriers can avoid frequent, disruptive upgrades and rest assured that their infrastructure remains compliant over the long term. Such a commitment to stability is a key reason telecom operators choose Canonical – long-term maintenance provides confidence that critical network workloads will run on a hardened, well-maintained platform for many years.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Cost efficiency and vendor neutrality&lt;/h3&gt;
&lt;p&gt;As an open-source, upstream-aligned distribution, Canonical Kubernetes has no licensing costs and prevents vendor lock-in. Telcos are free to deploy it on their preferred hardware or cloud, and they benefit from a large ecosystem of Kubernetes-compatible tools and operators. The platform’s efficient resource usage and automation also help drive down operating costs – by improving hardware utilization and simplifying management, it enables operators to serve growing traffic loads without linear cost increases. In short, Canonical’s Kubernetes offers carrier-grade performance and features at a fraction of the cost of proprietary alternatives, all while keeping the operator in control of their technology roadmap.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Enabling a new wave of cloud-native telco services&lt;/h1&gt;
&lt;p&gt;Using Canonical Kubernetes, cloud-native telcos can position themselves to innovate faster and operate more efficiently in the 5G era. They can readily stand up cloud-native 5G Core functions, scale out Open RAN deployments, and push applications to the network edge – all on a consistent Kubernetes foundation. In fact, Kubernetes makes it feasible for telcos to transition from traditional VNFs on virtual machines to containerized CNFs, reducing resource overhead and speeding up deployment of network features. This means legacy network applications can be modernized step-by-step and run alongside new microservices on the same platform, avoiding risky “big bang” overhauls.&lt;/p&gt;
&lt;p&gt;The result is not only technical efficiency but business agility: operators can launch new services (from enhanced mobile broadband to IoT analytics) in weeks instead of months, respond quickly to customer demand spikes, and streamline the integration of new network functions or vendors.&lt;/p&gt;
&lt;p&gt;Early adopters in the industry are already seeing the benefits. For example, &lt;a href="https://ubuntu.com/blog/bringing-canonical-kubernetes-to-sylva-a-new-chapter-for-european-telco-clouds"&gt;Canonical’s Kubernetes has been embraced in initiatives like the European Sylva open telco cloud project&lt;/a&gt;, in part due to its security, flexibility and long-term support advantages. This momentum underscores that a performant, open Kubernetes platform is becoming a strategic asset for telcos aiming to stay ahead in a competitive landscape. Perhaps most importantly, Canonical Kubernetes lets telcos focus on delivering value to subscribers – ultra-reliable connectivity, rich digital services, tailored enterprise solutions – rather than getting bogged down in infrastructure complexity. It abstracts away much of the heavy lifting of deploying and upgrading distributed systems, while providing the controls needed to meet strict cloud-native telco requirements. The combination of automation, performance tuning, and openness creates a powerful engine for telecom innovation.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Cloud-native at any scale: Canonical Kubernetes meets MicroCloud&lt;/h1&gt;
&lt;p&gt;At the edge, complexity is the enemy. That’s why Canonical Kubernetes pairs naturally with MicroCloud, our lightweight production-grade cloud infrastructure for distributed environments. MicroCloud fits the edge use case extremely well: it is easy to deploy, fully automated, and optimized for bare-metal and low-power sites. Drop it into a telco cabinet, regional hub, or remote data center, and you get a resilient control plane for running Kubernetes, virtualization, and storage with zero overhead.&lt;/p&gt;
&lt;p&gt;In such deployments, MicroCloud and Canonical Kubernetes form a tightly integrated stack that brings cloud-native operations to the far edge. Need to orchestrate CNFs next to VMs? Spin up a single-node cluster with high availability? Scale to dozens of locations without rearchitecting? This combo makes it possible, with snaps for simple updates, Juju for full automation, and long-term support built in.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Conclusion: building the future of cloud-native telco on open source Kubernetes&lt;/h1&gt;
&lt;p&gt;5G and edge computing are reshaping telecom networks, and Kubernetes has proven to be an essential technology powering this evolution.&lt;a href="https://ubuntu.com/industrial"&gt; Industrial IoT&lt;/a&gt;,&lt;a href="https://ubuntu.com/automotive"&gt; automotive applications&lt;/a&gt; ,&lt;a href="https://ubuntu.com/internet-of-things/smart-city"&gt; smart cities&lt;/a&gt;,&lt;a href="https://ubuntu.com/robotics"&gt; robotics&lt;/a&gt;, remote health care, and the gaming industry rely on high data transfer, close to real time latency, very high availability and reliability. Canonical Kubernetes brings the best of cloud-native innovation to the telecom domain in a form that aligns with carriers’ operational realities and performance needs. It delivers a rare mix of benefits – agility and efficiency from automation, high performance for demanding workloads, freedom from lock-in, and assured long-term support – making it a compelling choice for any telco modernizing its infrastructure.&lt;/p&gt;
&lt;p&gt;Telecommunications leaders looking to become cloud-native telcos should consider how an open-source platform like Canonical Kubernetes can serve as a foundation for growth. Whether the goal is to reduce operating costs in the core network, roll out programmable 5G services at the edge, or simply break free from proprietary constraints, Canonical’s Kubernetes distribution provides a proven path forward.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Explore further&lt;/h1&gt;
&lt;p&gt;To dive deeper into how Canonical Kubernetes meets telco performance and reliability requirements, we invite you to read our detailed white paper: &lt;a href="https://ubuntu.com/engage/kubernetes-for-telco-performance"&gt;Addressing telco performance requirements with Canonical Kubernetes&lt;/a&gt;&lt;em&gt;.&lt;/em&gt; It offers in-depth insights and benchmark results from real-world cloud-native telco scenarios. Additionally, visit our blogs on Ubuntu.com and Canonical.com for more success stories and technical guides – from 5G network modernization strategies to edge:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/edge-networking-gets-smarter-ai-and-5g-in-action"&gt;Edge Networking gets smarter: AI and 5G in action&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/canonical-releases-fips-enabled-kubernetes"&gt;Canonical releases FIPS-enabled Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/canonical-kubernetes-officially-included-in-sylva-1-5"&gt;Canonical Kubernetes officially included in Sylva 1.5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Visiting MWC 2026?&lt;a href="https://canonical.com/solutions/telco#get-in-touch"&gt; Book a meeting with Canonical&lt;/a&gt; to find out more.&lt;/p&gt;
</content:encoded><author>Benjamin Ryzman (Benjamin Ryzman)</author><category>Cloud Native</category><category>kubernetes</category><category>Telco 5G</category><pubDate>Wed, 10 Dec 2025 15:47:17 +0000</pubDate></item><item><title>The rhythm of reliability: inside Canonical’s operational cadence</title><link>https://ubuntu.com//blog/the-rhythm-of-reliability</link><description>&lt;p&gt;At Canonical, time is fixed. Ubuntu releases never slip because we run on a strict rhythm: six-month cycles, two-week pulses, and in-person sprints. Every change is deliberate, ensuring stability without losing agility. This discipline is what enables us to provide 15 years of Long-Term Support. Reliability is built into everything we do.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;In software engineering, we often talk about the “iron triangle” of constraints: time, resources, and features. You can rarely fix all three. At many companies, when scope creeps or resources get tight, the timeline is often the first element of the triangle to slip.&lt;/p&gt;
&lt;p&gt;At Canonical, we take a different approach. For us, &lt;strong&gt;time&lt;/strong&gt; is the fixed constraint.&lt;/p&gt;
&lt;p&gt;This isn’t just about strict project management. It is a mechanism of trust. Our users, customers, and the open source community need to know exactly when the next Ubuntu release is coming. To deliver that reliability externally, we need a rigorous operational rhythm internally, and for over 20 years, we have honored this commitment.&lt;/p&gt;
&lt;p&gt;Here is how we orchestrate the business of building software, from our six-month cycles to the daily pulse of engineering:&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="554" loading="lazy" sizes="(min-width: 1184px) 1184px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1184/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1184/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1184w" width="1184"/&gt;&lt;/figure&gt;
&lt;p class="has-text-align-center"&gt;Fig. 1 Canonical’s Operating Cycle&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The six-month cycle&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Our entire engineering organization operates on a six-month cycle that aligns with the Ubuntu release cadence. This cycle is our heartbeat. It drives accountability and ensures we ship features on time.&lt;/p&gt;
&lt;p&gt;To make this work, we rely on three critical control points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sprint Readiness Review (SRR): This is where prioritization happens. Before a cycle begins, we don’t just ask “what fits?”: we ask “what matters?” We go through feedback to find the most valuable engineering opportunities, ensuring we prioritize quality and impact over volume. We don’t start the work until we know the scope is worth the effort.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Product Roadmap Sprint: The SRR culminates in this one-week, face-to-face event. This is the formal moment of truth where we close out the previous cycle and leadership signs off on the plan for the next one. It ensures that every team leaves the room with a clear, approved mandate.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Midcycle Review: Three months in, we hold a “Virtual Sprint” to check our progress. Crucially, we review any “bad news”, in which we immediately identify items that will not ship or are at risk. By addressing what won’t happen upfront, leadership can make informed decisions to course-correct immediately rather than letting a deadline slip.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This discipline ensures we stay agile, and that we can adjust our trajectory halfway through without derailing the entire delivery.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The two-week pulse&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;While the six-month cycle sets the destination, the “pulse” gets us there. A pulse is our version of a two-week agile sprint.&lt;/p&gt;
&lt;p&gt;Crucially, these pulses are synchronized across the entire company, on a cross-functional basis. Marketing, Sales, and Support all operate on this same frequency. When a team member says, “we will do it next pulse,” everyone, regardless of department, knows exactly what that means. This creates a shared expectation of delivery that keeps the whole organization moving in lockstep.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Sprints are for in-person connection&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We distinguish between a “pulse” (our virtual, two-week work iteration) and a “sprint.” For us, a sprint is a physical, one-week event where teams meet face-to-face.&lt;/p&gt;
&lt;p&gt;We are a remote-first company, which makes these moments invaluable. Sprints provide the high-bandwidth communication and human connection needed to sustain us through months of remote execution.&lt;/p&gt;
&lt;p&gt;We also stagger these sprints to separate context. Our &lt;strong&gt;Engineering Sprints&lt;/strong&gt; happen in May and November (immediately after an Ubuntu release) so teams can focus purely on technical roadmapping. &lt;strong&gt;Commercial Sprints&lt;/strong&gt; happen in January and July, aligning with our fiscal half-years to focus on business value. This “dual-clock” system ensures that commercial goals and technical realities are synchronized without overwhelming the teams.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Managing the exceptions&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Of course, market reality doesn’t always adhere to a six-month schedule. Customers have urgent needs, and high-value opportunities appear unexpectedly. To handle this without breaking our rhythm, we use the &lt;strong&gt;Commercial Review (CR)&lt;/strong&gt; process.&lt;/p&gt;
&lt;p&gt;The CR process protects our engineering teams from chaos while giving us the agility to say “yes” to the right opportunities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Protection:&lt;/strong&gt; We don’t let unverified requests disrupt the roadmap. A Review Board assesses every non-standard request before we make a promise.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conscious trade-offs:&lt;/strong&gt; If a new request is critical, we ask: “What are we removing to make space for this?” It forces a conscious decision. We review the roadmap and agree on what gets deprioritized to satisfy the new request.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This ensures that when we do deviate from the plan, it is a strategic choice, not an accident.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Quality as a natural habit&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Underpinning this entire rhythm is a commitment to quality standards. We follow the Plan, Do, Check, Act (PDCA) cycle, a concept rooted in ISO 9001. While we align with these formal frameworks, it has become a natural habit for us at Canonical.&lt;/p&gt;
&lt;p&gt;This operational discipline is what enables up to &lt;a href="https://canonical.com/blog/canonical-expands-total-coverage-for-ubuntu-lts-releases-to-15-years-with-legacy-add-on"&gt;15 years of LTS commitment&lt;/a&gt; on a vast portfolio of open source components, providing Long-Term Support for the entire, integrated collection of application software, libraries, and toolchains. Offering 15 years of security maintenance on our entire stack is only possible because we are operationally consistent. Long-term stability is the direct result of short-term discipline.&lt;/p&gt;
&lt;p&gt;By sticking to this rhythm, we ensure that Canonical remains not just a source of great technology, but a reliable partner for the long haul.&lt;/p&gt;
</content:encoded><author>Maksim Beliaev (Maksim Beliaev)</author><category>Business</category><category>Canonical</category><category>lifecycle</category><category>operations</category><pubDate>Wed, 10 Dec 2025 12:22:33 +0000</pubDate></item><item><title>Canonical to distribute AMD ROCm AI/ML and HPC libraries in Ubuntu</title><link>https://ubuntu.com//blog/canonical-amd-rocm-ai-ml-hpc-libraries</link><description>&lt;p&gt;Canonical is pleased to announce an expanded collaboration with AMD to package and maintain AMD ROCm™ software directly in Ubuntu. AMD ROCm is an open software ecosystem to enable hardware-accelerated AI/ML and HPC workloads on AMD Instinct™ and AMD Radeon™ GPUs, simplifying the deployment of AI infrastructure with long term support from Canonical. Canonical has [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Canonical is pleased to announce an expanded collaboration with AMD to package and maintain AMD ROCm™ software directly in Ubuntu. AMD ROCm is an open software ecosystem to enable hardware-accelerated AI/ML and HPC workloads on AMD Instinct™ and AMD Radeon™ GPUs, simplifying the deployment of AI infrastructure with long term support from Canonical.&lt;/p&gt;
&lt;p&gt;Canonical has formed a dedicated team of engineers to package the AMD ROCm software libraries to streamline installation, support, and long-term maintenance on Ubuntu. Canonical will also submit these packages for consideration in Debian.&lt;/p&gt;
&lt;p&gt;This work will simplify the delivery of AMD AI solutions in data centers, workstations, laptops, Windows Subsystem for Linux, and edge environments. AMD ROCm software will be available as a dependency for any Debian package, snap, or Docker image (OCI) build.  Performance fixes and security patches will automatically be available to production systems.&lt;/p&gt;
&lt;p&gt;This collaboration aims to make AMD ROCm software available in Ubuntu starting with Ubuntu 26.04 LTS, with updates available in every subsequent Ubuntu release.  &lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;AMD ROCm software: a commitment to open source &lt;/h2&gt;
&lt;p&gt;Canonical works with silicon industry leaders to incorporate the software libraries and drivers that accelerate applications on their silicon directly into Ubuntu. Comprehensive support for the latest silicon dramatically accelerates developer adoption and production deployments. &lt;/p&gt;
&lt;p&gt;For AMD, the software that enables hardware-accelerated AI processing is called ROCm. It is an open software platform that includes runtimes, compilers, libraries, kernel components, and drivers that together accelerate industry standard frameworks such as PyTorch, Tensorflow, Jax, and more on supported AMD GPUs and APUs. &lt;/p&gt;
&lt;p&gt;“AMD ROCm software enables open, high-performance acceleration for AI and HPC on AMD hardware. Working with Canonical to package AMD ROCm for Ubuntu makes it easier for developers and enterprises to deploy AMD solutions on supported systems,” said Andrej Zdravkovic, Senior Vice President, GPU Technologies and Engineering Software and Chief Software Officer at AMD.     &lt;/p&gt;
&lt;p&gt;Packaging AMD ROCm in Ubuntu underscores the strong AMD commitment to developer experience and enterprise experience:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simpler installation with ‘apt install rocm’ or as an automatic dependency for other projects, like ollama-amd.&lt;/li&gt;
&lt;li&gt;Both stable LTS and fresh ROCm versions every six months will be available, to ensure immediate support for the latest hardware and software.&lt;/li&gt;
&lt;li&gt;Easy security fixes and performance improvements (just “apt upgrade”).&lt;/li&gt;
&lt;li&gt;Up to 15 years of support for AMD ROCm in Ubuntu LTS versions under Ubuntu Pro. &lt;/li&gt;
&lt;li&gt;Personal Ubuntu Pro subscriptions are free.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“We are delighted to work alongside AMD and the community to package AMD ROCm libraries directly into Ubuntu,” said Cindy Goldberg, SVP of Silicon and Cloud Alliances at Canonical. “This will simplify the use of AMD hardware and software for AI workloads, and enable organizations to meet security and maintenance requirements for production use at scale.”&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Improved hardware support&lt;/h2&gt;
&lt;p&gt;Canonical works closely with hardware manufactures to test, optimize, and certify Ubuntu for their devices, and to integrate the required software drivers and kernel patches to support that hardware. Thanks to this extensive hardware program, Ubuntu runs equally well on laptops, workstations, servers, and IoT/edge devices, and developers have a seamless path from development through to deployment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn more about &lt;a href="https://canonical.com/partners/silicon"&gt;Canonical’s silicon partnerships&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amd.com/en/products/software/rocm.html"&gt;Read about AMD ROCm software&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Canonical (Canonical)</author><category>AI/ML</category><category>Certified hardware</category><category>Ubuntu Pro</category><pubDate>Tue, 09 Dec 2025 17:38:05 +0000</pubDate></item></channel></rss>