<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Ubuntu blog</title><link>https://ubuntu.com//blog/feed</link><description>Ubuntu blog feed</description><atom:link href="https://ubuntu.com//blog/feed" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>Python Feedgen</generator><lastBuildDate>Mon, 22 Dec 2025 12:07:14 +0000</lastBuildDate><item><title>A better way to provision NVIDIA BlueField DPUs at scale with MAAS</title><link>https://ubuntu.com//blog/a-better-way-to-provision-nvidia-bluefield-dpus-at-scale-with-maas</link><description>&lt;p&gt;The recent release of MAAS 3.7 introduces a significant new capability: the ability to provision NVIDIA BlueField Data Processing Units (DPUs) directly through their Baseboard Management Controller (BMC),&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;MAAS 3.7 has been &lt;a href="https://canonical.com/maas/docs/release-notes-and-upgrade-instructions#p-9229-version-37-release-notes"&gt;officially released&lt;/a&gt; and it includes a bunch of cool new features. One of the capabilities that stands out most, without a doubt, is the support for NVIDIA Bluefield DPU provisioning directly through the Baseboard Management Controller (BMC).&lt;/p&gt;
&lt;p&gt;But, what are BlueField DPUs? This leads to a broader question: what are DPUs and SmartNICs, and why is the ability to provision them through the BMC a significant advancement?&lt;/p&gt;
&lt;p&gt;Let’s deep dive into all this.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;DPUs and SmartNICs&lt;/h2&gt;
&lt;p&gt;Today’s data centers face increasing demands: higher throughput, more tenants, rising security threats and the growing complexity of cloud-native environments. Traditional servers struggle when networking, storage, and security functions consume more and more CPU cycles intended for applications.&lt;/p&gt;
&lt;p&gt;This trend has driven the industry toward &lt;strong&gt;infrastructure hardware acceleration&lt;/strong&gt;, where specialised processors handle tasks traditionally executed by the host CPU. &lt;/p&gt;
&lt;p&gt;A SmartNIC was the logical solution, a Network Interface Card (NIC) enhanced with onboard compute and acceleration hardware. Unlike traditional NICs, which simply move packets, SmartNICs can process, filter, and &lt;strong&gt;accelerate data&lt;/strong&gt; directly on the card  before it ever reaches the host CPU.&lt;/p&gt;
&lt;p&gt;A Data Processing Unit (DPU) goes further. It is effectively a small, fully functional server on a PCIe card, with its own CPU cores, memory, operating system, security capabilities, and hardware offload engines. DPUs are designed to take over the entire &lt;strong&gt;infrastructure plane&lt;/strong&gt; (networking, storage, security and management) so that the host CPU can focus entirely on application workloads.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="530" loading="lazy" sizes="(min-width: 720px) 720px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_720/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp" srcset="https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 460w, https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 620w, https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 1036w, https://res.cloudinary.com/canonical/image/fetch/f_webp,q_auto,fl_sanitize,c_fill,w_720/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4a37%2FDPU.webp 720w" width="720"/&gt;&lt;/figure&gt;
&lt;p&gt;DPUs are increasingly common in cloud, telco, and high-performance environments such as AI training clouds. Typical use cases include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Network acceleration/offloading&lt;/strong&gt;: Implementing Software-Defined Networking (SDN) for OpenStack, LXD/MicroCloud, Kubernetes, and bare-metal, including distributed firewall functionality.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage acceleration/offloading&lt;/strong&gt;: running agents (like Ceph RBD) to present distributed storage as a standard device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secure root of trust&lt;/strong&gt;: providing authentication, attestation and isolation, and monitoring the host’s processes and network connections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes on the DPU&lt;/strong&gt;: using the DPU as a worker node for packaging and orchestrating network, storage, and security functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="wp-block-heading"&gt;NVIDIA Bluefield&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/"&gt;NVIDIA BlueField&lt;/a&gt; family is NVIDIA’s line of DPUs. This family showcases how NVIDIA has expanded from the original SmartNIC concept into a full platform that supports not only infrastructure offloads but also advanced telemetry, security analytics, and AI-centric workloads, all designed to free up host CPUs and accelerate core operations in modern and distributed data centers.&lt;/p&gt;
&lt;p&gt;BlueField-3 is particularly relevant here. It was the first DPU of the family that incorporated a Baseboard Management Controller (BMC), allowing remote monitoring and control of the DPU. A BMC is a dedicated, independent micro-controller embedded on a server’s motherboard (in this case embedded on the DPU) that provides out-of-band management capabilities. It enables administrators to remotely monitor hardware health (like temperature and power), control the server’s power state (turn it on/off or reboot), and access the console.&lt;/p&gt;
&lt;p&gt;This independence is what makes clean, automated provisioning possible.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;How should you provision a DPU: through the BMC or through the host?&lt;/h2&gt;
&lt;p&gt;Historically, DPUs were provisioned &lt;strong&gt;through the host&lt;/strong&gt;. The host OS booted first, ran vendor tools, and then configured or imaged the DPU. While workable for early deployments, this approach tightly couples the DPU lifecycle to the host, makes recovery harder, and becomes operationally fragile at scale.&lt;/p&gt;
&lt;p&gt;With a built-in BMC, a second option is available: provisioning the DPU directly &lt;strong&gt;through the BMC&lt;/strong&gt;. In this model, the DPU is treated like an independent server. The BMC can power it on, flash firmware, install an operating system, run configuration workflows, and make it operational, independently of the host.&lt;/p&gt;
&lt;p&gt;Benefits of BMC-based provisioning include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consistent “day-0” initialization&lt;/li&gt;
&lt;li&gt;Host-agnostic workflows (no dependency on a running OS)&lt;/li&gt;
&lt;li&gt;Easier recovery and re-provisioning&lt;/li&gt;
&lt;li&gt;Cleaner separation between host workloads and infrastructure functions, enabling a &lt;a href="https://ubuntu.com/blog/canonical-and-nvidia-bluefield-4-a-foundation-for-zero-trust-high-performance-infrastructure"&gt;zero-trust deployment model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Better suitability for large-scale or zero-touch environments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the provisioning method &lt;strong&gt;MAAS now supports&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;MAAS now supports BlueField provisioning through the BMC&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical.com/maas"&gt;MAAS (Metal as a Service)&lt;/a&gt; is Canonical’s open-source platform for managing physical servers with cloud-like automation. It provides a central place to discover, commission, deploy and repurpose machines. It offers repeatable workflows that make large-scale infrastructure easier to operate and an infrastructure-as-code approach to programmatically automate the whole data center.&lt;/p&gt;
&lt;p&gt;With the release of MAAS 3.7, BlueField DPUs can now be provisioned directly through their BMC. This allows MAAS to treat the DPU as an independent server, without relying on the host operating system to initialise or configure it. Behind the scenes, MAAS handles power control, device relationships, and the order of operations required to bring both the host and the DPU online correctly.&lt;/p&gt;
&lt;p&gt;Prior to this release, MAAS supported BlueField provisioning only through-the-host, meaning that MAAS needed the host to be provisioned and operational first, before even being able to provision the DPU. While functional, this approach made DPU lifecycle management dependent on the host and limited automation in larger environments.&lt;/p&gt;
&lt;p&gt;This new workflow gives operators a cleaner and more predictable way to manage DPUs. By integrating BlueField provisioning into standard MAAS processes, it becomes simpler to adopt DPUs across the data centre and maintain them consistently alongside the rest of the hardware fleet.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Get started with MAAS 3.7&lt;/h2&gt;
&lt;p&gt;You can start experimenting with BlueField provisioning today by installing or upgrading to MAAS 3.7. The easiest way to get started with MAAS is to follow the &lt;a href="https://canonical.com/maas/docs/maas-in-thirty-minutes"&gt;comprehensive 30-min tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For DPU provisioning details and supported workflows, check out the &lt;a href="https://canonical.com/maas/docs"&gt;MAAS documentation&lt;/a&gt; and the dedicated &lt;a href="https://discourse.maas.io/t/how-to-deploy-dpus-in-maas/15418"&gt;BlueField provisioning guide.&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;Give it a try and &lt;a href="https://canonical.com/maas#get-in-touch"&gt;let us know&lt;/a&gt; how it works in your environment.&lt;/p&gt;
&lt;p&gt;And if you are interested in getting Canonical’s support and compliance for MAAS, you can explore &lt;a href="https://ubuntu.com/pro"&gt;Ubuntu Pro&lt;/a&gt;, or &lt;a href="https://canonical.com/maas#get-in-touch"&gt;get in touch&lt;/a&gt; with our team. &lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://maas.io"&gt;Canonical MAAS (Metal as a Service)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://maas.io/tutorials/build-a-maas-and-lxd-environment-in-30-minutes-with-multipass-on-ubuntu"&gt;Build a MAAS and LXD environment in 30 minutes with Multipass on Ubuntu&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://maas.io/docs"&gt;MAAS documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>David Beamonte (David Beamonte)</author><category>bare metal</category><category>bluefield</category><category>data center</category><category>dpu</category><category>MAAS</category><pubDate>Fri, 19 Dec 2025 17:14:05 +0000</pubDate></item><item><title>MicroCeph: why it’s the superior MinIO alternative (and how to use it)</title><link>https://ubuntu.com//blog/microceph-why-its-the-superior-minio-alternative</link><description>&lt;p&gt;Recently, the team at MinIO moved the open source project into maintenance mode and will no longer accept any changes. That means that no new features or enhancements will be added to MinIO, and existing issues &amp;#8212; according to the update &amp;#8212; will not be actively considered. Whilst MinIO brought a solid developer-friendly approach to [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="2250" loading="lazy" sizes="(min-width: 4000px) 4000px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_4000/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F752a%2FMicroCeph-minio-blog-1.png 1920w" width="4000"/&gt;&lt;/figure&gt;
&lt;p&gt;Recently, the team at MinIO moved the open source project into &lt;a href="https://github.com/minio/minio/commit/27742d469462e1561c776f88ca7a1f26816d69e2"&gt;maintenance mode&lt;/a&gt; and will no longer accept any changes. That means that no new features or enhancements will be added to MinIO, and existing issues — according to the update — will not be actively considered. Whilst MinIO brought a solid developer-friendly approach to object storage (S3) for many years, this update means that the project is unlikely to keep up with advancements in storage tech.  So, for developers hoping to stay at the cutting edge of object storage, and to take advantage of block and file storage, what’s the next step?&lt;/p&gt;
&lt;p&gt;Ceph has set the standard as the trusted, production-worthy open source storage for over a decade. However, some users have found the upstream tooling complex to use; so, a couple of years ago we introduced MicroCeph as an opinionated and simple way to deploy Ceph.&lt;/p&gt;
&lt;p&gt;Despite the Micro name, there’s nothing missing. MicroCeph is fully-featured Ceph, with the same scale-out architecture, and block (RBD), file (CephFS, NFS), and object (S3, Swift) protocols. The positive difference is that MicroCeph offers simpler deployment, scaling, and day-2 operations. &lt;/p&gt;
&lt;p&gt;Since its release, adoption of MicroCeph has spread far and wide. Now, you’ll find it deployed in everything from single-node development environments and CI pipelines, to production-scale multi-PetaByte deployments, enabling organisations to manage ever increasing data storage needs. For developers looking for a MinIO alternative, MicroCeph could work for you.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Setting up your MinIO alternative: how to get started with MicroCeph&lt;/h2&gt;
&lt;p&gt;In this tutorial, we’ll walk through the steps to get a single node Ceph cluster up and running. We’ll also explain how to enable RGW (Rados Gateway), so that you can use the S3 API like you might have done with MinIO.&lt;/p&gt;
&lt;p&gt;First you’ll need a single node or VM to try things out. And with MicroCeph being delivered as a Snap, you don’t have to be using Ubuntu OS – any Linux machine with snapd will work!&lt;/p&gt;
&lt;p&gt;Begin by installing the latest stable version of MicroCeph:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo snap install microceph --channel=squid/stable&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once the snap is downloaded and installed, we need to initialize the Ceph cluster:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph cluster bootstrap&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can then check to see if the bootstrap was completed successfully: &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo ceph status&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You should see output similar to the example below. Don’t worry about HEALTH_WARN at this stage, that’s expected as we only have a single Monitor (MON) in the cluster and no Object Storage Daemons (OSDs).&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="520" loading="lazy" sizes="(min-width: 844px) 844px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_844/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_844/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa80a%2Fimage-1.png 844w" width="844"/&gt;&lt;/figure&gt;
&lt;p&gt;Like any storage system, Ceph needs some disks to make it useful. In this scenario, we’ll add one file-based disk to get started. That’s perfect for testing and CI – but not ideal in production. For that you should use real disks, i.e. flash or spinning media. Find out more about which disks to use for MicroCeph in &lt;a href="http://microceph.com/"&gt;our documentation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;To add a file-based disk, input the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph disk add loop,4G,1&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once again, we can check the status of the cluster. Here we can see that the OSD has been successfully added.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="520" loading="lazy" sizes="(min-width: 868px) 868px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_868/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_868/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F4e07%2Fimage.png 868w" width="868"/&gt;&lt;/figure&gt;
&lt;p&gt;One more step that we need to carry out in this test, or demonstration configuration is to adjust the replication factor. This should &lt;strong&gt;never be done in production&lt;/strong&gt;, or with data that you care about: if the single disk fails, you will encounter data loss.&lt;/p&gt;
&lt;p&gt;To adjust the replication factor, input the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph pool set-rf "" --size=1&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="658" loading="lazy" sizes="(min-width: 1024px) 1024px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1024/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1024/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8bfc%2Fimage-1.png 1024w" width="1024"/&gt;&lt;/figure&gt;
&lt;p&gt;While there is a warning, this can be ignored for now, as this is just a test environment.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Enabling RGW&lt;/h2&gt;
&lt;p&gt;The next step is to enable RGW so that we can use the S3 API.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph enable rgw&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MicroCeph will take care of several things in this step: it’ll deploy the RGW daemon and create the pools needed for object meta-data and the objects themselves.&lt;/p&gt;
&lt;p&gt;We can see those cluster changes by checking the cluster status again:&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="642" loading="lazy" sizes="(min-width: 974px) 974px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_974/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_974/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F6f35%2Fimage.png 974w" width="974"/&gt;&lt;/figure&gt;
&lt;p&gt;And also by listing the pools in the cluster:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo ceph osd pool ls&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="210" loading="lazy" sizes="(min-width: 792px) 792px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_792/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_792/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F3ab3%2Fimage.png 792w" width="792"/&gt;&lt;/figure&gt;
&lt;p&gt;Next, create a RGW user so that we can grant access to storage in the cluster:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo radosgw-admin user create --uid=user --display-name=user&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The command will provide output like the example below. Your application will need the access_key and secret_key to interact with the cluster – for example, to create buckets, as well as uploading and downloading objects.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="506" loading="lazy" sizes="(min-width: 1338px) 1338px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1338/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1338/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fe1e8%2Fimage-1.png 1338w" width="1338"/&gt;&lt;/figure&gt;
&lt;p&gt;We can quickly find out the IP address of the RGW by checking MicroCeph’s status:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;sudo microceph status&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="182" loading="lazy" sizes="(min-width: 784px) 784px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_784/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_784/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2a03%2Fimage.png 784w" width="784"/&gt;&lt;/figure&gt;
&lt;p&gt;And then we can test the API endpoint using curl:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;curl http://&amp;lt;IP Address&amp;gt;&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="118" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Faf84%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p&gt;Here we can see that the API endpoint is responding – ready for you to create buckets, and start uploading and downloading files.&lt;/p&gt;
&lt;p&gt;There are many ways of interacting with object storage. Tools like &lt;a href="https://github.com/s3tools/s3cmd"&gt;s3cmd&lt;/a&gt;, &lt;a href="https://github.com/boto/boto3"&gt;boto3&lt;/a&gt;, &lt;a href="https://github.com/peak/s5cmd"&gt;s5cmd&lt;/a&gt; or &lt;a href="https://cyberduck.io/s3/"&gt;cyberduck&lt;/a&gt; are all popular. Alternatively, your application may accept the access and secret keys to directly manage objects stored in an S3 compatible bucket.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;MicroCeph beyond a MinIO alternative&lt;/h2&gt;
&lt;p&gt;Of course, this tutorial only provides a taster of what Ceph is capable of. Scaling up from one node is a very simple process, and ultimately, the cluster can be scaled to multiple petabytes if needed. And unlike MinIO, no other solution is needed if you require Block or File storage too! Find out how to perform a multi-node install in &lt;a href="https://canonical-microceph.readthedocs-hosted.com/v19.2.0-squid/how-to/multi-node/"&gt;our documentation&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;The great thing about the MicroCeph snap is that, as part of Ubuntu and Canonical’s Long Term Support (LTS) commitment, it can be supported for up to 15 years from the release of the LTS. If you’re curious to find out how you can use MicroCeph in the long term, try our blog &lt;a href="https://canonical.com/blog/storage-for-kubernetes"&gt;explaining how to use MicroCeph as Kubernetes storage&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Philip Williams (Philip Williams)</author><category>ceph</category><category>Storage</category><pubDate>Fri, 19 Dec 2025 08:26:00 +0000</pubDate></item><item><title>Design and Documentation clinics at FOSDEM Fringe 2026</title><link>https://ubuntu.com//blog/design-and-documentation-clinics-at-fosdem-fringe-2026</link><description>&lt;p&gt;FOSDEM is one of the biggest and most exciting open source events of the year, held at the Solbosch campus of the Université Libre de Bruxelles (Brussels), Belgium. Thousands of open source contributors and enthusiasts attend, often with several folks from Canonical among them. The next one is coming quickly, with FOSDEM 2026 being held [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;&lt;a href="https://fosdem.org/2026/"&gt;FOSDEM&lt;/a&gt; is one of the biggest and most exciting open source events of the year, held at the Solbosch campus of the Université Libre de Bruxelles (Brussels), Belgium.&lt;/p&gt;
&lt;p class="has-medium-font-size"&gt;Thousands of open source contributors and enthusiasts attend, often with several folks from Canonical among them. The next one is coming quickly, with FOSDEM 2026 being held across the weekend of &lt;strong&gt;January 31st – February 1st&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For the first time, a few of us from the Design and Documentation teams at Canonical are going to both attend and &lt;em&gt;organize&lt;/em&gt; a&lt;strong&gt; free&lt;/strong&gt; &lt;a href="https://fosdem.org/2026/fringe/"&gt;FOSDEM Fringe&lt;/a&gt;&lt;strong&gt; &lt;/strong&gt;event&lt;strong&gt; &lt;/strong&gt;on &lt;strong&gt;Monday February 2nd&lt;/strong&gt;, between 09:00 and 17:00.  Anyone who needs help with their open source work is invited, as are unaffiliated individuals who want to learn more about either Design or Documentation.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;How we can help&lt;/h3&gt;
&lt;p&gt;Our fringe event includes both Design and Documentation clinics where attendees can ask questions and get the help they need to fix a problem, get a review, or create a solution. Items you might want to consider include:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Design clinic:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;UX/UI reviews:&lt;/strong&gt; Professional feedback on your CLI or GUI.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Workflow optimization:&lt;/strong&gt; Streamline how users interact with your tool.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualization:&lt;/strong&gt; Learn how to create and share your ideas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt; &lt;strong&gt;clinic:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Structure and strategy:&lt;/strong&gt; Organize and plan your content for better navigability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tooling setup:&lt;/strong&gt; Pick and configure the right documentation tools.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Onboarding:&lt;/strong&gt; Make it easier for new contributors to join.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But these are just a guide. We’re up for any challenge!&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Register now&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;When: &lt;/strong&gt;Monday 2nd February, between 09:00 and 17:00. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where&lt;/strong&gt;: &lt;a href="https://www.workatfirma.be/"&gt;Firma&lt;/a&gt;, Brussels.&lt;/p&gt;
&lt;p&gt;To give us some idea of numbers, we’re asking anyone who may want to attend to register their interest first. Please fill in the following form and we’ll be in touch:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSfJLEIb5zZ3gggdIWQiB6X2asTIEJ_07CPV077blzf9YJ0HCQ/viewform"&gt;&lt;strong&gt;Documentation and Design Clinic @FOSDEM Fringe Attendance Form&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;Questions? Find us on Matrix at &lt;/strong&gt;&lt;a href="https://matrix.to/#/#design:ubuntu.com"&gt;&lt;strong&gt;#design:ubuntu.com&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; and &lt;/strong&gt;&lt;a href="https://matrix.to/#/#documentation:ubuntu.com"&gt;&lt;strong&gt;#documentation:ubuntu.com&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;
</content:encoded><author>Graham Morrison (Graham Morrison)</author><category>Design</category><category>documentation</category><category>Event</category><pubDate>Thu, 18 Dec 2025 09:24:45 +0000</pubDate></item><item><title>Extending ROS Noetic Support with ESM-Enabled Content Snaps</title><link>https://ubuntu.com//blog/extending-ros-noetic-support-with-esm-enabled-content-snaps</link><description>&lt;p&gt;Canonical has now extended its ESM (Expanded Security Maintenance) for ROS coverage to ROS Noetic content-sharing snaps. With ESM for ROS now available in both deb and snap formats, Ubuntu continues to be the trusted foundation for secure, long-term robotics innovation.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Since ROS Noetic reached end of life in May 2025, the Ubuntu Robotics team has been working to ensure that developers and organizations can continue building and deploying robots securely on Ubuntu.&lt;/p&gt;
&lt;p&gt;To build on this foundation, Canonical has now &lt;strong&gt;extended its &lt;/strong&gt;&lt;a href="https://ubuntu.com/blog/ros-noetic-is-eol-take-action-to-maintain-fleet-security"&gt;&lt;strong&gt;ESM (Expanded Security Maintenance) for ROS&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; coverage to ROS Noetic content-sharing snaps.&lt;/strong&gt; This update is a significant step toward long-term support and security for ROS environments distributed through the Snap ecosystem, ensuring developers can continue to rely on maintained and compatible components.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;What are content-sharing snaps?&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/explanations/snaps/ros-architectures-with-snaps/#multi-snaps-using-content-sharing"&gt;Content-sharing snaps&lt;/a&gt; are a key feature of the Snap ecosystem that allow multiple snaps to share common dependencies, such as ROS libraries, tools, and assets, without duplication. This model simplifies packaging, improves consistency, and reduces image size across robotic systems. You can learn more about the benefits of following a modular architecture for your ROS robots &lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/explanations/snaps/ros-architectures-with-snaps/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Ubuntu Robotics team maintains several content-sharing snaps on the &lt;a href="https://snapcraft.io/publisher/ubuntu-robotics-community"&gt;Snap Store&lt;/a&gt; – such as &lt;a href="https://snapcraft.io/ros-noetic-desktop"&gt;&lt;em&gt;ros-noetic-desktop&lt;/em&gt;&lt;/a&gt; and &lt;a href="https://snapcraft.io/ros-noetic-ros-base"&gt;&lt;em&gt;ros-noetic-ros-base&lt;/em&gt;&lt;/a&gt; – which serve as the foundation for many ROS-based applications.&lt;/p&gt;
&lt;p&gt;With ESM now integrated, these content &lt;strong&gt;snaps continue to receive security updates and maintenance&lt;/strong&gt;, ensuring developers can build and deploy with confidence as ROS 1 transitions into its long-term maintenance phase. What’s more, this benefit is free – no Pro token is required.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Why this matters&lt;/h2&gt;
&lt;p&gt;Robotics projects often have long lifecycles, where stability and security are critical. While ROS Noetic is no longer maintained upstream, Canonical’s ESM for ROS service delivers ongoing CVE patches and security fixes for both ROS and Ubuntu packages.&lt;/p&gt;
&lt;p&gt;By extending ESM for ROS to content-sharing snaps, we’re &lt;strong&gt;giving developers the same long-term security guarantees in the snap ecosystem&lt;/strong&gt; that they already rely on in Ubuntu’s ESM for deb packages. This means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Continued security maintenance for ROS Noetic environments distributed through snaps.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;A unified and consistent experience across both deb-based and snap-based systems.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Easier access to maintained ROS libraries for new and existing robotic deployments.&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="wp-block-heading"&gt;Continuing long-term support for the ROS community&lt;/h2&gt;
&lt;p&gt;This update reflects Canonical’s ongoing commitment to the ROS ecosystem – helping developers and organizations extend the life of their robots securely and sustainably. With ESM for ROS now available in both deb and snap formats, Ubuntu continues to be the trusted foundation for secure, long-term robotics innovation.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Learn more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/explanations/security/what-is-ros-esm/"&gt;What is ESM for ROS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canonical-robotics.readthedocs-hosted.com/en/latest/tutorials/snaps-core/building-ros-snaps-with-content-sharing/"&gt;Tutorial: Building ROS snaps with content sharing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://canonical.com/blog/ros-enterprise-support-15-things-you-need-to-know"&gt;ESM for ROS: 15 things you need to know&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Florencia Cabral Berenfus (Florencia Cabral Berenfus)</author><category>devices</category><category>ESM for ROS</category><category>robotics</category><category>ROS</category><category>Security</category><pubDate>Wed, 17 Dec 2025 20:38:28 +0000</pubDate></item><item><title>Native integration available between Canonical LXD and HPE Alletra MP B10000</title><link>https://ubuntu.com//blog/canonical_lxd_hpe_alletra</link><description>&lt;p&gt;Native integration available between Canonical LXD and HPE Alletra MP B10000. The integration combines efficient open source virtualization with high performance, enterprise-grade storage&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;The integration combines efficient open source virtualization with high performance, enterprise-grade storage&lt;/p&gt;
&lt;p&gt;We are pleased to announce a new,  native integration between Canonical LXD and HPE Alletra. This integration brings together Canonical’s securely designed, open source virtualization platform with HPE’s enterprise-grade storage to deliver a simple, scalable, high-performance experience. &lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Enterprise-grade storage meets efficient open source virtualization&lt;/h1&gt;
&lt;p&gt;HPE Alletra is designed to deliver mission-critical storage at mid range economics, with a consistent data experience across various cloud environments. With this integration, Canonical LXD and MicroCloud users can now provision and manage Alletra block storage directly through the LXD interface, without the need for any third-party plugins or additional abstraction layers. &lt;/p&gt;
&lt;p&gt;The integration enables users to seamlessly create, attach, snapshot, and manage thin-provisioned block volumes as easily as working with local storage, while retaining the full performance, resilience, and enterprise data services of HPE Alletra. &lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="949" loading="lazy" sizes="(min-width: 1571px) 1571px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1571/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1571/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fb448%2Fimage.png 1571w" width="1571"/&gt;&lt;/figure&gt;
&lt;h1 class="wp-block-heading"&gt;Simplified operations and scalable performance&lt;/h1&gt;
&lt;p&gt;HPE Alletra NVMe-based architecture ensures sub-millisecond latency for demanding workloads, with built-in services such as thin-provisioning and data deduplication minimizing storage costs while maintaining consistent performance. Paired with LXD’s lightweight control plane and streamlined UI, users can easily operate their environments, combining the best of open source with enterprise storage functionality.&lt;/p&gt;
&lt;p&gt;As demands grow, new volumes and storage capacity can be allocated on the fly. Alletra’s scale-out, modular architecture ensures the platform can expand without disrupting running workloads. &lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;A foundation for modern infrastructure deployments &lt;/h1&gt;
&lt;p&gt;LXD provides a unified open source virtualization platform to run system containers and virtual machines with a focus on efficiency, security, and ease of management. With native support for HPE Alletra, enterprises can now build, deploy, and manage their workloads with enterprise storage guarantees, whether in private clouds, on-premises data centers, or edge environments. &lt;/p&gt;
&lt;p&gt;The combined solution empowers teams to deliver predictable performance for critical and data-intensive workloads while reducing complexity and ensuring agility.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Availability&lt;/h1&gt;
&lt;p&gt;The integration between LXD and HPE Alletra is available starting with the &lt;a href="https://documentation.ubuntu.com/lxd/latest/reference/release-notes/release-notes-6.6/"&gt;LXD 6.6 feature release&lt;/a&gt;, and requires a HPE Alletra WSAPI version 1. LXD currently supports connecting to HPE Alletra storage through NVMe/TCP or iSCSI protocols. For detailed information, visit &lt;a href="https://documentation.ubuntu.com/lxd/stable-5.21/reference/storage_alletra/"&gt;Canonical’s LXD documentation&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Miona Aleksic (Miona Aleksic)</author><category>HPE</category><category>LXD</category><category>microcloud</category><pubDate>Mon, 15 Dec 2025 15:57:28 +0000</pubDate></item><item><title>Why you should retire your Microsoft Azure Consumption Commitment (MACC) with Ubuntu Pro</title><link>https://ubuntu.com//blog/retire-azure-consumption-commitment-macc-ubuntu-pro</link><description>&lt;p&gt;Fulfilling your Microsoft Azure Consumption Commitment (MACC) requires efficient planning. Discover how allocating your MACC to Ubuntu Pro allows you to meet consumption goals while securing your open source supply chain and automating compliance.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;When your organization first signed its Microsoft Azure Consumption Commitment (MACC), it was a strategic step to unlock better pricing and enable cloud growth. However, fulfilling that commitment efficiently requires planning. Organizations often look for ways to retire their MACC that drive strategic value, rather than simply increasing consumption to meet a deadline.&lt;/p&gt;
&lt;p&gt;The goal is to meet your commitment while delivering long-term benefits to the business.&lt;/p&gt;
&lt;p&gt;With Ubuntu Pro in the Azure Marketplace, you can retire your MACC at 100% of the pretax purchase amount. In practice, this allows you to meet consumption goals on your standard Azure invoice, while securing your open source supply chain and automating compliance.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Turn a spend target into an open source security strategy&lt;/h1&gt;
&lt;p&gt;Instead of simply increasing consumption to hit a target, effective IT and FinOps teams align their MACC with broader strategic goals. Open source support and security maintenance is a priority for enterprises, as a &lt;a href="https://pages.ubuntu.com/rs/066-EOV-335/images/Final%20report%20-%20WorldofOS_EUSpotlight_2025_081525.pdf?version=0&amp;amp;_gl=1*tbk0ic*_gcl_au*MjAyODc1NDE5My4xNzU0OTk1ODU4"&gt;recent Linux Foundation report&lt;/a&gt; shows: 54% of enterprises want long-term guarantees, and 53% expect rapid security patching.&lt;/p&gt;
&lt;p&gt;Ubuntu Pro offers both. By choosing software that strengthens your security and operations, you can retire your MACC while funding capabilities your organization prioritizes.&lt;/p&gt;
&lt;p&gt;Allocating MACC to Ubuntu Pro is a direct investment in your open source estate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Expanded Security Maintenance (ESM)&lt;/strong&gt;: extend security coverage to the critical open source applications running above the operating system layer. ESM provides up to 15 years of security updates for the OS, plus tens of thousands of packages. You might already see alerts for these missing updates in your Azure portal – learn how to check your exposure in our blog: [&lt;a href="https://ubuntu.com/blog/ubuntu-lts-vm-azure-security-view"&gt;A complete security view for every Ubuntu LTS VM on Azure&lt;/a&gt;].&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kernel Livepatch&lt;/strong&gt;: reduce maintenance windows by applying critical kernel patches without requiring a reboot for most workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compliance tooling&lt;/strong&gt;: access options for CIS hardening and FIPS 140-3 validated cryptographic modules to support meeting compliance and regulatory needs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optional enterprise support&lt;/strong&gt;: add enterprise SLAs, direct access to Canonical engineers for break-fix and bug-fix, and guidance on operating Ubuntu and ESM-covered packages on Azure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By choosing Ubuntu Pro, you convert your MACC spend into a maintained open source foundation across the development lifecycle.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Maximize value and streamline procurement&lt;/h1&gt;
&lt;p&gt;Retiring your commitment should be financially efficient and administratively simple. While standard Marketplace listings are MACC-eligible, many organizations use p&lt;a href="https://learn.microsoft.com/en-us/marketplace/private-offers-overview"&gt;rivate offers&lt;/a&gt; to secure tailored commercial terms, like custom pricing or volume discounts, without sacrificing eligibility.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;We support both standard private offers and multiparty private offers for rollouts involving resellers in the US/UK. In all cases, checking that your purchase counts toward your commitment is straightforward:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Confirm Eligibility&lt;/strong&gt;: verify the listing or private offer is marked as “Azure benefit-eligible.”&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Purchase Correctly&lt;/strong&gt;: execute the transaction in the Azure portal under the tenant and subscription tied to your MACC agreement.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This approach guarantees that every dollar spent satisfies your financial goals while delivering the specific security coverage your organization needs.&lt;/p&gt;
&lt;p&gt;Ready to align Ubuntu Pro with your MACC? &lt;a href="https://ubuntu.com/azure/contact-us"&gt;Talk to our team&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Jehudi (Jehudi)</author><pubDate>Sat, 13 Dec 2025 00:07:17 +0000</pubDate></item><item><title>How to launch a Deep Learning VM on Google Cloud</title><link>https://ubuntu.com//blog/how-to-launch-a-deep-learning-vm-on-google-cloud</link><description>&lt;p&gt;Setting up a local Deep Learning environment can be a headache. Between managing CUDA drivers, resolving Python library conflicts, and ensuring you have enough GPU power, you often spend more time configuring than coding. Google Cloud and Canonical work together to solve this with Deep Learning VM Images, which use Ubuntu Accelerator Optimized OS as [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Setting up a local Deep Learning environment can be a headache. Between managing CUDA drivers, resolving Python library conflicts, and ensuring you have enough GPU power, you often spend more time configuring than coding.&lt;/p&gt;
&lt;p&gt;Google Cloud and Canonical work together to solve this with &lt;a href="https://console.cloud.google.com/marketplace/details/click-to-deploy-images/deeplearning"&gt;Deep Learning VM Images&lt;/a&gt;, which use Ubuntu Accelerator Optimized OS as the base OS. These are pre-configured virtual machines optimized for data science and machine learning tasks. They come pre-installed with popular frameworks, such as PyTorch, and the necessary NVIDIA drivers.&lt;/p&gt;
&lt;p&gt;In this guide, I’ll walk you through how to launch a Deep Learning VM on GCP using the Console, and how to verify your software stack so you can start training immediately.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Why use a Deep Learning VM?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pre-installed frameworks:&lt;/strong&gt; No need to pip install generic libraries manually.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPU-ready:&lt;/strong&gt; NVIDIA drivers are pre-installed and verified.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter integration:&lt;/strong&gt; Seamless access to JupyterLab right out of the box.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 class="wp-block-heading"&gt;How to make a Deep Learning VM in GCP&lt;/h1&gt;
&lt;h2 class="wp-block-heading"&gt;Step 1: Navigate to the GCP Marketplace&lt;/h2&gt;
&lt;p&gt;First, log in to your Google Cloud Console. Instead of creating a generic Compute Engine instance, we want to use a specialized image from the Marketplace.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open the&lt;a href="https://console.cloud.google.com"&gt; Google Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In the search bar at the top, type &lt;strong&gt;“Deep Learning VM”&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Select the product named &lt;strong&gt;Deep Learning VM&lt;/strong&gt; published by Google.&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="538" loading="lazy" sizes="(min-width: 1448px) 1448px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1448/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1448/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F8758%2Fimage.png 1448w" width="1448"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Step 2: Configure your instance&lt;/h2&gt;
&lt;p&gt;Once you are on the Marketplace Deep Learning VM listing page, click &lt;strong&gt;Launch&lt;/strong&gt;. This will take you to the deployment configuration screen. This is where you define the power behind your model.&lt;/p&gt;
&lt;p&gt;Here are the key settings you need to pay attention to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Zone:&lt;/strong&gt; Make sure to select a zone that supports the specific GPU you want to use (in my case, I selected the us-central1-f zone).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Type:&lt;/strong&gt; Choose a CPU/RAM combination that meets your requirements if you don’t need a GPU.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPU Type:&lt;/strong&gt; You can add your GPU type, such as the NVIDIA T4, A100, or H100. &lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="585" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F7a77%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;Configuring the VM instance in the Google Cloud Console.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Once you have made your selections, click &lt;strong&gt;Deploy&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Step 3: Connect and verify&lt;/h2&gt;
&lt;p&gt;After a minute or two, your VM will be deployed. You can find it listed in your &lt;strong&gt;Compute Engine &amp;gt; VM Instances&lt;/strong&gt; page.&lt;/p&gt;
&lt;p&gt;To access the machine, click the &lt;strong&gt;SSH&lt;/strong&gt; button next to your new instance. This opens a terminal window directly in your browser.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="497" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F2228%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Step 4: Check the software stack &amp;amp; drivers&lt;/h2&gt;
&lt;p&gt;Now, let’s make sure everything is working under the hood.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;1. Verify NVIDIA drivers&lt;/h3&gt;
&lt;p&gt;If you have attached a GPU, the most important check is to ensure the drivers have loaded correctly. Run the following command in your SSH terminal:&lt;/p&gt;
&lt;p&gt;nvidia-smi&lt;/p&gt;
&lt;p&gt;You should see a table listing your GPU (e.g., A100) and the CUDA version.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="691" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F5332%2Fimage.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h3 class="wp-block-heading"&gt;2. Check pre-installed software&lt;/h3&gt;
&lt;p&gt;Google’s Deep Learning VMs usually come with PyTorch pre-configured. You can check the installed packages to ensure your favorite libraries are there:&lt;/p&gt;
&lt;p&gt;pip show torch&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="391" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F737c%2Fimage-1.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;h2 class="wp-block-heading"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;And that’s it! In just a few minutes, you have built a fully configured Deep Learning environment. You can now start running training scripts directly from the terminal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don’t forget:&lt;/strong&gt; Deep Learning VMs with GPUs can be expensive. Remember to &lt;strong&gt;stop&lt;/strong&gt; your instance when you aren’t using it to avoid unexpected charges!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://documentation.ubuntu.com/gcp/google-explanation/canonical-offerings/"&gt;Learn  more about Canonical’s offerings on GCP&lt;/a&gt;&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Read more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ubuntu.com/gcp"&gt;Ubuntu on Google Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discourse.ubuntu.com/t/optimizing-ai-workloads-with-ubuntu-ai-images/67099"&gt;Optimizing AI workloads with Ubuntu AI images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Hugo Huang (Hugo Huang)</author><category>accelerator</category><category>deep learning</category><category>Google Cloud</category><pubDate>Thu, 11 Dec 2025 14:31:00 +0000</pubDate></item><item><title>Harnessing the potential of 5G with Kubernetes: a cloud-native telco transformation perspective</title><link>https://ubuntu.com//blog/harnessing-the-potential-of-5g-with-kubernetes-a-cloud-native-telco-transformation-perspective</link><description>&lt;p&gt;Telecommunications networks are undergoing a cloud-native revolution. 5G promises ultra-fast connectivity and real-time services, but achieving those benefits requires an infrastructure that is agile, low-latency, and highly reliable. Kubernetes has emerged as a cornerstone for telecom operators to meet 5G demands. In 2025, Canonical Kubernetes delivers a single, production-grade Kubernetes platform with long-term support (LTS) [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Telecommunications networks are undergoing a cloud-native revolution. 5G promises ultra-fast connectivity and real-time services, but achieving those benefits requires an infrastructure that is agile, low-latency, and highly reliable. Kubernetes has emerged as a cornerstone for telecom operators to meet 5G demands. In 2025, Canonical Kubernetes delivers a single, production-grade Kubernetes platform with long-term support (LTS) and telco-specific optimizations, deployable across clouds, data centers, and the far edge.&lt;/p&gt;
&lt;p&gt;This blog explores how Canonical Kubernetes empowers 5G and cloud-native telco workloads with high performance, enhanced platform awareness (EPA), and robust security, while offering flexible deployment via snaps, Juju, or Cluster API. We’ll also highlight its integration into industry initiatives like Sylva, support for GPU/DPU acceleration, and synergy with MicroCloud for scalable edge infrastructure.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;The rise of the cloud-native telco&lt;/h1&gt;
&lt;p&gt;Telecom decision-makers face immense pressure to evolve their networks rapidly and cost-effectively. Traditional, hardware-centric architectures struggle to keep pace with 5G’s requirements for low latency, high throughput, and dynamic scaling. This is where Kubernetes – the de facto platform for cloud-native applications – comes in. Kubernetes brings powerful automation, scalability, and resiliency that allow telcos to manage network functions like software across data centers, public clouds, and far-edge deployments. The result is a more agile operational model: services can be rolled out faster, resources automatically optimized to demand, and updates applied continuously without disrupting critical services. In the 5G era, such agility is essential for delivering innovations like network slicing, multi-access edge computing (MEC), and AI-driven services.&lt;/p&gt;
&lt;p&gt;At the same time, Kubernetes opens the door for telcos to refactor their network functions into microservices. Instead of relying on monolithic appliances or heavy virtual machines, operators can deploy &lt;em&gt;cloud-native network functions (CNFs)&lt;/em&gt; – essentially containerized network services – that are lighter and faster to roll out than traditional virtual network functions (VNFs). By shifting to CNFs, new network features (whether a 5G core component or a firewall) can be introduced or updated in a fraction of the time, using automated CI/CD pipelines instead of lengthy manual upgrades. This approach helps telcos simplify the migration from legacy systems to a more agile, software-driven network model.&lt;/p&gt;
&lt;p&gt;However, adopting Kubernetes for telecom workloads also means meeting rigorous performance and reliability standards. Carrier-grade services like voice, video, and core network functions can’t tolerate unpredictable delays or downtime. Telco leaders need a Kubernetes platform that combines cloud-native flexibility with &lt;em&gt;telco-grade&lt;/em&gt; performance, security, and support. Canonical Kubernetes answers that call, providing a Kubernetes distribution specifically tuned for telecommunications needs.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Canonical Kubernetes: optimized for cloud-native 5G networks and edge computing&lt;/h1&gt;
&lt;p&gt;Canonical’s Kubernetes distribution has been engineered from the ground up to address the unique challenges of 5G and cloud-native telco cloud deployments. It is a single, unified Kubernetes offering that blends the ease of use of lightweight deployments with the robustness of an enterprise-grade platform. Importantly, Canonical Kubernetes can be deployed and managed in whatever way best fits a telco’s environment – whether installed as a secure snap package or integrated with full automation tooling like Juju (model-driven operations) or Kubernetes Cluster API (CAPI). This flexibility means operators can start small at the network edge or scale up to carrier-core clusters, all using the same consistent platform. Notably, Canonical Kubernetes brings cloud-native telco-friendly capabilities in the areas of performance, networking, operations, and support:&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;High performance &amp;amp; low latency&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://ubuntu.com/engage/an-introduction-to-real-time-linux-part-i"&gt;Real-time linux kernel&lt;/a&gt; support ensures that high-priority network workloads execute with predictable, ultra-low latency, a critical requirement for functions like the 5G user plane function (UPF). In parallel, built-in support for advanced networking (including SR-IOV and DPDK) enables fast packet processing by giving containerized network functions direct access to hardware, dramatically reducing network I/O latency for high bandwidth 5G applications. Together, these features allow cloud-native network functions to meet stringent performance and determinism once only achievable on specialized telecom hardware.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;GPU acceleration&lt;/h3&gt;
&lt;p&gt;Canonical Kubernetes integrates seamlessly with acceleration technologies to support emerging cloud-native telco workloads. It works with NVIDIA’s GPU and networking operators to leverage hardware accelerators (GPUs, SmartNICs, DPUs) for intensive tasks. It supports NVIDIA’s Multi-Instance GPU (MIG), which expands the performance and value of the NVIDIA’s data center GPUs, such as the latest GB200 and RTX PRO 6000 Blackwell Server Edition by partitioning the GPU into up to seven instances, each fully hardware isolated with its own high-bandwidth memory, cache, and streaming multiprocessors. The partitioned instances are transparent to workloads which greatly optimizes the use of resources and allows for serving workloads with guaranteed QoS.&lt;/p&gt;
&lt;p&gt;This means telecom operators can run AI/ML analytics, media processing, or virtual RAN computations that take advantage of GPUs and DPU offloading within their Kubernetes clusters – all managed under the same platform. By tapping into hardware acceleration, telcos can deliver advanced services (like AI-driven network optimization or AR/VR streaming) with high performance, without needing separate siloed infrastructure.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Operational efficiency and automation&lt;/h3&gt;
&lt;p&gt;Day-0 to Day-2 operations are streamlined through automation in Canonical’s stack. The distribution supports full lifecycle management – clusters can be deployed, scaled, and updated via one-step commands or integrated CI/CD pipelines, reducing manual effort and errors. Using Juju charms, Canonical’s model-driven operations further simplify complex orchestration, enabling teams to configure and update Kubernetes and related services in a repeatable, declarative way. Built-in self-healing and high availability features ensure that the platform can recover from failures automatically, keeping services running without intervention.&lt;/p&gt;
&lt;p&gt;This high degree of automation translates into faster rollout of new network functions and updates (with minimal downtime), allowing telco teams to focus on innovation rather than routine ops tasks.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Edge flexibility&lt;/h3&gt;
&lt;p&gt;Canonical Kubernetes is designed to run from the core to the far edge with equal ease. Its lightweight, efficient design (delivered as a single snap package) results in a low resource footprint, making it viable even on a one- or two-node edge cluster in a remote site. At the same time, it scales up to multi-node deployments for central networks. The platform supports a variety of configurations – from a single node for an ultra-compact edge appliance, to a dual-node high-availability cluster, to large multi-node clusters for data centers – all with the same tooling and consistent experience.&lt;/p&gt;
&lt;p&gt;This flexibility allows operators to extend cloud capabilities to edge locations (for ultra-low latency processing) while managing everything in a unified way. In practice, Canonical’s solution can power cloud-native telco IT workloads, 5G core functions, and edge applications under one umbrella, meeting the specific performance and latency needs of each environment.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Long-Term support and stability&lt;/h3&gt;
&lt;p&gt;Canonical backs its Kubernetes with long-term support options far exceeding the typical open-source release cycle. &lt;a href="https://canonical.com/blog/12-year-lts-for-kubernetes"&gt;Each Canonical Kubernetes LTS version can receive security patches and maintenance for up to 15 years&lt;/a&gt;, ensuring a stable foundation for cloud-native telco services over the entire 5G rollout and beyond. (For comparison, upstream Kubernetes offers roughly 1 year of support per release).&lt;/p&gt;
&lt;p&gt;This extended support window means carriers can avoid frequent, disruptive upgrades and rest assured that their infrastructure remains compliant over the long term. Such a commitment to stability is a key reason telecom operators choose Canonical – long-term maintenance provides confidence that critical network workloads will run on a hardened, well-maintained platform for many years.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Cost efficiency and vendor neutrality&lt;/h3&gt;
&lt;p&gt;As an open-source, upstream-aligned distribution, Canonical Kubernetes has no licensing costs and prevents vendor lock-in. Telcos are free to deploy it on their preferred hardware or cloud, and they benefit from a large ecosystem of Kubernetes-compatible tools and operators. The platform’s efficient resource usage and automation also help drive down operating costs – by improving hardware utilization and simplifying management, it enables operators to serve growing traffic loads without linear cost increases. In short, Canonical’s Kubernetes offers carrier-grade performance and features at a fraction of the cost of proprietary alternatives, all while keeping the operator in control of their technology roadmap.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Enabling a new wave of cloud-native telco services&lt;/h1&gt;
&lt;p&gt;Using Canonical Kubernetes, cloud-native telcos can position themselves to innovate faster and operate more efficiently in the 5G era. They can readily stand up cloud-native 5G Core functions, scale out Open RAN deployments, and push applications to the network edge – all on a consistent Kubernetes foundation. In fact, Kubernetes makes it feasible for telcos to transition from traditional VNFs on virtual machines to containerized CNFs, reducing resource overhead and speeding up deployment of network features. This means legacy network applications can be modernized step-by-step and run alongside new microservices on the same platform, avoiding risky “big bang” overhauls.&lt;/p&gt;
&lt;p&gt;The result is not only technical efficiency but business agility: operators can launch new services (from enhanced mobile broadband to IoT analytics) in weeks instead of months, respond quickly to customer demand spikes, and streamline the integration of new network functions or vendors.&lt;/p&gt;
&lt;p&gt;Early adopters in the industry are already seeing the benefits. For example, &lt;a href="https://ubuntu.com/blog/bringing-canonical-kubernetes-to-sylva-a-new-chapter-for-european-telco-clouds"&gt;Canonical’s Kubernetes has been embraced in initiatives like the European Sylva open telco cloud project&lt;/a&gt;, in part due to its security, flexibility and long-term support advantages. This momentum underscores that a performant, open Kubernetes platform is becoming a strategic asset for telcos aiming to stay ahead in a competitive landscape. Perhaps most importantly, Canonical Kubernetes lets telcos focus on delivering value to subscribers – ultra-reliable connectivity, rich digital services, tailored enterprise solutions – rather than getting bogged down in infrastructure complexity. It abstracts away much of the heavy lifting of deploying and upgrading distributed systems, while providing the controls needed to meet strict cloud-native telco requirements. The combination of automation, performance tuning, and openness creates a powerful engine for telecom innovation.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Cloud-native at any scale: Canonical Kubernetes meets MicroCloud&lt;/h1&gt;
&lt;p&gt;At the edge, complexity is the enemy. That’s why Canonical Kubernetes pairs naturally with MicroCloud, our lightweight production-grade cloud infrastructure for distributed environments. MicroCloud fits the edge use case extremely well: it is easy to deploy, fully automated, and optimized for bare-metal and low-power sites. Drop it into a telco cabinet, regional hub, or remote data center, and you get a resilient control plane for running Kubernetes, virtualization, and storage with zero overhead.&lt;/p&gt;
&lt;p&gt;In such deployments, MicroCloud and Canonical Kubernetes form a tightly integrated stack that brings cloud-native operations to the far edge. Need to orchestrate CNFs next to VMs? Spin up a single-node cluster with high availability? Scale to dozens of locations without rearchitecting? This combo makes it possible, with snaps for simple updates, Juju for full automation, and long-term support built in.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Conclusion: building the future of cloud-native telco on open source Kubernetes&lt;/h1&gt;
&lt;p&gt;5G and edge computing are reshaping telecom networks, and Kubernetes has proven to be an essential technology powering this evolution.&lt;a href="https://ubuntu.com/industrial"&gt; Industrial IoT&lt;/a&gt;,&lt;a href="https://ubuntu.com/automotive"&gt; automotive applications&lt;/a&gt; ,&lt;a href="https://ubuntu.com/internet-of-things/smart-city"&gt; smart cities&lt;/a&gt;,&lt;a href="https://ubuntu.com/robotics"&gt; robotics&lt;/a&gt;, remote health care, and the gaming industry rely on high data transfer, close to real time latency, very high availability and reliability. Canonical Kubernetes brings the best of cloud-native innovation to the telecom domain in a form that aligns with carriers’ operational realities and performance needs. It delivers a rare mix of benefits – agility and efficiency from automation, high performance for demanding workloads, freedom from lock-in, and assured long-term support – making it a compelling choice for any telco modernizing its infrastructure.&lt;/p&gt;
&lt;p&gt;Telecommunications leaders looking to become cloud-native telcos should consider how an open-source platform like Canonical Kubernetes can serve as a foundation for growth. Whether the goal is to reduce operating costs in the core network, roll out programmable 5G services at the edge, or simply break free from proprietary constraints, Canonical’s Kubernetes distribution provides a proven path forward.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Explore further&lt;/h1&gt;
&lt;p&gt;To dive deeper into how Canonical Kubernetes meets telco performance and reliability requirements, we invite you to read our detailed white paper: &lt;a href="https://ubuntu.com/engage/kubernetes-for-telco-performance"&gt;Addressing telco performance requirements with Canonical Kubernetes&lt;/a&gt;&lt;em&gt;.&lt;/em&gt; It offers in-depth insights and benchmark results from real-world cloud-native telco scenarios. Additionally, visit our blogs on Ubuntu.com and Canonical.com for more success stories and technical guides – from 5G network modernization strategies to edge:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/edge-networking-gets-smarter-ai-and-5g-in-action"&gt;Edge Networking gets smarter: AI and 5G in action&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/canonical-releases-fips-enabled-kubernetes"&gt;Canonical releases FIPS-enabled Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ubuntu.com/blog/canonical-kubernetes-officially-included-in-sylva-1-5"&gt;Canonical Kubernetes officially included in Sylva 1.5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Visiting MWC 2026?&lt;a href="https://canonical.com/solutions/telco#get-in-touch"&gt; Book a meeting with Canonical&lt;/a&gt; to find out more.&lt;/p&gt;
</content:encoded><author>Benjamin Ryzman (Benjamin Ryzman)</author><category>Cloud Native</category><category>kubernetes</category><category>Telco 5G</category><pubDate>Wed, 10 Dec 2025 15:47:17 +0000</pubDate></item><item><title>The rhythm of reliability: inside Canonical’s operational cadence</title><link>https://ubuntu.com//blog/the-rhythm-of-reliability</link><description>&lt;p&gt;At Canonical, time is fixed. Ubuntu releases never slip because we run on a strict rhythm: six-month cycles, two-week pulses, and in-person sprints. Every change is deliberate, ensuring stability without losing agility. This discipline is what enables us to provide 15 years of Long-Term Support. Reliability is built into everything we do.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;In software engineering, we often talk about the “iron triangle” of constraints: time, resources, and features. You can rarely fix all three. At many companies, when scope creeps or resources get tight, the timeline is often the first element of the triangle to slip.&lt;/p&gt;
&lt;p&gt;At Canonical, we take a different approach. For us, &lt;strong&gt;time&lt;/strong&gt; is the fixed constraint.&lt;/p&gt;
&lt;p&gt;This isn’t just about strict project management. It is a mechanism of trust. Our users, customers, and the open source community need to know exactly when the next Ubuntu release is coming. To deliver that reliability externally, we need a rigorous operational rhythm internally, and for over 20 years, we have honored this commitment.&lt;/p&gt;
&lt;p&gt;Here is how we orchestrate the business of building software, from our six-month cycles to the daily pulse of engineering:&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="554" loading="lazy" sizes="(min-width: 1184px) 1184px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1184/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1184/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F54bc%2Fimage.png 1184w" width="1184"/&gt;&lt;/figure&gt;
&lt;p class="has-text-align-center"&gt;Fig. 1 Canonical’s Operating Cycle&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The six-month cycle&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Our entire engineering organization operates on a six-month cycle that aligns with the Ubuntu release cadence. This cycle is our heartbeat. It drives accountability and ensures we ship features on time.&lt;/p&gt;
&lt;p&gt;To make this work, we rely on three critical control points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sprint Readiness Review (SRR): This is where prioritization happens. Before a cycle begins, we don’t just ask “what fits?”: we ask “what matters?” We go through feedback to find the most valuable engineering opportunities, ensuring we prioritize quality and impact over volume. We don’t start the work until we know the scope is worth the effort.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Product Roadmap Sprint: The SRR culminates in this one-week, face-to-face event. This is the formal moment of truth where we close out the previous cycle and leadership signs off on the plan for the next one. It ensures that every team leaves the room with a clear, approved mandate.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Midcycle Review: Three months in, we hold a “Virtual Sprint” to check our progress. Crucially, we review any “bad news”, in which we immediately identify items that will not ship or are at risk. By addressing what won’t happen upfront, leadership can make informed decisions to course-correct immediately rather than letting a deadline slip.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This discipline ensures we stay agile, and that we can adjust our trajectory halfway through without derailing the entire delivery.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The two-week pulse&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;While the six-month cycle sets the destination, the “pulse” gets us there. A pulse is our version of a two-week agile sprint.&lt;/p&gt;
&lt;p&gt;Crucially, these pulses are synchronized across the entire company, on a cross-functional basis. Marketing, Sales, and Support all operate on this same frequency. When a team member says, “we will do it next pulse,” everyone, regardless of department, knows exactly what that means. This creates a shared expectation of delivery that keeps the whole organization moving in lockstep.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Sprints are for in-person connection&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We distinguish between a “pulse” (our virtual, two-week work iteration) and a “sprint.” For us, a sprint is a physical, one-week event where teams meet face-to-face.&lt;/p&gt;
&lt;p&gt;We are a remote-first company, which makes these moments invaluable. Sprints provide the high-bandwidth communication and human connection needed to sustain us through months of remote execution.&lt;/p&gt;
&lt;p&gt;We also stagger these sprints to separate context. Our &lt;strong&gt;Engineering Sprints&lt;/strong&gt; happen in May and November (immediately after an Ubuntu release) so teams can focus purely on technical roadmapping. &lt;strong&gt;Commercial Sprints&lt;/strong&gt; happen in January and July, aligning with our fiscal half-years to focus on business value. This “dual-clock” system ensures that commercial goals and technical realities are synchronized without overwhelming the teams.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Managing the exceptions&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Of course, market reality doesn’t always adhere to a six-month schedule. Customers have urgent needs, and high-value opportunities appear unexpectedly. To handle this without breaking our rhythm, we use the &lt;strong&gt;Commercial Review (CR)&lt;/strong&gt; process.&lt;/p&gt;
&lt;p&gt;The CR process protects our engineering teams from chaos while giving us the agility to say “yes” to the right opportunities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Protection:&lt;/strong&gt; We don’t let unverified requests disrupt the roadmap. A Review Board assesses every non-standard request before we make a promise.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conscious trade-offs:&lt;/strong&gt; If a new request is critical, we ask: “What are we removing to make space for this?” It forces a conscious decision. We review the roadmap and agree on what gets deprioritized to satisfy the new request.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This ensures that when we do deviate from the plan, it is a strategic choice, not an accident.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Quality as a natural habit&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Underpinning this entire rhythm is a commitment to quality standards. We follow the Plan, Do, Check, Act (PDCA) cycle, a concept rooted in ISO 9001. While we align with these formal frameworks, it has become a natural habit for us at Canonical.&lt;/p&gt;
&lt;p&gt;This operational discipline is what enables up to &lt;a href="https://canonical.com/blog/canonical-expands-total-coverage-for-ubuntu-lts-releases-to-15-years-with-legacy-add-on"&gt;15 years of LTS commitment&lt;/a&gt; on a vast portfolio of open source components, providing Long-Term Support for the entire, integrated collection of application software, libraries, and toolchains. Offering 15 years of security maintenance on our entire stack is only possible because we are operationally consistent. Long-term stability is the direct result of short-term discipline.&lt;/p&gt;
&lt;p&gt;By sticking to this rhythm, we ensure that Canonical remains not just a source of great technology, but a reliable partner for the long haul.&lt;/p&gt;
</content:encoded><author>Maksim Beliaev (Maksim Beliaev)</author><category>Business</category><category>Canonical</category><category>lifecycle</category><category>operations</category><pubDate>Wed, 10 Dec 2025 12:22:33 +0000</pubDate></item><item><title>Canonical to distribute AMD ROCm AI/ML and HPC libraries in Ubuntu</title><link>https://ubuntu.com//blog/canonical-amd-rocm-ai-ml-hpc-libraries</link><description>&lt;p&gt;Canonical is pleased to announce an expanded collaboration with AMD to package and maintain AMD ROCm™ software directly in Ubuntu. AMD ROCm is an open software ecosystem to enable hardware-accelerated AI/ML and HPC workloads on AMD Instinct™ and AMD Radeon™ GPUs, simplifying the deployment of AI infrastructure with long term support from Canonical. Canonical has [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Canonical is pleased to announce an expanded collaboration with AMD to package and maintain AMD ROCm™ software directly in Ubuntu. AMD ROCm is an open software ecosystem to enable hardware-accelerated AI/ML and HPC workloads on AMD Instinct™ and AMD Radeon™ GPUs, simplifying the deployment of AI infrastructure with long term support from Canonical.&lt;/p&gt;
&lt;p&gt;Canonical has formed a dedicated team of engineers to package the AMD ROCm software libraries to streamline installation, support, and long-term maintenance on Ubuntu. Canonical will also submit these packages for consideration in Debian.&lt;/p&gt;
&lt;p&gt;This work will simplify the delivery of AMD AI solutions in data centers, workstations, laptops, Windows Subsystem for Linux, and edge environments. AMD ROCm software will be available as a dependency for any Debian package, snap, or Docker image (OCI) build.  Performance fixes and security patches will automatically be available to production systems.&lt;/p&gt;
&lt;p&gt;This collaboration aims to make AMD ROCm software available in Ubuntu starting with Ubuntu 26.04 LTS, with updates available in every subsequent Ubuntu release.  &lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;AMD ROCm software: a commitment to open source &lt;/h2&gt;
&lt;p&gt;Canonical works with silicon industry leaders to incorporate the software libraries and drivers that accelerate applications on their silicon directly into Ubuntu. Comprehensive support for the latest silicon dramatically accelerates developer adoption and production deployments. &lt;/p&gt;
&lt;p&gt;For AMD, the software that enables hardware-accelerated AI processing is called ROCm. It is an open software platform that includes runtimes, compilers, libraries, kernel components, and drivers that together accelerate industry standard frameworks such as PyTorch, Tensorflow, Jax, and more on supported AMD GPUs and APUs. &lt;/p&gt;
&lt;p&gt;“AMD ROCm software enables open, high-performance acceleration for AI and HPC on AMD hardware. Working with Canonical to package AMD ROCm for Ubuntu makes it easier for developers and enterprises to deploy AMD solutions on supported systems,” said Andrej Zdravkovic, Senior Vice President, GPU Technologies and Engineering Software and Chief Software Officer at AMD.     &lt;/p&gt;
&lt;p&gt;Packaging AMD ROCm in Ubuntu underscores the strong AMD commitment to developer experience and enterprise experience:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simpler installation with ‘apt install rocm’ or as an automatic dependency for other projects, like ollama-amd.&lt;/li&gt;
&lt;li&gt;Both stable LTS and fresh ROCm versions every six months will be available, to ensure immediate support for the latest hardware and software.&lt;/li&gt;
&lt;li&gt;Easy security fixes and performance improvements (just “apt upgrade”).&lt;/li&gt;
&lt;li&gt;Up to 15 years of support for AMD ROCm in Ubuntu LTS versions under Ubuntu Pro. &lt;/li&gt;
&lt;li&gt;Personal Ubuntu Pro subscriptions are free.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“We are delighted to work alongside AMD and the community to package AMD ROCm libraries directly into Ubuntu,” said Cindy Goldberg, SVP of Silicon and Cloud Alliances at Canonical. “This will simplify the use of AMD hardware and software for AI workloads, and enable organizations to meet security and maintenance requirements for production use at scale.”&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Improved hardware support&lt;/h2&gt;
&lt;p&gt;Canonical works closely with hardware manufactures to test, optimize, and certify Ubuntu for their devices, and to integrate the required software drivers and kernel patches to support that hardware. Thanks to this extensive hardware program, Ubuntu runs equally well on laptops, workstations, servers, and IoT/edge devices, and developers have a seamless path from development through to deployment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn more about &lt;a href="https://canonical.com/partners/silicon"&gt;Canonical’s silicon partnerships&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amd.com/en/products/software/rocm.html"&gt;Read about AMD ROCm software&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded><author>Canonical (Canonical)</author><category>AI/ML</category><category>Certified hardware</category><category>Ubuntu Pro</category><pubDate>Tue, 09 Dec 2025 17:38:05 +0000</pubDate></item><item><title>How telco companies can reduce 5G infrastructure costs with modern open source cloud-native technologies</title><link>https://ubuntu.com//blog/how-telco-companies-can-reduce-5g-infrastructure-costs-with-modern-open-source-cloud-native-technologies</link><description>&lt;p&gt;5G continues to transform the telecommunications landscape, enabling massive device density, edge computing, and new enterprise use cases. However, operators still face significant cost pressures: from accelerating RAN modernization and 5G SA rollouts to energy demands and the shift to cloud-native network functions (CNFs). As telcos redesign their infrastructure strategies, open source has become a [&amp;hellip;]&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;5G continues to transform the telecommunications landscape, enabling massive device density, edge computing, and new enterprise use cases. However, operators still face significant cost pressures: from accelerating RAN modernization and 5G SA rollouts to energy demands and the shift to cloud-native network functions (CNFs). As telcos redesign their infrastructure strategies, open source has become a key lever to reduce costs, increase flexibility, and accelerate innovation.&lt;/p&gt;
&lt;p&gt;This blog outlines today’s primary 5G infrastructure challenges and highlights how modern open source cloud technologies from Canonical help operators address them.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;The telco dilemma: 5G infrastructure challenges&lt;/h2&gt;
&lt;p&gt;With the advancements of 5G and more complex deployments, telcos face several challenges in building and maintaining 5G infrastructure, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;High investment costs:&lt;/strong&gt; 5G infrastructure requires significant investment in new hardware and software, especially for hosting the virtualization infrastructure necessary to run 5G software&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rising OPEX and energy costs:&lt;/strong&gt; Power consumption of distributed 5G sites is now one of the largest operational expenses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud-native complexity:&lt;/strong&gt; Moving from virtualized network functions (VNFs) to cloud-native network functions (CNFs) increases the need for Kubernetes-scale automation and observability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disaggregated RAN and multi-vendor integrations:&lt;/strong&gt; Open RAN and virtualised RAN require consistent infrastructure, automation and lifecycle management.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limited spectrum:&lt;/strong&gt; The available spectrum for 5G is limited and highly regulated, which can make it difficult for telcos to acquire and use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edge footprint explosion:&lt;/strong&gt; 5G MEC deployments increase the number of sites operators must manage.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Talent and skills gaps:&lt;/strong&gt; Cloud-native and Kubernetes skills remain scarce in telecom operations teams.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security:&lt;/strong&gt; 5G networks are vulnerable to cyber attacks, which can compromise the security and privacy of users’ data. The attack surface is larger with 5G compared to previous generations of mobile networks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vendor Lock-in:&lt;/strong&gt; a telecom operator is heavily dependent on one or a few vendors for all of its 5G network infrastructure and services, making it difficult for the operator to switch to another vendor without incurring significant costs and disruption to its network.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 class="wp-block-heading"&gt;How open source is changing the game&lt;/h2&gt;
&lt;p&gt;Open source plays a central role in enabling telcos to modernise their networks: from VNF virtualization to full cloud-native CNF deployments. By standardizing on open platforms like Ubuntu, Kubernetes and OpenStack, operators reduce infrastructure licensing costs, improve interoperability, and accelerate innovation. Today, most large operators run the majority of their 5G core workloads on open source infrastructure.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Shared standards&lt;/h3&gt;
&lt;p&gt;Open source communities, including CNCF, O-RAN Alliance and Project Sylva, provide common frameworks that reduce integration effort. By adopting open standards, operators can more easily mix vendors and ensure long-term ecosystem interoperability.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Avoid vendor lock-in&lt;/h3&gt;
&lt;p&gt;In line with the development of shared standards, open source solutions can help avoid vendor lock-in by providing access to code that can be modified and adapted to meet specific needs. This means that telcos and ISVs can avoid being tied to a particular vendor or technology stack and choose the best solutions for their specific requirements instead.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Meet specific-telco requirements&lt;/h3&gt;
&lt;p&gt;Telcos have demanding requirements when it comes to performance, reliability, and security. Long-term support (LTS) is important in the telco industry, as telcos often have long cycles of release deployment. Open source solutions that are supported over the long term, with no API breaks or major changes that could disrupt telco operations (i.e. 12-month release at least, and a few years on average) are the foremost choice for telcos. This is usually a vendor-driven decision, but choosing the right open source with the right vendor is the key here. The reason is, it is difficult to have a telco-grade system after dealing with all the interoperability and fixing into the puzzle challenges, so it is reasonable for an operator to expect the support cycle to be as long as possible.&lt;/p&gt;
&lt;p&gt;Performance, flexibility, and automation are key requirements in the telco industry, as they enable telcos to operate more efficiently and effectively. By leveraging the expertise of the wider community, telcos, and ISVs can build solutions that are optimised for telco environments and that can be easily customised to meet specific requirements.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Cost optimization&lt;/h3&gt;
&lt;p&gt;Open source software offers cost savings compared to proprietary solutions, which can be especially beneficial for organizations with limited budgets. With open source software, organizations do not need to pay for licenses, and there are no vendor lock-ins. They can leverage the vast community of developers and users to troubleshoot issues and implement new features. In addition to removing licensing fees, open source automation frameworks significantly reduce operational costs by simplifying CNF lifecycle management, improving energy optimization, and enabling consistent operations across core, edge and RAN deployments.&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Security&lt;/h3&gt;
&lt;p&gt;The telecom sector handles a vast amount of sensitive information, including personal and financial data, making it a prime target for cyber-attacks. There are several data privacy and security concerns that the telecom sector faces, including data breaches, malware attacks, insider threats, lack of compliance, etc. In this regard, open source software vulnerabilities are often patched more quickly than with proprietary software. In addition, open source software is transparent and customisable, making it easier to meet the operator’s unique needs and implement security features that align with their security requirements.&lt;/p&gt;
&lt;p&gt;In the sections that follow we provide example applications for open source solutions across the telco stack, with a focus on tooling supported by Canonical.&lt;/p&gt;
&lt;h2 class="wp-block-heading"&gt;Open source solutions for telcos&lt;/h2&gt;
&lt;p&gt;Canonical’s telco portfolio spans the entire network – from RAN compute nodes to edge clouds, MEC platforms, private clouds and public-cloud deployments. Ubuntu and our cloud-native infrastructure stack (MAAS, MicroCloud, OpenStack, Kubernetes and Juju) provide a consistent operational model across all layers of the 5G architecture.. This enables telcos to meet any current or future use cases – from OpenRAN to next-generation Core (5G and beyond) and AI at the edge. &lt;a href="https://ubuntu.com/pro"&gt;Ubuntu Pro&lt;/a&gt; is Canonical’s comprehensive subscription for enterprise security, compliance and support.&lt;/p&gt;
&lt;p class="has-text-align-center has-small-font-size"&gt;&lt;img decoding="async" height="404" loading="lazy" src="blob:https://admin.insights.ubuntu.com/7992c784-e5d4-4e93-9690-7104aa776539" width="588"/&gt;&lt;br/&gt;Open source solutions for telcos&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Open source for RAN&lt;/h3&gt;
&lt;p&gt;vRAN and Open RAN deployments require high performance, low latency and hardware acceleration. Canonical works closely with &lt;a href="https://builders.intel.com/docs/networkbuilders/network-and-cloud-edge-reference-system-architecture-with-flexran-software-setup-on-a-single-server-quick-start-guide-1658491779.pdf"&gt;Intel FlexRAN&lt;/a&gt;, NVIDIA Aerial and ARM ecosystem partners to optimize Ubuntu for RAN workloads.&lt;/p&gt;
&lt;p&gt;Another major Canonical contribution for RANs edge use cases is&lt;a href="https://ubuntu.com/engage/guide-to-micro-clouds"&gt; MicroCloud,&lt;/a&gt; which reproduces the APIs and primitives of the big clouds at the scale of the edge. MicroClouds are typically targeted to easily deploy and lifecycle manage distributed micro clouds – bare metal compute clusters of between 3-100 nodes. A Canonical MicroCloud stack consists of certain building blocks. The details for each component are covered in our Telco 5G infrastructure&lt;a href="https://ubuntu.com/engage/telco-dilemma-reduce-5g-infra-cost"&gt; whitepaper.&lt;/a&gt;&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Open source for core networks&lt;/h3&gt;
&lt;p&gt;Most operators deploy their 5G Core on private clouds to maintain strict performance and security control. Canonical’s reference architecture – &lt;a href="https://canonical.com/maas"&gt;MAAS&lt;/a&gt; for bare metal, &lt;a href="https://canonical.com/openstack"&gt;OpenStack&lt;/a&gt; for virtualised infrastructure, &lt;a href="https://ubuntu.com/kubernetes"&gt;Kubernetes&lt;/a&gt; for CNFs, and &lt;a href="https://canonical.com/juju"&gt;Juju&lt;/a&gt; for automation – provides a proven, carrier-grade cloud foundation adopted by major network equipment providers (NEPs) and operators globally.&lt;/p&gt;
&lt;p class="has-text-align-center has-small-font-size"&gt;&lt;img decoding="async" height="416" loading="lazy" src="blob:https://admin.insights.ubuntu.com/6db34da1-e968-4e98-9b89-9477bd901677" width="624"/&gt;&lt;br/&gt;Canonical stack for private clouds&lt;/p&gt;
&lt;h4 class="wp-block-heading"&gt;Open source for public and hybrid clouds&lt;/h4&gt;
&lt;p&gt;Ubuntu is known for its reliability, security, and versatility, making it a popular choice for telecom companies that require a stable and secure operating system to run Telco applications in the public cloud. A hybrid cloud architecture combines the usage of a private cloud and one or more public cloud services with a workload orchestration engine between the platforms. Using Juju, operators can orchestrate and lifecycle-manage the same CNF or VNF stack across private OpenStack, MicroCloud edge clusters, and hyperscalers. Juju automation provides a consistent approach that natively supports all major hyper scalers APIs and is a de-facto standard tool for MicroClouds in edge use cases. Additionally, Ubuntu Pro for Public Clouds provides telcos with capabilities based on their unique requirements. Details of these requirements and features from Ubuntu are given in this blog series:&lt;a href="https://ubuntu.com/blog/public-clouds-for-telco-amazon-web-services"&gt; Amazon Web services (AWS)&lt;/a&gt;,&lt;a href="https://ubuntu.com/blog/public-cloud-for-telco-part-2-google-cloud-platform"&gt; Google Cloud Platform (GCP)&lt;/a&gt;, and&lt;a href="https://ubuntu.com/blog/public-cloud-for-telco-part-3-microsoft-azure"&gt; Microsoft Azure.&lt;/a&gt;&lt;/p&gt;
&lt;h3 class="wp-block-heading"&gt;Wrapping up&lt;/h3&gt;
&lt;p&gt;5G infrastructure modernization continues to introduce new operational and cost challenges. Open source cloud technologies, combined with Canonical’s automation and long-term support, help operators simplify their architectures, reduce OPEX, and accelerate the shift to cloud-native 5G.&lt;/p&gt;
&lt;p&gt;To explore the latest best practices, &lt;a href="https://canonical.com/solutions/telco#get-in-touch"&gt;speak with our telco specialists&lt;/a&gt;.&lt;/p&gt;
</content:encoded><author>Benjamin Ryzman (Benjamin Ryzman)</author><category>5g</category><category>Infrastructure</category><category>Telco</category><pubDate>Mon, 08 Dec 2025 12:38:38 +0000</pubDate></item><item><title>From cloud to dashboard: experience the future of infotainment development at CES 2026</title><link>https://ubuntu.com//blog/future-of-infotainment-canonical-at-ces-2026</link><description>&lt;p&gt;This year, we’re excited to show a demo that combines the strengths of both Anbox Cloud and Rightware’s Kanzi, the industry-leading software for creating rich, visually stunning infotainment interfaces.&lt;/p&gt;
</description><content:encoded>
&lt;p&gt;Every year at CES, we try to go beyond showing technology; we want to give you an experience. This time, it’s the story of how in-vehicle infotainment development is transforming, and how developers can now build, test, and deploy immersive experiences faster than ever.&lt;/p&gt;
&lt;p&gt;This year, we’re excited to show a demo that combines the strengths of both Anbox Cloud and Rightware’s Kanzi, the industry-leading software for creating rich, visually stunning infotainment interfaces. It demonstrates cloud-native development, automation, and how virtualization can open up completely new ways to design and test next-generation in-vehicle experiences.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="720" loading="lazy" sizes="(min-width: 1280px) 1280px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1280/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1280/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Fa0b2%2Fimage.png 1280w" width="1280"/&gt;&lt;/figure&gt;
&lt;h1 class="wp-block-heading"&gt;Bridging design, development, and validation&lt;/h1&gt;
&lt;p&gt;Automotive software development has become incredibly complex. Teams are often focused on their own discipline, UI designers on immersive experiences, Android developers on building integrations, and validation engineers on reliability across hardware variants. These teams can’t always collaborate seamlessly.&lt;/p&gt;
&lt;p&gt;Testing an infotainment system means being able to access specific hardware or prototypes, which makes iteration slow and collaboration difficult. Small design updates can take days to validate, and testing across different screen configurations or performance conditions is often limited by the availability of physical setups.&lt;/p&gt;
&lt;p&gt;We wanted to change that by bringing agility and scalability to infotainment development.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Infotainment comes to life in the cloud&lt;/h1&gt;
&lt;p&gt;In our demo, we’ll show how Anbox Cloud turns this traditionally hardware-bound process into a fully virtualized, cloud-native experience. By running Android in the cloud, developers can instantly deploy and test infotainment environments built using Kanzi, on demand, at any scale, from anywhere.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="900" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2Ff2cd%2Fimage-1.jpeg 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p class="has-text-align-center"&gt;&lt;em&gt;Widescreen 8K infotainment CES demo&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Our setup fits perfectly with Rightware’s widescreen 8K infotainment and cluster bench, powered by Kanzi. Developers can stream the exact same 8K rendering using Anbox Cloud. The result is an impressive, interactive experience, generated and streamed entirely from the cloud.&lt;/p&gt;
&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="" height="302" loading="lazy" sizes="(min-width: 1600px) 1600px, 100vw" src="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png" srcset="https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_460/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png 460w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_620/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png 620w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1036/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png 1036w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1681/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png 1681w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1920/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png 1920w, https://res.cloudinary.com/canonical/image/fetch/f_auto,q_auto,fl_sanitize,c_fill,w_1600/https%3A%2F%2Fubuntu.com%2Fwp-content%2Fuploads%2F9fea%2Fimage-1.png 1600w" width="1600"/&gt;&lt;/figure&gt;
&lt;p class="has-text-align-center"&gt;&lt;em&gt;8K virtual Android device running on Anbox Cloud&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Thanks to Anbox Cloud, Android can be virtualized to any resolution, with pixel-perfect rendering and responsiveness. It can scale to dozens of Android instances running simultaneously, so teams can run automated testing, validate UI performance, and work on the system updates in parallel. Your development becomes faster, collaborative, and independent of physical limitations.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Why choose cloud-native Android development?&lt;/h1&gt;
&lt;p&gt;When moving your development testing to the cloud, designers and developers can collaborate in real time and can see their changes without waiting for hardware to be available. Validation teams can run automated tests on multiple Android instances, across different configurations. For OEMs and Tier 1 suppliers, this means shorter development cycles, meaning more efficient resource use, and faster results.&lt;/p&gt;
&lt;p&gt;“Kanzi has always been about empowering designers and developers to bring exceptional in-vehicle experiences to life,” says Tero Koivu, Co-CEO at Rightware. “Seeing a Kanzi made UI streamed at 8K through Anbox Cloud shows how cloud-native workflows can dramatically accelerate iteration and collaboration. It opens a powerful new path for teams building the next generation of connected, visually stunning automotive user interfaces.”&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;See it at CES 2026&lt;/h1&gt;
&lt;p&gt;Join us at LVCC, North Hall, Booth #10562, and check out the workflow for yourself. You’ll see how Kanzi and Anbox Cloud come together to deliver high-fidelity, scalable, cloud-native infotainment experiences, and how this is redefining the way developers can use Android in the cloud.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://calendar.app.google/ao4AHxoZWGkx4wsBA"&gt;Book a meeting with our team&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Come see the future of automotive software development, from cloud to dashboard.&lt;/p&gt;
&lt;p&gt;In the meantime, learn more about &lt;a href="https://canonical.com/anbox-cloud"&gt;Anbox Cloud&lt;/a&gt;, and &lt;a href="https://rightware.com"&gt;Rightware&lt;/a&gt;.&lt;/p&gt;
&lt;h1 class="wp-block-heading"&gt;Further reading&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://documentation.ubuntu.com/anbox-cloud/#"&gt;Official documentation&lt;br/&gt;&lt;/a&gt;&lt;a href="https://documentation.ubuntu.com/anbox-cloud/howto/install-appliance/install-on-github/"&gt;Anbox Cloud Appliance&lt;br/&gt;&lt;/a&gt;&lt;a href="https://canonical.com/anbox-cloud"&gt;Learn more about Anbox Cloud &lt;/a&gt;&lt;/p&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity"/&gt;
&lt;p&gt;Android is a trademark of Google LLC. Anbox Cloud uses assets available through the Android Open Source Project.&lt;/p&gt;
</content:encoded><author>Bertrand Boisseau (Bertrand Boisseau)</author><category>Anbox</category><category>anbox cloud</category><category>Anbox Cloud Appliance</category><category>Automotive</category><category>CES</category><category>Event</category><pubDate>Fri, 05 Dec 2025 08:00:00 +0000</pubDate></item></channel></rss>